{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","show_conversation","apiInProgress","listenButton","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","timer","setTimeout","i","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","g_anwers","CustomVoiceGPT","props","api","kwargs","height","width","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","imageSrc","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistenButton","faceData","useRef","audioRef","isListening","setIsListening","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","Streamlit","setFrameHeight","intervalId","setInterval","SpeechRecognition","browserSupportsContinuousListening","listenContinuously","clearInterval","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","ret","command","type","text","user","stopListening","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","window","location","href","resizeWindow","resizeBy","addEventListener","removeEventListener","className","flex","toLowerCase","endsWith","controls","autoPlay","loop","muted","src","position","top","left","backgroundImage","animation","transform","color","fontSize","background","borderRadius","overflowY","maxHeight","map","answer","idx","key","marginBottom","backgroundColor","resp","padding","marginTop","marginRight","border","cursor","onClick","click_listenButton","marginLeft","placeholder","value","onChange","event","target","onKeyDown","margin","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICgFVC,MArFIC,IAQZ,IARa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,kBACpBC,GAAoB,EAAI,cACxBC,GAAgB,EAAK,aACrBC,GAAe,GAChBP,EACC,MAAOQ,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IAoD7C,OAlDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAS1B,GARAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAG1BO,QAAQC,IAAI,oBAAqBpB,GAI7BU,EAAgBW,MAAM,KAAKC,OAAS,IAGtC,OAFAH,QAAQC,IAAI,wFACZT,IAKFM,EAAcP,GAGd,MAAMa,EAAQC,WAAW,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAI3B,EAASwB,OAAQG,IAAK,CACxC,MAAM,SAAEC,EAAQ,SAAEC,GAAa7B,EAAS2B,GACxC,IAAK,IAAIG,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,IAAKE,GAAkB/B,GAAoBI,KAAkBD,EAU3D,OATIH,EACFD,EAAOW,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACThC,EAAOW,EAAiBZ,EAAS2B,GAAI,GAE9BrB,GACPL,EAAOW,EAAiBZ,EAAS2B,GAAI,QAEvCd,KAMNQ,QAAQC,IAAI,gDACQ,IAAnBnB,GAEH,MAAO,IAAMgC,aAAaV,KAE3B,CAACb,EAAiBV,EAAkBF,EAAUG,EAAkBU,EAAiBR,EAAeC,IAG9FS,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGlC,GACCgC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,WAC5CL,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,SARpCsB,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,OC5DjB,IAEIK,EAAW,GA+gBAC,MA5gBSC,IACtB,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOF,GACvB,SACJ5C,EAAQ,OACR+C,EAAM,MACNC,EAAK,kBACL5C,EAAiB,WACjB6C,EAAU,WACVC,EAAU,iBACV/C,EAAgB,WAChBgD,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,GACEX,GACGY,EAAUC,GAAelD,mBAASqC,EAAOQ,aACzCM,EAAeC,GAAoBpD,mBAASqC,EAAOQ,aAEnDQ,EAASC,GAActD,mBAAS,KAChCuD,EAASC,GAAcxD,mBAAS,KAChCP,EAAkBgE,GAAuBzD,oBAAS,IAElD0D,EAAcC,GAAmB3D,oBAAS,IAC1C4D,EAAcC,GAAmB7D,oBAAS,IAC1C8D,EAAYC,GAAiB/D,mBAAS,KACtCJ,EAAeoE,GAAoBhE,oBAAS,IAC5CiE,EAAUC,GAAyBlE,oBAAS,IAE5CH,EAAcsE,GAAmBnE,oBAAS,GAG3CoE,EAAWC,iBAAO,IAMlBC,GALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAEjBE,EAAaC,GAAkBxE,oBAAS,IACxCyE,EAAoBC,GAAyB1E,oBAAS,IAEtD2E,EAAYC,IAAiB5E,mBAAS,kBACtC6E,GAAmBC,IAAwB9E,mBAAS,aAG3DW,oBAAU,KACJkC,GAEFkC,GAAelC,IAEhB,CAACA,IAEJ,MAAMkC,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAItC,GAASsC,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/CxC,EAAYqC,GACZnC,EAAiBiC,GACjB,MAAOM,OACP/E,QAAQ+E,MAAM,6BAA8BA,SAYhDhF,oBAAU,KACRiF,IAAUC,iBAGV,MAAMC,EAAaC,YAAY,KACxBC,IAAkBC,uCAErBrF,QAAQC,IAAI,iCAAkC8E,OAC9CO,OAED,KAEH,MAAO,KACLC,cAAcL,KAEf,IAEH,MAqBMI,GAAqBA,KACzBF,IAAkBI,eAAe,CAC/BC,YAAY,EACZC,SAAU,UAEZ9B,GAAe,IAYjB7D,oBAAU,KACWqE,WAGjBuB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAMtD,GAAgB,KAEhCuD,GACA,MAAMC,EAAWpB,YAAY,OAE1B,KACH,MAAO,IAAMI,cAAcgB,IAC1B,IAGH,MA8GM3H,GAASwF,MAAOoC,EAAKC,EAASC,KAClChE,EAAW,KAAD8B,OAAMiC,EAAkB,SAAW,QAAC,MAAAjC,OAAKgC,EAAG,MACtD,MAAMG,EAAO,IAAItF,EAAU,CAAEuF,KAAMJ,IACnC5D,EAAW,IAAI+D,IACf,IACE3G,QAAQC,IAAI,wBAAyBwG,GACrCrD,GAAiB,GApKnBgC,IAAkByB,gBAClBjD,GAAe,GACf5D,QAAQC,IAAI,mCAAoC0D,GAqK9C,MAAMmD,EAAO,CACXC,YAAaL,EACb3E,QAASA,EACT4E,KAAMA,EACN1E,WAAYM,EACZyE,UAAWxD,EAASyD,QACpBjF,YAAaA,EACbG,YAAaA,EACbC,cAAcA,GAEhBpC,QAAQC,IAAI,OACZ,MAAM,KAAE6E,SAAeR,IAAM4C,KAAK1F,EAAKsF,GACvC9G,QAAQC,IAAI,YAAa6E,EAAMgC,GAC3BhC,EAAiB,YAAKA,EAAiB,aAAMvC,GAC/C4B,GAAeW,EAAiB,YAElClC,EAAWkC,EAAW,MACtBzD,EAAW,IAAIyD,EAAW,MAEtBpB,EAASuD,SACXvD,EAASuD,QAAQE,QAInB,MAAMC,EAAkB,GAAA5C,OAAMtC,GAASsC,OAAGM,EAAiB,YAC3DpB,EAASuD,QAAU,IAAII,MAAMD,GAC7B1D,EAASuD,QAAQK,OAGjBhE,GAAsB,GACtBY,GAAqB,kBACf,IAAIyB,QAAStH,IACjBqF,EAASuD,QAAQM,QAAU,KACzBvH,QAAQC,IAAI,4BACZ5B,OAGJ2F,GAAc,iBACdE,GAAqB,aACrBZ,GAAsB,GACtBF,GAAiB,GAEjBpD,QAAQC,IAAI,kCAEZ4C,EAAoBiC,EAAyB,oBAC7C9E,QAAQC,IAAI,qBAAsB6E,EAAyB,qBAE/B,IAAxBA,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD9E,QAAQC,IAAI,sBAAuB6E,EAAkB,aAErD0C,OAAOC,SAASC,KAAO5C,EAAkB,cAGvCjG,GAAqBI,GAAiB4E,EAIjC5E,EACTsE,GAAgB,GAEPM,EACPC,GAAsB,IAGtBwB,KACApB,GAAqB,iDAXrBoB,KACApB,GAAqB,sCAavBlE,QAAQC,IAAI,cAAe0D,GAE3B,MAAOoB,OACP/E,QAAQC,IAAI,6BAA8B8E,OAC1C3B,GAAiB,GACjBG,GAAgB,KAoBpB,OAhBAxD,oBAAU,KAER,MAAM4H,EAAeA,KACnBH,OAAOI,SAAS,EAAG,IAQrB,OAHAJ,OAAOK,iBAAiB,wBAAyBF,GAG1C,KACLH,OAAOM,oBAAoB,wBAAyBH,KAErD,IAGD5G,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAK+G,UAAU,OACbhH,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,MAAOO,MAAO,SAE1DZ,IAAAC,cAAA,OAAKE,MAAO,CAAE8G,KAAM,IACjB3F,GAAYA,EAAS4F,cAAcC,SAAS,QAC3CnH,IAAAC,cAAA,SACEU,OAAQA,GAAU,IAClBC,MAAOA,GAAS,IAChBwG,UAAQ,EACRC,UAAU,EACVC,MAAM,EACNC,OAAK,GAELvH,IAAAC,cAAA,UAAQuH,IAAKlG,EAAUqE,KAAK,cAAc,gDAI5C3F,IAAAC,cAAA,OAAKuH,IAAKlG,EAAUX,OAAQA,GAAU,IAAKC,MAAOA,GAAS,MAG5D3C,GACC+B,IAAAC,cAAA,OACEE,MAAO,CACLsH,SAAU,WACVC,IAAK,OACLC,KAAM,IACN/G,MAAO,OACPD,OAAQ,OACRiH,gBAAiB,sDACjBC,UAAW,0BAGb7H,IAAAC,cAAA,OAAKE,MAAO,CAAEsH,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,sBAIrI1F,GACCtC,IAAAC,cAAA,OACEE,MAAO,CACLsH,SAAU,WACVC,IAAK,OACLC,KAAM,IACN/G,MAAO,OACPD,OAAQ,OACRsH,WAAY,uDACZJ,UAAW,4BACXK,aAAc,SAGhBlI,IAAAC,cAAA,OAAKE,MAAO,CAAEsH,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,aAIrIpF,GACC5C,IAAAC,cAAA,OACEE,MAAO,CACLsH,SAAU,WACVC,IAAK,OACLC,KAAM,IACN/G,MAAO,OACPD,OAAQ,OACRiH,gBAAiB,wDACjBC,UAAW,0BAGb7H,IAAAC,cAAA,OAAKE,MAAO,CAAEsH,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAW9E,MAO3IlD,IAAAC,cAAA,OAAKE,MAAO,CAAE8G,KAAM,EAAGkB,UAAW,OAAQC,UAAW,WAC5B,IAAtBpK,GACCgC,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,WAAK,SAAOyB,GACXE,EAAQyG,IAAI,CAACC,EAAQC,IACpBvI,IAAAC,cAAA,OAAKuI,IAAKD,EAAKpI,MAAO,CAAEsI,aAAc,QACpCzI,IAAAC,cAAA,OAAKE,MAAO,CAAEuI,gBAAiBJ,EAAOK,KAAO,UAAY,YAAaC,QAAS,MAAOV,aAAc,QAAS,UACnGI,EAAOzC,MAEjB7F,IAAAC,cAAA,OAAKE,MAAO,CAAEuI,gBAAiBJ,EAAOK,KAAO,cAAgB,UAAWC,QAAS,MAAOV,aAAc,QAAS,UACrGI,EAAOK,KAAOL,EAAOK,KAAO,oBAUhD3I,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQyI,UAAW,SACxC7I,IAAAC,cAAA,UACEE,MAAO,CACL8G,KAAM,EACN6B,YAAa,MACbJ,gBAAiB,UACjBX,MAAO,QACPa,QAAS,OACTG,OAAQ,oBACRC,OAAQ,WAEVC,QAxNiBC,KACzB1G,GAAgB,GAChB+B,KACAtB,GAAc,gBACdhE,QAAQC,IAAI,iCACZD,QAAQC,IAAIhB,KAqNH8E,GAEHhD,IAAAC,cAAA,UACEE,MAAO,CACL8G,KAAM,EACNkC,WAAY,MACZT,gBAAiB,UACjBX,MAAO,QACPa,QAAS,OACTG,OAAQ,oBACRC,OAAQ,WAEVC,QAAS1E,IACV,wBAMHvE,IAAAC,cAAA,OAAK+G,UAAU,OACbhH,IAAAC,cAACvC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,kBAAmBA,EACnBC,cAAeA,EACfC,aAAcA,KAKjB4C,GACCd,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAK+G,UAAU,cACbhH,IAAAC,cAAA,SACE+G,UAAU,eACVrB,KAAK,OACLyD,YAAY,eACZC,MAAOlH,EACPmH,SAvWWC,IAEvBnH,EAAcmH,EAAMC,OAAOH,OAG3BtG,GAAsB,IAmWV0G,UAhWWvM,IACT,UAAVA,EAAEsL,MACJvJ,QAAQC,IAAI,kBAAmBiD,GAC/BtE,GAAOsE,EAAY,CAAE1C,SAAU,CAAEE,QAAS,KAAQ,GAClDyC,EAAc,SA+VRpC,IAAAC,cAAA,MAAIE,MAAO,CAAEuJ,OAAQ,YAAc,QC9fhCC,kBAVDnJ,IACZ,MAAM,IAAEC,EAAG,OAAEC,GAAWF,EAAMoJ,KAE9B,OADA5K,oBAAU,IAAMiF,IAAUC,kBAExBlE,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAC4J,EAAQ,CAACpJ,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAMoJ,EAAS,IAAIC,IAGnBC,IAASC,OACPjK,IAAAC,cAACD,IAAMkK,WAAU,KACflK,IAAAC,cAACkK,IAAiB,CAACd,MAAOS,GACxB9J,IAAAC,cAACmK,IAAa,CAACC,MAAOC,KACpBtK,IAAAC,cAACsK,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.39ffbb43.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  show_conversation = true,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n\n      // Add logs to check the conditions\n      console.log(\"listenAfterReply:\", listenAfterReply);\n      // console.log(\"Number of words:\", finalTranscript.split(\" \").length);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (finalTranscript.split(\" \").length > 100000) {\n        console.log(\"Transcript exceeds 89 words. Clearing You really should call func-api to save .\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword or API is in progress\n        console.log(\"Waiting for a keyword or API is in progress\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n        <div style={{ display: \"flex\", flexDirection: \"column\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          {/* Add other conversation messages here */}\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progress\n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n\n\n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n\n  const [isListening, setIsListening] = useState(false);\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n  const checkListeningStatus = () => {\n    // Check if continuous listening is active\n    if (!SpeechRecognition.browserSupportsContinuousListening()) {\n      // If not, restart continuous listening\n      startContinuousListening();\n    }\n  };\n\n  useEffect(() => {\n    Streamlit.setFrameHeight();\n\n    // Check listening status every minute\n    const intervalId = setInterval(() => {\n      if (!SpeechRecognition.browserSupportsContinuousListening()) {\n        // If continuous listening is not active, start it\n        console.log(\"LISTEN STOPPED TURNING BACK ON\", error);\n        listenContinuously();\n      }\n    }, 60000);\n\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  const startContinuousListening = () => {\n    // Start continuous listening\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n    setIsListening(true)\n  };\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n    setIsListening(false);\n    console.log(\"Stopping Listening, isListening=\", isListening)\n\n    \n  }\n  \n  const startListening = () => {\n    SpeechRecognition.startListening();\n  };\n\n  const listenContinuously = () =>{\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n    setIsListening(true)\n  }\n\n  const listenContinuouslyInChinese = () =>\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"zh-CN\",\n    });\n  const listenOnce = () =>\n    SpeechRecognition.startListening({ continuous: false });\n\n  \n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    listenContinuously()\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      // audioRef.current = new Audio(data[\"audio_path\"]);\n      const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n      audioRef.current = new Audio(apiUrlWithFileName);\n      audioRef.current.play();\n      \n      // Wait for the onended callback to complete before continuing\n      setSpeakingInProgress(true)\n      setButtonName_listen(\"Speaking\")\n      await new Promise((resolve) => {\n        audioRef.current.onended = () => {\n          console.log(\"Audio playback finished.\");\n          resolve();\n        };\n      });\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"]);\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n      \n      if (listenAfterReply && !listenButton && !UserUsedChatWindow) {\n        listenContinuously()\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (UserUsedChatWindow){\n        setUserUsedChatWindow(false)\n      }\n      else {\n        listenContinuously()\n        setButtonName_listen(\"listeing waiting for key word --> stefan\")\n      }\n      \n      console.log(\"listing end\", isListening)\n\n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n  };\n\n  useEffect(() => {\n    // Function to resize the window\n    const resizeWindow = () => {\n      window.resizeBy(0, 1); // Resize the window by 1 pixel vertically\n    };\n\n    // Resize the window after the response finishes\n    // Replace `RESPONSE_FINISH_EVENT` with the event that indicates the response finished\n    window.addEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n\n    // Cleanup the event listener\n    return () => {\n      window.removeEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n    };\n  }, []); // Run only once after component mounts\n\n  return (\n    <>\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'row', width: '100%' }}>\n          {/* Image or video section */}\n          <div style={{ flex: 1 }}>\n            {imageSrc && imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                height={height || 100}\n                width={width || 100}\n                controls\n                autoPlay={true}\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img src={imageSrc} height={height || 100} width={width || 100} />\n            )}\n            {/* Flashing green line indicator */}\n            {apiInProgress && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '10px',\n                  left: '0',\n                  width: '100%',\n                  height: '10px',\n                  backgroundImage: 'linear-gradient(90deg, blue, transparent 50%, blue)',\n                  animation: 'flashLine 1s infinite',\n                }}\n              >\n                <div style={{ position: 'relative', top: '-20px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>One Moment please</div>\n              </div>\n            )}\n            {/* Speaking indicator */}\n            {speaking && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '10px',\n                  left: '0',\n                  width: '100%',\n                  height: '20px',\n                  background: 'linear-gradient(to right, blue, transparent, purple)',\n                  animation: 'waveAnimation 1s infinite',\n                  borderRadius: '10px',\n                }}\n              >\n                <div style={{ position: 'relative', top: '-30px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>Speaking</div>\n              </div>\n            )}\n            {/* Listening indicator */}\n            {isListening && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '10px',\n                  left: '0',\n                  width: '100%',\n                  height: '10px',\n                  backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                  animation: 'flashLine 1s infinite',\n                }}\n              >\n                <div style={{ position: 'relative', top: '-20px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>{buttonName_listen}</div>\n              </div>\n            )}\n          </div>\n  \n          {/* Message section */}\n        {/* Conversation history */}\n        <div style={{ flex: 1, overflowY: 'auto', maxHeight: '400px' }}>\n          {show_conversation === true && (\n            <>\n              <div> You: {message}</div>\n              {answers.map((answer, idx) => (\n                <div key={idx} style={{ marginBottom: '5px' }}>\n                  <div style={{ backgroundColor: answer.resp ? '#f2f2f2' : 'lightblue', padding: '5px', borderRadius: '5px' }}>\n                    -user: {answer.user}\n                  </div>\n                  <div style={{ backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2', padding: '5px', borderRadius: '5px' }}>\n                    -resp: {answer.resp ? answer.resp : \"thinking...\"}\n                  </div>\n                </div>\n              ))}\n            </>\n          )}\n        </div>\n        </div>\n  \n        {/* Listen and Listening buttons */}\n        <div style={{ display: 'flex', marginTop: '10px' }}>\n          <button\n            style={{\n              flex: 1,\n              marginRight: '5px',\n              backgroundColor: '#3498db',\n              color: 'white',\n              padding: '10px',\n              border: '2px solid #2980b9',\n              cursor: 'pointer',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          <button\n            style={{\n              flex: 1,\n              marginLeft: '5px',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              padding: '10px',\n              border: '2px solid #2980b9',\n              cursor: 'pointer',\n            }}\n            onClick={listenContinuously}\n          >\n            Conversational Mode\n          </button>\n        </div>\n  \n        {/* Dictaphone component */}\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            show_conversation={show_conversation}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n          />\n        </div>\n  \n        {/* Input text section */}\n        {input_text && (\n          <>\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder=\"Chat with Me\"\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '20px 0' }} /> {/* Add a solid line */}\n          </>\n        )}\n  \n      </div>\n    </>\n  );\n};\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}