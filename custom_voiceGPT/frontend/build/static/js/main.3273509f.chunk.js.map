{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","noResponseTime","show_conversation","apiInProgress","listenButton","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","timer","setTimeout","i","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","g_anwers","firstFace","CustomVoiceGPT","props","api","kwargs","height","width","show_video","input_text","no_response_time","face_recon","api_key","refresh_ask","before_trigger","api_audio","client_user","imageSrc","setImageSrc","self_image","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","setlistenButton","faceData","useRef","faceTriggered","videoRef","canvasRef","audioRef","isListening","setIsListening","isGreenLightOn","setIsGreenLightOn","async","ret","command","type","concat","text","user","stopListening","body","tigger_type","face_data","current","data","axios","post","pause","apiUrlWithFileName","Audio","play","Promise","onended","window","location","href","listenContinuously","error","Streamlit","setFrameHeight","intervalId","setInterval","SpeechRecognition","browserSupportsContinuousListening","clearInterval","startListening","continuous","language","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","className","position","toLowerCase","endsWith","controls","autoPlay","loop","muted","src","top","left","backgroundImage","animation","transform","color","fontSize","marginTop","flex","marginRight","backgroundColor","padding","border","cursor","onClick","click_listenButton","marginLeft","placeholder","value","onChange","target","onKeyDown","key","map","answer","idx","resp","textAlign","closeWebcam","srcObject","getTracks","stop","borderRadius","startVideo","navigator","mediaDevices","getUserMedia","video","stream","catch","err","justifyContent","opacity","ref","onPlay","handleVideoOnPlay","innerHTML","displaySize","detections","withFaceLandmarks","withFaceExpressions","resizedDetections","hello_audio","getContext","clearRect","drawDetections","drawFaceLandmarks","drawFaceExpressions","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICkFVC,MAvFIC,IAQZ,IARa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,eACxBC,EAAiB,EAAC,kBAClBC,GAAoB,EAAI,cACxBC,GAAgB,EAAK,aACrBC,GAAe,GAChBP,EACC,MAAOQ,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IAsD7C,OApDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAS1B,GARAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAG1BO,QAAQC,IAAI,oBAAqBpB,GAI7BU,EAAgBW,MAAM,KAAKC,OAAS,GAGtC,OAFAH,QAAQC,IAAI,+CACZT,IAKFM,EAAcP,GAGd,MAAMa,EAAQC,WAAW,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAI3B,EAASwB,OAAQG,IAAK,CACxC,MAAM,SAAEC,EAAQ,SAAEC,GAAa7B,EAAS2B,GACxC,IAAK,IAAIG,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAI9C,GAHAV,QAAQC,IAAI,oBAAqBpB,IAG5B+B,GAAkB/B,GAAoBI,KAAkBD,EAU3D,OATIH,EACFD,EAAOW,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACThC,EAAOW,EAAiBZ,EAAS2B,GAAI,GAE9BrB,GACPL,EAAOW,EAAiBZ,EAAS2B,GAAI,QAEvCd,KAMNQ,QAAQC,IAAI,gDACM,IAAjBnB,GAEH,MAAO,IAAMgC,aAAaV,KAE3B,CAACb,EAAiBV,EAAkBF,EAAUG,EAAgBU,EAAiBR,EAAeC,IAG5FS,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGlC,GACCgC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,WAC5CL,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,OACrCsB,IAAAC,cAAA,YAAM,+BAA6B3B,EAA0B,KAAO,SATnE0B,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,OC9DjB,IAEIK,EAAW,GACXC,GAAY,EA2dDC,MAzdSC,IACtB,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOF,GACvB,SACJ7C,EAAQ,OACRgD,EAAM,MACNC,EAAK,kBACL7C,EAAiB,WACjB8C,EAAU,WACVC,EAAU,iBACVC,EAAgB,WAChBC,EAAU,QACVC,EAAO,YACPC,EAAW,eACXC,EAAc,UACdC,EAAS,YACTC,GACEX,GACGY,EAAUC,GAAenD,mBAASsC,EAAOc,aACzCC,EAASC,GAActD,mBAAS,KAChCuD,EAASC,GAAcxD,mBAAS,KAChCP,EAAkBgE,GAAuBzD,oBAAS,IAClD0D,EAAcC,GAAmB3D,oBAAS,IAC1C4D,EAAcC,GAAmB7D,oBAAS,IAC1C8D,EAAYC,GAAiB/D,mBAAS,KACtCJ,EAAeoE,GAAoBhE,oBAAS,IAC5CH,EAAcoE,GAAmBjE,oBAAS,GAG3CkE,EAAWC,iBAAO,IAClBC,EAAgBD,kBAAO,GACvBE,EAAWF,mBAGXG,EAAYH,mBACZI,EAAWJ,iBAAO,OAEjBK,EAAaC,GAAkBzE,oBAAS,IACxC0E,EAAgBC,GAAqB3E,oBAAS,GAuH/CR,EAASoF,MAAOC,EAAKC,EAASC,KAClCzB,EAAW,KAAD0B,OAAMF,EAAkB,SAAW,QAAC,MAAAE,OAAKH,EAAG,MACtD,MAAMI,EAAO,IAAIhD,EAAU,CAAEiD,KAAML,IACnCrB,EAAW,IAAIyB,IACf,IACErE,QAAQC,IAAI,wBAAyBiE,GACrCd,GAAiB,GACjBmB,IAEA,MAAMC,EAAO,CACXC,YAAaN,EACblC,QAASA,EACToC,KAAMA,EACN7B,WAAYF,EACZoC,UAAWpB,EAASqB,QACpBzC,YAAaA,EACbG,YAAaA,GAEfrC,QAAQC,IAAI,OACZ,MAAM,KAAE2E,SAAeC,IAAMC,KAAKrD,EAAK+C,GACvCxE,QAAQC,IAAI,YAAa2E,EAAMJ,GAC/BI,EAAiB,YAAKrC,EAAYqC,EAAiB,YAC/CjB,EAASgB,SACXhB,EAASgB,QAAQI,QAInB,MAAMC,EAAkB,GAAAZ,OAAMhC,GAASgC,OAAGQ,EAAiB,YAC3DjB,EAASgB,QAAU,IAAIM,MAAMD,GAC7BrB,EAASgB,QAAQO,aAGX,IAAIC,QAAS9G,IACjBsF,EAASgB,QAAQS,QAAU,KACzBpF,QAAQC,IAAI,4BACZ5B,OAIJ2B,QAAQC,IAAI,kCACZ2C,EAAWgC,EAAW,MACtBvD,EAAW,IAAIuD,EAAW,MAE1B/B,EAAoB+B,EAAyB,oBAC7C5E,QAAQC,IAAI,qBAAsB2E,EAAyB,qBAE/B,IAAxBA,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD5E,QAAQC,IAAI,sBAAuB2E,EAAkB,aAErDS,OAAOC,SAASC,KAAOX,EAAkB,aAGvC3F,GACJoE,GAAgB,GAEZxE,GACF2G,MAIFA,KAEApC,GAAiB,GAEjB,MAAOqC,OACPzF,QAAQC,IAAI,6BAA8BwF,OAC1CrC,GAAiB,GACjBC,GAAgB,KAIpBtD,oBAAU,KACR2F,IAAUC,iBAGV,MAAMC,EAAaC,YAAY,KACxBC,IAAkBC,uCAErB/F,QAAQC,IAAI,iCAAkCwF,OAC9CD,OAED,KAEH,MAAO,KACLQ,cAAcJ,KAEf,IAEH,MASMrB,EAAgBA,KACpBuB,IAAkBvB,iBAMdiB,GAAqBA,IACzBM,IAAkBG,eAAe,CAC/BC,YAAY,EACZC,SAAU,UA8Bd,OAnBApG,oBAAU,KACWiE,WAGjBmB,QAAQiB,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAM9D,GAAgB,KAEhC+D,GACA,MAAMC,EAAWlB,YAAY,KAC3B7F,QAAQC,IAAI,wBAAyBqD,EAASqB,UAC7C,KACH,MAAO,IAAMqB,cAAce,IAC1B,IAGDhG,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKgG,UAAU,OACfjG,IAAAC,cAAA,OAAKE,MAAO,CAAE+F,SAAU,WAAY9F,QAAS,OAAQC,cAAe,SAAUQ,MAAO,SACzFb,IAAAC,cAAA,OAAKE,MAAO,CAAE+F,SAAU,aACrB3E,GAAYA,EAAS4E,cAAcC,SAAS,QAC3CpG,IAAAC,cAAA,SACEW,OAAQA,GAAU,IAClBC,MAAOA,GAAS,IAChBwF,UAAQ,EACRC,UAAU,EACVC,MAAM,EACNC,OAAK,GAELxG,IAAAC,cAAA,UAAQwG,IAAKlF,EAAU6B,KAAK,cAAc,gDAI5CpD,IAAAC,cAAA,OAAKwG,IAAKlF,EAAUX,OAAQA,GAAU,IAAKC,MAAOA,GAAS,MAG5D5C,GACC+B,IAAAC,cAAA,OACEE,MAAO,CACL+F,SAAU,WACVQ,IAAK,OACLC,KAAM,IACN9F,MAAO,OACPD,OAAQ,MACRgG,gBAAiB,wDACjBC,UAAW,0BAGb7G,IAAAC,cAAA,OAAKE,MAAO,CAAE+F,SAAU,WAAYQ,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,qBAKxIhH,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQS,MAAO,OAAQoG,UAAW,SACvDjH,IAAAC,cAAA,UACEE,MAAO,CACL+G,KAAM,EACNC,YAAa,MACbC,gBAAiB,UACjBL,MAAO,QACPM,QAAS,OACTC,OAAQ,oBACRC,OAAQ,WAEVC,QAjMuBC,KACzBnF,GAAgB,GAChBmC,KACAxF,QAAQC,IAAI,iCACZD,QAAQC,IAAIhB,KA8LX,WAGD8B,IAAAC,cAAA,UACEE,MAAO,CACL+G,KAAM,EACNQ,WAAY,MACZN,gBAAiB,UACjBL,MAAO,QACPM,QAAS,OACTC,OAAQ,oBACRC,OAAQ,WAEVC,QAAS/C,IACV,eAMGzE,IAAAC,cAAA,OAAKgG,UAAU,OACbjG,IAAAC,cAACvC,EAAU,CACTE,SAAUA,EACVC,OAAQA,EACRC,iBAAkBA,EAClBC,eAAgBiD,EAChBhD,kBAAmBA,EACnBC,cAAeA,EACfC,aAAcA,KAIjB6C,GACCf,IAAAC,cAAA,OAAKgG,UAAU,cACbjG,IAAAC,cAAA,SACEgG,UAAU,eACV7C,KAAK,OACLuE,YAAY,kBACZC,MAAOzF,EACP0F,SA3Ua3K,IACvB,MAAM,MAAE0K,GAAU1K,EAAE4K,OACpB1F,EAAcwF,IA0UJG,UAvUa7K,IACT,UAAVA,EAAE8K,MACJ/I,QAAQC,IAAI,kBAAmBiD,GAC/BtE,EAAOsE,EAAY,CAAE1C,SAAU,CAAEE,QAAS,KAAQ,GAClDyC,EAAc,UAuUW,IAAtBpE,GACCgC,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,WAAK,SAAOyB,GACXE,EAAQqG,IAAI,CAACC,EAAQC,IACpBnI,IAAAC,cAAA,OAAK+H,IAAKG,GACRnI,IAAAC,cAAA,WAAK,UAAQiI,EAAO3E,MACpBvD,IAAAC,cAAA,WAAK,UACKiI,EAAOE,KAAOF,EAAOE,KAAO,mBAOhDpI,IAAAC,cAAA,YAGAD,IAAAC,cAAA,WACGgB,GACCjB,IAAAC,cAAA,OAAKE,MAAO,CAAEkI,UAAW,SAAUhB,QAAS,SACzCpF,GAAgBF,EACf/B,IAAAC,cAAA,UACEuH,QA1QMc,KAClB5F,EAASkB,QAAQI,QACjBtB,EAASkB,QAAQ2E,UAAUC,YAAY,GAAGC,OAC1CvG,GAAgB,IAwQJ/B,MAAO,CACLoH,OAAQ,UACRH,gBAAiB,QACjBL,MAAO,QACPM,QAAS,OACTL,SAAU,OACVM,OAAQ,OACRoB,aAAc,SAEjB,gBAID1I,IAAAC,cAAA,UACEuH,QAxWKmB,KACjBzG,GAAgB,GAChB0G,UAAUC,aACPC,aAAa,CAAEC,MAAO,CAAElI,MAAO,OAC/BiF,KAAMkD,IACL,IAAID,EAAQrG,EAASkB,QACrBmF,EAAMR,UAAYS,EAClBD,EAAM5E,SAEP8E,MAAOC,IACNjK,QAAQyF,MAAM,SAAUwE,MA+VhB/I,MAAO,CACLoH,OAAQ,UACRH,gBAAiB,QACjBL,MAAO,QACPM,QAAS,OACTL,SAAU,OACVM,OAAQ,OACRoB,aAAc,SAEjB,gBAMNzG,EACCF,EACE/B,IAAAC,cAAA,WACED,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACT+I,eAAgB,SAChB9B,QAAS,OACTnB,SAAUpF,EAAa,GAAK,WAC5BsI,QAAStI,EAAa,EAAI,KAG5Bd,IAAAC,cAAA,SACEoJ,IAAK3G,EACL9B,OAvaI,IAwaJC,MAvaG,IAwaHyI,OA1XUC,KACxBzE,YAAY7B,UACV,GAAIN,GAAaA,EAAUiB,QAAS,CAClCjB,EAAUiB,QAAQ4F,UAAYlE,IAC5B5C,EAASkB,SAEX,MAAM6F,EAAc,CAClB5I,MArDW,IAsDXD,OAvDY,KA0Dd0E,IAAwB3C,EAAUiB,QAAS6F,GAE3C,MAAMC,QAAmBpE,IAErB5C,EAASkB,QACT,IAAI0B,KAELqE,oBACAC,sBAEGC,EAAoBvE,IAAsBoE,EAAYD,GAe5D,GAbII,EAAkBzK,OAAS,GAC7BmD,EAASqB,QAAUiG,GACdpH,EAAcmB,SAAW3C,IAC5BpD,EAAO,GAAI,CAAE4B,SAAU,CAAEE,QAAS,KAAQ,GAC1C8C,EAAcmB,SAAU,IAI1BtE,WAAW,KACTiD,EAASqB,QAAU,IAClB,KAGDiG,EAAkBzK,OAAS,IAAMmB,IACnCA,GAAY,EACRI,EAAOmJ,aAAa,CACR,IAAI5F,MAAMvD,EAAOmJ,aACzB3F,OAIVxB,GACEA,EAAUiB,SACVjB,EAAUiB,QACPmG,WAAW,MACXC,UAAU,EAAG,EA9FL,IADC,KAgGdrH,GACEA,EAAUiB,SACV0B,IAAa2E,eAAetH,EAAUiB,QAASiG,GACjDlH,GACEA,EAAUiB,SACV0B,IAAa4E,kBAAkBvH,EAAUiB,QAASiG,GACpDlH,GACEA,EAAUiB,SACV0B,IAAa6E,oBACXxH,EAAUiB,QACViG,KAGL,MA6TW1J,MAAO,CAAEuI,aAAc,UAEzB1I,IAAAC,cAAA,UAAQoJ,IAAK1G,EAAWxC,MAAO,CAAE+F,SAAU,gBAI/ClG,IAAAC,cAAA,WAAK,cAGPD,IAAAC,cAAAD,IAAAE,SAAA,SC7cKkK,kBAVD3J,IACZ,MAAM,IAAEC,EAAG,OAAEC,GAAWF,EAAM4J,KAE9B,OADArL,oBAAU,IAAM2F,IAAUC,kBAExB5E,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACqK,EAAQ,CAAC5J,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAM4J,EAAS,IAAIC,IAGnBC,IAASC,OACP1K,IAAAC,cAACD,IAAM2K,WAAU,KACf3K,IAAAC,cAAC2K,IAAiB,CAAChD,MAAO2C,GACxBvK,IAAAC,cAAC4K,IAAa,CAACC,MAAOC,KACpB/K,IAAAC,cAAC+K,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.3273509f.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  noResponseTime = 1,\n  show_conversation = true,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n\n      // Add logs to check the conditions\n      console.log(\"listenAfterReply:\", listenAfterReply);\n      // console.log(\"Number of words:\", finalTranscript.split(\" \").length);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (finalTranscript.split(\" \").length > 89) {\n        console.log(\"Transcript exceeds 89 words. Clearing.\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n            console.log(\"listenAfterReply:\", listenAfterReply);\n            // console.log(\"listenButton:\", listenButton);\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword or API is in progress\n        console.log(\"Waiting for a keyword or API is in progress\");\n      }, noResponseTime * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, noResponseTime, resetTranscript, apiInProgress, listenButton]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n        <div style={{ display: \"flex\", flexDirection: \"column\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          <span>Clear Transcript On Listen: {clearTranscriptOnListen ? \"on\" : \"off\"}</span>\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    before_trigger,\n    api_audio,\n    client_user,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n\n\n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n\n  const [isListening, setIsListening] = useState(true);\n  const [isGreenLightOn, setIsGreenLightOn] = useState(false);\n\n\n  // ... (other code)\n\n  const checkListeningStatus = () => {\n    // Check if continuous listening is active\n    if (!SpeechRecognition.browserSupportsContinuousListening()) {\n      // If not, restart continuous listening\n      startContinuousListening();\n    }\n  };\n\n\n  const handleInputText = (e) => {\n    const { value } = e.target;\n    setTextString(value);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    listenContinuously()\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      data[\"self_image\"] && setImageSrc(data[\"self_image\"]);\n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      // audioRef.current = new Audio(data[\"audio_path\"]);\n      const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n      audioRef.current = new Audio(apiUrlWithFileName);\n      audioRef.current.play();\n\n      // Wait for the onended callback to complete before continuing\n      await new Promise((resolve) => {\n        audioRef.current.onended = () => {\n          console.log(\"Audio playback finished.\");\n          resolve();\n        };\n      });\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"]);\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n      \n      if (listenButton) {\n      setlistenButton(false)\n      \n      if (listenAfterReply) {\n        listenContinuously();\n      }\n      }\n      else {\n      listenContinuously();\n      }\n      setApiInProgress(false); // Set API in progress to false after completion\n\n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n  };\n\n  useEffect(() => {\n    Streamlit.setFrameHeight();\n\n    // Check listening status every minute\n    const intervalId = setInterval(() => {\n      if (!SpeechRecognition.browserSupportsContinuousListening()) {\n        // If continuous listening is not active, start it\n        console.log(\"LISTEN STOPPED TURNING BACK ON\", error);\n        listenContinuously();\n      }\n    }, 60000);\n\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  const startContinuousListening = () => {\n    // Start continuous listening\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n    setIsListening(true);\n  };\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n  };\n  const startListening = () => {\n    SpeechRecognition.startListening();\n  };\n\n  const listenContinuously = () =>\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n  const listenContinuouslyInChinese = () =>\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"zh-CN\",\n    });\n  const listenOnce = () =>\n    SpeechRecognition.startListening({ continuous: false });\n\n  \n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <>\n      <div className=\"p-2\">\n      <div style={{ position: 'relative', display: 'flex', flexDirection: 'column', width: '100%' }}>\n  <div style={{ position: 'relative' }}>\n    {imageSrc && imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n      <video\n        height={height || 100}\n        width={width || 100}\n        controls\n        autoPlay={true}\n        loop={false}\n        muted\n      >\n        <source src={imageSrc} type=\"video/mp4\" />\n        Your browser does not support the video tag.\n      </video>\n    ) : (\n      <img src={imageSrc} height={height || 100} width={width || 100} />\n    )}\n    {/* Flashing green line indicator with words */}\n    {apiInProgress && (\n      <div\n        style={{\n          position: 'absolute',\n          top: '10px',\n          left: '0',\n          width: '100%',\n          height: '4px',\n          backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n          animation: 'flashLine 1s infinite',\n        }}\n      >\n        <div style={{ position: 'absolute', top: '-20px', left: '50%', transform: 'translateX(-50%)', color: 'white', fontSize: '14px' }}>Your words here</div>\n      </div>\n    )}\n  </div>\n  {/* Listen and Listening buttons */}\n  <div style={{ display: 'flex', width: '100%', marginTop: '10px' }}>\n    <button\n      style={{\n        flex: 1,\n        marginRight: '5px',\n        backgroundColor: '#3498db', // Lighter blue color\n        color: 'white',\n        padding: '10px',\n        border: '2px solid #2980b9', // Darker blue border\n        cursor: 'pointer',\n      }}\n      onClick={click_listenButton}\n    >\n      Ask Ozz\n    </button>\n    <button\n      style={{\n        flex: 1,\n        marginLeft: '5px',\n        backgroundColor: '#2980b9', // Darker blue color\n        color: 'white',\n        padding: '10px',\n        border: '2px solid #2980b9', // Use the same color for the border\n        cursor: 'pointer',\n      }}\n      onClick={listenContinuously}\n    >\n      Listening\n    </button>\n  </div>\n</div>\n\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            noResponseTime={no_response_time}\n            show_conversation={show_conversation}\n            apiInProgress={apiInProgress} // Pass down API in progress\n            listenButton={listenButton} // Pass down API in progress\n          />\n        </div>\n\n        {input_text && (\n          <div className=\"form-group\">\n            <input\n              className=\"form-control\"\n              type=\"text\"\n              placeholder=\"Chat with Hoots\"\n              value={textString}\n              onChange={handleInputText}\n              onKeyDown={handleOnKeyDown}\n            />\n          </div>\n        )}\n        {show_conversation === true && (\n          <>\n            <div> You: {message}</div>\n            {answers.map((answer, idx) => (\n              <div key={idx}>\n                <div>-user: {answer.user}</div>\n                <div>\n                  -resp: {answer.resp ? answer.resp : \"thinking...\"}\n                </div>\n              </div>\n            ))}\n          </>\n        )}\n      </div>\n      <div>\n        {/* ... (rest of your code) */}\n      </div>\n      <div>\n        {face_recon && (\n          <div style={{ textAlign: \"center\", padding: \"10px\" }}>\n            {captureVideo && modelsLoaded ? (\n              <button\n                onClick={closeWebcam}\n                style={{\n                  cursor: \"pointer\",\n                  backgroundColor: \"green\",\n                  color: \"white\",\n                  padding: \"15px\",\n                  fontSize: \"25px\",\n                  border: \"none\",\n                  borderRadius: \"10px\",\n                }}\n              >\n                Close Webcam\n              </button>\n            ) : (\n              <button\n                onClick={startVideo}\n                style={{\n                  cursor: \"pointer\",\n                  backgroundColor: \"green\",\n                  color: \"white\",\n                  padding: \"15px\",\n                  fontSize: \"25px\",\n                  border: \"none\",\n                  borderRadius: \"10px\",\n                }}\n              >\n                Open Webcam\n              </button>\n            )}\n          </div>\n        )}\n        {captureVideo ? (\n          modelsLoaded ? (\n            <div>\n              <div\n                style={{\n                  display: \"flex\",\n                  justifyContent: \"center\",\n                  padding: \"10px\",\n                  position: show_video ? \"\" : \"absolute\",\n                  opacity: show_video ? 1 : 0.3,\n                }}\n              >\n                <video\n                  ref={videoRef}\n                  height={videoHeight}\n                  width={videoWidth}\n                  onPlay={handleVideoOnPlay}\n                  style={{ borderRadius: \"10px\" }}\n                />\n                <canvas ref={canvasRef} style={{ position: \"absolute\" }} />\n              </div>\n            </div>\n          ) : (\n            <div>loading...</div>\n          )\n        ) : (\n          <></>\n        )}\n      </div>\n    </>\n  );\n};\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}