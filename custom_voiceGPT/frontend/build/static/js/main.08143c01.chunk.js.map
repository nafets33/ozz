{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","MediaDisplay.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","apiInProgress","listenButton","session_listen","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","show_transcript","setshow_transcript","useEffect","console","log","split","length","i","timer","setTimeout","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","height","display","flexDirection","maxHeight","overflowY","border","padding","onClick","showTranscript_func","marginTop","clearTranscript_func","MediaDisplay","showImage","imageSrc","largeHeight","largeWidth","smallHeight","smallWidth","width","className","alignItems","justifyContent","toLowerCase","endsWith","maxWidth","borderRadius","objectFit","controls","autoPlay","loop","muted","src","type","alt","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistening","show_conversation","setshow_conversation","setlistenButton","setsession_listen","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","setShowImage","windowWidth","setWindowWidth","updateWindowWidth","window","innerWidth","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","stopListening","SpeechRecognition","listenContinuously","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","setInterval","clearInterval","ret","command","text","user","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","location","href","background_color_chat","color_dict","splitImage","placeholder","flex","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","textAlign","marginLeft","marginRight","wordBreak","resp","margin","value","onChange","event","target","onKeyDown","fontSize","color","cursor","click_listenButton","backgroundImage","animation","listen_button","background","listenSession","withStreamlitConnection","args","Streamlit","setFrameHeight","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,gJCyGVC,MA9GIC,IAQZ,IARa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,cACpBC,GAAgB,EAAK,aACrBC,GAAe,EAAK,eACpBC,GAAiB,GAClBP,EACC,MAAOQ,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAiBC,GAAsBV,oBAAS,GAqEvD,OArDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAO1B,GANAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAC1BO,QAAQC,IAAI,oBAAqBpB,GAI7BI,GAAkBM,EAAgBW,MAAM,KAAKC,OAAS,IAAQ,CAChEH,QAAQC,IAAI,8BAEZ,IAAK,IAAIG,EAAI,EAAGA,EAAIzB,EAASwB,OAAQC,IACnCxB,EAAOW,EAAiBZ,EAASyB,GAAI,GAGvC,YADAZ,IAIF,IAAKP,GAAkBM,EAAgBW,MAAM,KAAKC,OAAS,IAGzD,OAFAH,QAAQC,IAAI,kDACZT,IAKF,MAAMa,EAAQC,WAAW,KAEvB,IAAK,IAAIF,EAAI,EAAGA,EAAIzB,EAASwB,OAAQC,IAAK,CACxC,MAAM,SAAEG,EAAQ,SAAEC,GAAa7B,EAASyB,GACxC,IAAK,IAAIK,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,IAAKE,GAAkB/B,GAAoBG,KAAkBD,EAS3D,OARIF,EACFD,EAAOW,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACThC,EAAOW,EAAiBZ,EAASyB,GAAI,GAC5BpB,GACTJ,EAAOW,EAAiBZ,EAASyB,GAAI,QAEvCZ,KAKNQ,QAAQC,IAAI,0BACQ,IAAnBnB,GAEH,MAAO,IAAMgC,aAAaT,KAE3B,CAACd,EAAiBE,EAAWZ,EAAkBF,EAAUG,EAAkBU,EAAiBT,EAAeC,IAEzGU,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKE,MAAO,CAAEC,OAAQ,UAAY,IACjCtB,GACCkB,IAAAC,cAAA,OAAKE,MAAO,CAAEE,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SAChIV,IAAAC,cAAA,YAAM,aAAWzB,GACjBwB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,QAKzCsB,IAAAC,cAAA,UAAQU,QAtFgBC,KAC1B3B,QAAQC,IAAI,qBAAsBJ,GAEhCC,GADED,IAoFoCqB,MAAO,CAAEU,UAAW,SACzD/B,EAAkB,kBAAoB,mBAEvCkB,IAAAC,cAAA,UAAQU,QAhFiBG,KAC3B7B,QAAQC,IAAI,oBACZT,KA8EyC0B,MAAO,CAAEU,UAAW,SAAU,sBAjBhEb,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uBC7CAc,MAtCIpD,IAAsG,IAArG,UAAEqD,EAAS,SAAEC,EAAQ,YAAEC,EAAc,IAAG,WAAEC,EAAa,IAAG,YAAEC,EAAc,GAAE,WAAEC,EAAa,IAAI1D,EAEjH,MAAMyC,EAASY,EAAYE,EAAcE,EACnCE,EAAQN,EAAYG,EAAaE,EAEvC,OACErB,IAAAC,cAAA,OAAKsB,UAAU,MAAMpB,MAAO,CAAEE,QAAS,OAAQC,cAAe,SAAUkB,WAAY,WAElFxB,IAAAC,cAAA,OAAKE,MAAO,CAAEE,QAAS,OAAQoB,eAAgB,SAAUH,MAAO,SAC7DL,IACCA,EAASS,cAAcC,SAAS,QAC9B3B,IAAAC,cAAA,SACEE,MAAO,CAAEyB,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3D1B,OAAQA,EACRkB,MAAOA,EACPS,SAAUf,EACVgB,UAAQ,EACRC,MAAM,EACNC,OAAK,GAELlC,IAAAC,cAAA,UAAQkC,IAAKlB,EAAUmB,KAAK,cAAc,gDAI5CpC,IAAAC,cAAA,OACEkC,IAAKlB,EACLb,OAAQA,EACRkB,MAAOA,EACPnB,MAAO,CAAEyB,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DO,IAAI,sB,aCpBpB,IAEIC,EAAW,GAwoBAC,MAroBSC,IAAW,IAADC,EAChC,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOH,GACvB,SACJ5E,EAAQ,OACRwC,EAAM,MACNkB,EAAK,WACLsB,EAAU,WACVC,EAAU,iBACV9E,EAAgB,WAChB+E,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,EAAa,eACbC,GACEV,GACG1B,EAAUqC,GAAejF,mBAASsE,EAAOM,aACzCM,EAAeC,GAAoBnF,mBAASsE,EAAOM,aAEnDQ,EAASC,GAAcrF,mBAAS,KAChCsF,EAASC,GAAcvF,mBAAS,KAChCP,EAAkB+F,GAAuBxF,oBAAS,IAElDyF,EAAcC,GAAmB1F,oBAAS,IAC1C2F,EAAcC,GAAmB5F,oBAAS,IAC1C6F,EAAYC,GAAiB9F,mBAAS,KACtCL,EAAeoG,GAAoB/F,oBAAS,IAC5CgG,EAAUC,GAAyBjG,oBAAS,IAC5CK,EAAW6F,GAAgBlG,oBAAS,IAEpCmG,EAAmBC,GAAwBpG,oBAAS,IAGpDJ,EAAcyG,GAAmBrG,oBAAS,IAC1CH,EAAgByG,GAAqBtG,oBAAS,IAE9CuG,GAAqBC,IAAmBxG,mBAASsE,EAAOU,gBACzDyB,GAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBE,GAAoBC,IAAyB7G,oBAAS,IACtD8G,GAAYC,IAAiB/G,mBAAS,kBACtCgH,GAAmBC,IAAwBjH,mBAAS,cAEpD2C,GAAWuE,IAAgBlH,oBAAS,IAQpCmH,GAAaC,IAAkBpH,mBAAS,GAGvCqH,GAAoBA,KACF,qBAAXC,QACPF,GAAeE,OAAOC,aAK9B5G,oBAAU,KACN0G,MACD,IAEH1G,oBAAU,KACJiE,GAEF4C,GAAe5C,IAEhB,CAACA,IAEJ,MAAM4C,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAIhD,GAASgD,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/ClD,EAAY+C,GACZ7C,EAAiB2C,GACjB,MAAOM,GACPxH,QAAQwH,MAAM,6BAA8BA,KAM1CC,GAAgBA,KACpBnC,GAAa,GACboC,IAAkBD,gBAClBzH,QAAQC,IAAI,mCAAoCR,IAG5CkI,GAAqBA,KACzBrC,GAAa,GACboC,IAAkBE,eAAe,CAC/BC,YAAY,EACZC,SAAU,WAiBhB/H,oBAAU,KACJN,EACFO,QAAQC,IAAI,yBAEZD,QAAQC,IAAI,0BAEb,CAACR,IAYFM,oBAAU,KACW8G,WAGjBkB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAM3D,GAAgB,KAEhC4D,GACA,MAAMC,EAAWC,YAAY,OAE1B,KACH,MAAO,IAAMC,cAAcF,IAC1B,IAsHH,MAAM/J,GAASiI,MAAOiC,EAAKC,EAAS5F,KAClCsB,EAAW,KAADwC,OAAM8B,EAAkB,SAAW,QAAC,MAAA9B,OAAK6B,EAAG,MACtD,MAAME,EAAO,IAAI3F,EAAU,CAAE4F,KAAMH,IACnCnE,EAAW,IAAIqE,IACf,IACEhJ,QAAQC,IAAI,wBAAyB8I,GACrC5D,GAAiB,GACjBsC,KAEA,MAAMyB,EAAO,CACXC,YAAahG,EACbW,QAASA,EACTkF,KAAMA,EACNhF,WAAYM,EACZ8E,UAAWvD,GAASwD,QACpBtF,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdlF,eAAeA,EACf0G,oBAAoBA,IAEtB3F,QAAQC,IAAI,OACZ,MAAM,KAAEsH,SAAeR,IAAMuC,KAAK7F,EAAKyF,GAYvC,GAXAlJ,QAAQC,IAAI,YAAasH,EAAM2B,GAC3B3B,EAAiB,YAAKA,EAAiB,aAAMjD,GAC/CsC,GAAeW,EAAiB,YAElC5C,EAAW4C,EAAW,MACtBlE,EAAW,IAAIkE,EAAW,MAEtBxB,GAASsD,SACXtD,GAASsD,QAAQE,QAGfhC,EAAiB,WAAG,CACtB,MAAMiC,EAAkB,GAAAvC,OAAMhD,GAASgD,OAAGM,EAAiB,YAC3DxB,GAASsD,QAAU,IAAII,MAAMD,GAE7B,UACUzD,GAASsD,QAAQK,OAGvBrE,GAAsB,GACtBgB,GAAqB,kBAGf,IAAI0B,QAAS1J,IACf0H,GAASsD,QAAQM,QAAU,KACvB3J,QAAQC,IAAI,4BACZ5B,OAIV,MAAOmJ,GACLxH,QAAQwH,MAAM,wBAAyBA,GAC1C,QAEGzB,GAASsD,QAAU,KACnBhE,GAAsB,GACtBgB,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBhB,GAAsB,GACtBF,GAAiB,GAEjBnF,QAAQC,IAAI,kCAEZ2E,EAAoB2C,EAAyB,oBAC7CvH,QAAQC,IAAI,qBAAsBsH,EAAyB,mBAAG1I,IAIlC,IAAxB0I,EAAkB,aAAuC,OAAxBA,EAAkB,cACrDvH,QAAQC,IAAI,sBAAuBsH,EAAkB,aAErDb,OAAOkD,SAASC,KAAOtC,EAAkB,aAGvCvB,GACFC,IAAsB,GAEG,GAAlBpH,GACPmB,QAAQC,IAAI,sCACZoG,GAAqB,sCAEdrH,GACTyG,GAAgB,GAIhB,MAAO+B,GACPxH,QAAQC,IAAI,6BAA8BuH,GAC1CrC,GAAiB,GACjBM,GAAgB,GAGlBgB,KACAzG,QAAQC,IAAI,kBAoBR6J,IAA8C,QAAtBtG,EAAAO,EAAYgG,kBAAU,IAAAvG,OAAA,EAAtBA,EAAwBsG,wBAAyB,cACzEE,GAAahG,EAAW9D,MAAM,KAAK,GACnC+J,GAAW,aAAAhD,OAAgB+C,IAEjC,OACEjJ,IAAAC,cAAAD,IAAAE,SAAA,KAEEF,IAAAC,cAAA,OAAKsB,UAAU,OACbvB,IAAAC,cAAA,OAAKE,MAAO,CAAEE,QAAS,OAAQC,cAAe,SAAUgB,MAAO,SAE7DtB,IAAAC,cAAA,WAEED,IAAAC,cAACc,EAAY,CACXC,UAAWA,GACXC,SAAUA,EACVC,YAAa,IACbC,WAAY,IACZC,YAAa,GACbC,WAAY,MAKhBrB,IAAAC,cAAA,OAAKE,MAAO,CAAEgJ,KAAMnI,GAAY,EAAI,OAAQR,UAAW,OAAQD,UAAW,UACzEiE,GACCxE,IAAAC,cAAA,OACEE,MAAO,CACLE,QAAS,OACTC,cAAe,SACfC,UAAW,QACXH,OAAQ,QACRI,UAAW,OACXC,OAAQ,iBACRC,QAAS,SAGViD,EAAQyF,IAAI,CAACC,EAAQC,IACpBtJ,IAAAC,cAAA,OACEsJ,IAAKD,EACL/H,UAAU,yBACVpB,MAAO,CACLqJ,aAAc,MACd9I,QAAS,MACTmB,aAAc,MACdpB,OAAQ,iBACRgJ,UAAW,iCAIbzJ,IAAAC,cAAA,OACEsB,UAAU,YACVpB,MAAO,CACLuJ,gBAAiB,UACjBC,UAAW,QACXC,WAAY,OACZlJ,QAAS,QAGVyC,EAAY,KAAEnD,IAAAC,cAAA,YAAOoJ,EAAOnB,OAE/BlI,IAAAC,cAAA,OACEsB,UAAU,0BACVpB,MAAO,CACLE,QAAS,OACTmB,WAAY,aACZkI,gBAAiBX,GACjBrI,QAAS,SAIVO,GACCjB,IAAAC,cAAA,OAAKsB,UAAU,aAAapB,MAAO,CAAE0J,YAAa,SAChD7J,IAAAC,cAAA,OAAKkC,IAAKlB,EAAUoB,IAAI,WAAWlC,MAAO,CAAEmB,MAAO,WAIvDtB,IAAAC,cAAA,OAAKsB,UAAU,qBAAqBpB,MAAO,CAAEgJ,KAAM,EAAGW,UAAW,eAC9DT,EAAOU,MAAQ,qBAW7BlH,GACC7C,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAE6J,OAAQ,YACnBhK,IAAAC,cAAA,OAAKsB,UAAU,cACbvB,IAAAC,cAAA,SACEsB,UAAU,eACVa,KAAK,OACL8G,YAAaA,GACbe,MAAO/F,EACPgG,SA5UWC,IAEvBhG,EAAcgG,EAAMC,OAAOH,OAG3B/E,IAAsB,IAwUVmF,UArUWnN,IACT,UAAVA,EAAEqM,MACJtK,QAAQC,IAAI,kBAAmBgF,GAC/BrG,GAAOqG,EAAY,CAAEzE,SAAU,CAAEE,QAAS,KAAQ,GAClDwE,EAAc,SAoURnE,IAAAC,cAAA,MAAIE,MAAO,CAAE6J,OAAQ,aAK3BhK,IAAAC,cAAA,OAAKE,MAAO,CAAEE,QAAS,OAAQQ,UAAW,SAExCb,IAAAC,cAAA,OAAKE,MAAO,CAAEgJ,KAAM,EAAGQ,UAAW,WAChC3J,IAAAC,cAAA,UACEE,MAAO,CACLmK,SAAU,OACV5J,QAAS,MACTsJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACP9J,OAAQ,oBACRoB,aAAc,MACd2I,OAAQ,UACRlJ,MAAO,QAETX,QA/PiB8J,KACzB/F,GAAgB,GACXhG,GACLkI,KAEAxB,GAAc,gBACdnG,QAAQC,IAAI,iCACZD,QAAQC,IAAIjB,KA0PHkH,IAEFzG,GACCsB,IAAAC,cAAA,OACEE,MAAO,CACLmB,MAAO,OACPlB,OAAQ,OACRsK,gBAAiB,wDACjBC,UAAW,wBACX9J,UAAW,QAGbb,IAAAC,cAAA,OAAKE,MAAO,CAAEmK,SAAU,OAAQC,MAAO,UAAYlF,MAMzDrF,IAAAC,cAAA,OAAKE,MAAO,CAAEgJ,KAAM,EAAGQ,UAAW,WAChC3J,IAAAC,cAAA,UACEE,MAAO,CACLmK,SAAU,OACV5J,QAAS,MACTsJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACP9J,OAAQ,oBACRoB,aAAc,MACd2I,OAAQ,WAGV7J,QAtbUiK,KACpB3L,QAAQC,IAAI,aAAcR,GACrBA,GAIHO,QAAQC,IAAI,yBACZwH,OAJAzH,QAAQC,IAAI,yBACZ0H,QAmbO,uBAGAvC,GACCrE,IAAAC,cAAA,OACEE,MAAO,CAELC,OAAQ,OACRyK,WAAY,uDACZF,UAAW,4BACX9J,UAAW,MACXgB,aAAc,SAGhB7B,IAAAC,cAAA,OAAKE,MAAO,CAAEmK,SAAU,OAAQC,MAAO,UAAW,cAMxDvK,IAAAC,cAAA,OAAKE,MAAO,CAAEgJ,KAAM,EAAGQ,UAAW,WAChC3J,IAAAC,cAAA,UACEE,MAAO,CACLmK,SAAU,OACV5J,QAAS,MACTsJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACP9J,OAAQ,oBACRoB,aAAc,MACd2I,OAAQ,WAEV7J,QAncYmK,KAEpBnG,GADIzG,KAocKA,EAAiB,eAAiB,iBAEpCA,GACC8B,IAAAC,cAAA,OACEE,MAAO,CACLmB,MAAO,MACPlB,OAAQ,OACRsK,gBAAiB,0DACjBC,UAAW,wBACX9J,UAAW,QAGbb,IAAAC,cAAA,OAAKE,MAAO,CAAEmK,SAAU,OAAQC,MAAO,UAAW,qBAMxDvK,IAAAC,cAAA,OAAKE,MAAO,CAAEgJ,KAAM,EAAGQ,UAAW,WAChC3J,IAAAC,cAAA,UACEE,MAAO,CACLmK,SAAU,OACV5J,QAAS,MACTsJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACP9J,OAAQ,oBACRoB,aAAc,MACd2I,OAAQ,WAEV7J,QAAS+F,IAERhI,EAAY,iBAAmB,MAMpCsB,IAAAC,cAAA,OAAKsB,UAAU,MAAMpB,MAAO,CAAEqJ,aAAc,SAC1CxJ,IAAAC,cAACvC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,EAChBQ,UAAWA,QCtnBRqM,kBAVDvI,IACZ,MAAM,IAAEE,EAAG,OAAEC,GAAWH,EAAMwI,KAE9B,OADAhM,oBAAU,IAAMiM,IAAUC,kBAExBlL,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACkL,EAAQ,CAACzI,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAMyI,EAAS,IAAIC,IAGnBC,IAASC,OACPvL,IAAAC,cAACD,IAAMwL,WAAU,KACfxL,IAAAC,cAACwL,IAAiB,CAACxB,MAAOmB,GACxBpL,IAAAC,cAACyL,IAAa,CAACC,MAAOC,KACpB5L,IAAAC,cAAC4L,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.08143c01.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n  session_listen = false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [show_transcript, setshow_transcript] = useState(true); // Added state for API in progress\n\n  const showTranscript_func = () => {\n    console.log(\"set showTranscript\", show_transcript)\n    if (show_transcript) {\n      setshow_transcript(false)\n    } else {\n      setshow_transcript(true)\n    }\n  };\n\n  const clearTranscript_func = () => {\n    console.log(\"clear transcript\")\n    resetTranscript()\n  }\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds limits\n      if (session_listen && finalTranscript.split(\" \").length > 500000) {\n        console.log(\"Transcript exceeds X words\");\n        // Ensure to check if i is defined\n        for (let i = 0; i < commands.length; i++) {\n          myFunc(finalTranscript, commands[i], 6);\n        }\n        resetTranscript();\n        return;\n      }\n\n      if (!session_listen && finalTranscript.split(\" \").length > 10000) {\n        console.log(\"Transcript exceeds 10000 words. Clearing.\");\n        resetTranscript();\n        return;\n      }\n\n      // Clear any existing timers to prevent multiple triggers\n      const timer = setTimeout(() => {\n\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              } else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        console.log(\"Waiting for a keyword\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listening, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      <div style={{ height: \"20px\" }} /> {/* Adds empty space */}\n      {show_transcript && (\n        <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"200px\", overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span>You said: {finalTranscript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          {/* Add other conversation messages here */}\n        </div>\n      )}\n      {/* Button to clear the transcript */}\n      <button onClick={showTranscript_func} style={{ marginTop: \"10px\" }}>\n      {show_transcript ? \"Hide Transcript\" : \"Show Transcript\"}\n      </button>\n      <button onClick={clearTranscript_func} style={{ marginTop: \"10px\" }}>\n      Clear Transscript\n      </button>\n    </>\n  );\n}\n\nexport default Dictaphone;","import React from 'react';\n\nconst MediaDisplay = ({ showImage, imageSrc, largeHeight = 100, largeWidth = 100, smallHeight = 40, smallWidth = 40 }) => {\n    // Determine the dimensions based on `showImage` status\n    const height = showImage ? largeHeight : smallHeight;\n    const width = showImage ? largeWidth : smallWidth;\n  \n    return (\n      <div className=\"p-2\" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center' }}>\n        {/* Always show the image or video at the top center based on `showImage` */}\n        <div style={{ display: 'flex', justifyContent: 'center', width: '100%' }}>\n          {imageSrc && (\n            imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                height={height}\n                width={width}\n                controls={showImage} // Only show controls if `showImage` is true\n                autoPlay\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img\n                src={imageSrc}\n                height={height}\n                width={width}\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                alt=\"Media Preview\"\n              />\n            )\n          )}\n        </div>\n      </div>\n    );\n  };\n  \n  export default MediaDisplay;","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\nimport MediaDisplay from \"./MediaDisplay\";\n\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progresslistening\n  const [listening, setlistening] = useState(false); // Added state for API in progress\n\n  const [show_conversation, setshow_conversation] = useState(true); // Added state for API in progress\n  \n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n\n  \n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  const [windowWidth, setWindowWidth] = useState(0); // Initial value\n\n    // Create a reusable function for getting the window width\n    const updateWindowWidth = () => {\n      if (typeof window !== 'undefined') {\n          setWindowWidth(window.innerWidth);\n      }\n  };\n\n  // Call the function on component mount to set the initial window width\n  useEffect(() => {\n      updateWindowWidth();\n  }, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n\n\n  const stopListening = () => {\n    setlistening(false);\n    SpeechRecognition.stopListening();\n    console.log(\"Stopping Listening, isListening=\", listening)\n  }\n\n  const listenContinuously = () =>{\n    setlistening(true)\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n\n}\n\n\nconst listen_button = () => {\n  console.log(\"listening?\", listening);\n  if (!listening) {\n    console.log(\"Starting to listen...\");\n    listenContinuously();\n  } else {\n    console.log(\"Stopping listening...\");\n    stopListening();\n  }\n};\n\nuseEffect(() => {\n  if (listening) {\n    console.log(\"Listening has started\");\n  } else {\n    console.log(\"Listening has stopped\");\n  }\n}, [listening]);\n\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    if (!listening) {\n    listenContinuously()\n    }\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  function isHTML(str) {\n    return /^</.test(str);\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"], listenAfterReply);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n\n      if (UserUsedChatWindow) {\n        setUserUsedChatWindow(false)\n      }\n      else if (listenAfterReply==true) {\n        console.log(\"API END HIT listen after replyTRUE\")\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n\n      \n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n\n    updateWindowWidth();\n    console.log(\"ReSize Window\")\n  };\n\n  // useEffect(() => {\n  //   // Function to resize the window\n  //   const resizeWindow = () => {\n  //     window.resizeBy(0, 1); // Resize the window by 1 pixel vertically\n  //   };\n\n  //   // Resize the window after the response finishes\n  //   // Replace `RESPONSE_FINISH_EVENT` with the event that indicates the response finished\n  //   window.addEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n\n  //   // Cleanup the event listener\n  //   return () => {\n  //     window.removeEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n  //   };\n  // }, []); // Run only once after component mounts\n\n  \n  const background_color_chat = refresh_ask.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'column', width: '100%' }}>\n          {/* Image or video section */}\n          <div>\n            {/* Media Display */}\n            <MediaDisplay\n              showImage={showImage}\n              imageSrc={imageSrc}\n              largeHeight={100}   // Customize as needed\n              largeWidth={100}    // Customize as needed\n              smallHeight={40}    // Customize as needed\n              smallWidth={40}     // Customize as needed\n            />\n          </div>\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '400px' }}>\n          {show_conversation && (\n            <div\n              style={{\n                display: 'flex',\n                flexDirection: 'column',\n                maxHeight: '400px', // Set your desired max height\n                height: '400px', // Fixed height to ensure no resizing\n                overflowY: 'auto', // Enable scrolling within this container\n                border: '1px solid #ccc',\n                padding: '10px',\n              }}\n            >\n              {answers.map((answer, idx) => (\n                <div\n                  key={idx}\n                  className=\"chat-message-container\"\n                  style={{\n                    marginBottom: '5px',\n                    padding: '5px',\n                    borderRadius: '4px',\n                    border: '1px solid #ccc', // Inner border for each message\n                    boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',\n                    // backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2', // Background color\n                  }}\n                >\n                  <div\n                    className=\"chat-user\"\n                    style={{\n                      backgroundColor: '#f2f2f2',\n                      textAlign: 'right',\n                      marginLeft: 'auto',\n                      padding: '5px',\n                    }}\n                  >\n                    {client_user}: <span>{answer.user}</span>\n                  </div>\n                  <div\n                    className=\"chat-response-container\"\n                    style={{\n                      display: 'flex',\n                      alignItems: 'flex-start',\n                      backgroundColor: background_color_chat,\n                      padding: '10px', // Padding for better spacing\n                    }}\n                  >\n                    {/* Optional image on the left side */}\n                    {imageSrc && (\n                      <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                        <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} />\n                      </div>\n                    )}\n                    {/* Wrapping response text */}\n                    <div className=\"chat-response-text\" style={{ flex: 1, wordBreak: 'break-word' }}>\n                      {answer.resp || \"thinking...\"}\n                    </div>\n                  </div>\n                </div>\n              ))}\n            </div>\n          )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '20px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '20px 0' }} />\n          </>\n        )}\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '10px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '100%',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          {listening && (\n            <div\n              style={{\n                width: '100%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              // width: '100%',\n            }}\n            onClick={listen_button}\n          >\n            Conversational Mode\n          </button>\n          {speaking && (\n            <div\n              style={{\n                // width: '89%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={listenSession}\n          >\n            {session_listen ? \"Stop Session\" : \"Start Session\"}\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n        {/* Toggle Image Button */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={stopListening}\n          >\n            {listening ? \"Stop Listening\" : \"\"}\n          </button>\n        </div>\n      </div>\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\" style={{ marginBottom: '15px' }}>\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n            listening={listening}\n          />\n        </div>\n  \n\n      </div>\n\n\n\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}