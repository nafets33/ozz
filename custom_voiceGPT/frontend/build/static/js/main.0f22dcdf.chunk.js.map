{"version":3,"sources":["Dictaphone.jsx","MediaDisplay.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","apiInProgress","listenButton","session_listen","finalTranscript","interimTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","editableTranscript","setEditableTranscript","useState","show_transcript","setShowTranscript","textareaRef","useRef","cursorPosRef","useEffect","processTranscript","api_body","prev","trim","keywordFound","i","length","keywords","j","keyword","RegExp","search","console","log","current","selectionStart","selectionEnd","React","createElement","Fragment","style","display","gap","marginBottom","onClick","backgroundColor","color","border","padding","borderRadius","cursor","showTranscript_func","clearTranscript_func","flexDirection","maxHeight","height","overflowY","fontStyle","ref","value","onChange","e","target","width","resize","MediaDisplay","showImage","imageSrc","largeHeight","largeWidth","smallHeight","smallWidth","className","alignItems","justifyContent","toLowerCase","endsWith","maxWidth","objectFit","controls","autoPlay","loop","muted","src","type","alt","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","agent_actions","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistening","show_conversation","setshow_conversation","setlistenButton","setsession_listen","convo_button","setconvo_button","before_trigger_vars","before_trigger_","faceData","audioRef","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","setShowImage","selectedActions","setSelectedActions","windowWidth","setWindowWidth","updateWindowWidth","window","innerWidth","fetchImageData","async","response","axios","get","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","stopListening","SpeechRecognition","listenContinuously","startListening","continuous","language","ret","command","text","user","body","tigger_type","face_data","selected_actions","post","pause","apiUrlWithFileName","Audio","play","Promise","resolve","onended","location","href","background_color_chat","color_dict","placeholder","split","flex","map","answer","idx","key","boxShadow","textAlign","marginLeft","marginRight","wordBreak","resp","dangerouslySetInnerHTML","__html","margin","event","onKeyDown","marginTop","fontSize","click_listenButton","convo_mode","backgroundImage","animation","background","listenSession","Array","isArray","flexWrap","action","selected","includes","filter","a","withStreamlitConnection","args","Streamlit","setFrameHeight","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"8NA4MeA,MAzMIC,IAQb,IARcC,SAClBA,EAAQC,OACRA,EAAMC,iBACNA,GAAmB,EAAKC,iBACxBA,EAAmB,EAACC,cACpBA,GAAgB,EAAKC,aACrBA,GAAe,EAAKC,eACpBA,GAAiB,GAClBP,EACC,MAAMQ,gBACJA,EAAeC,kBACfA,EAAiBC,gBACjBA,EAAeC,UACfA,EAASC,iCACTA,EAAgCC,sBAChCA,GACEC,kCAEGC,EAAoBC,GAAyBC,mBAAS,KACtDC,EAAiBC,GAAqBF,oBAAS,GAOhDG,EAAcC,iBAAO,MACrBC,EAAeD,iBAAO,MA0D5BE,oBAAU,KAxDgBC,MACxB,GAAwB,KAApBhB,EAAwB,CAM1B,GAAIF,EAMJ,OAJAJ,EAAOM,EAAiB,CAAEiB,SAAU,IAAM,GAC1CT,EAAuBU,MAAYA,KAAQlB,IAAkBmB,QAC7DjB,SACAM,EAAsB,IAKtB,GAAIT,EAAgB,CAElB,IAAIqB,GAAe,EACnB,IAAK,IAAIC,EAAI,EAAGA,EAAI5B,EAAS6B,OAAQD,IAAK,CACxC,MAAME,SAAEA,EAAQN,SAAEA,GAAaxB,EAAS4B,GACxC,IAAK,IAAIG,EAAI,EAAGA,EAAID,EAASD,OAAQE,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOH,EAASC,GAAI,KAGxC,IAF4D,IAArCxB,EAAgB2B,OAAOF,KAEvB5B,EAMrB,OALA+B,QAAQC,sBAAsBN,EAASC,MACvC9B,EAAOM,EAAiBP,EAAS4B,GAAI,GACrCnB,IACAM,EAAsB,SACtBY,GAAe,IAMhBA,IAEHZ,EAAuBU,MAAYA,KAAQlB,IAAkBmB,QAC7DjB,UAIEU,EAAYkB,UACdhB,EAAagB,QAAUlB,EAAYkB,QAAQC,gBAG7CH,QAAQC,IAAI,qDACZrB,EAAuBU,MAAYA,KAAQlB,IAAkBmB,QAC7DjB,MAOJc,IACC,CAAChB,IAeJ,OATAe,oBAAU,KACJH,EAAYkB,SAAoC,OAAzBhB,EAAagB,UACtClB,EAAYkB,QAAQC,eAAiBjB,EAAagB,QAClDlB,EAAYkB,QAAQE,aAAelB,EAAagB,QAChDhB,EAAagB,QAAU,OAEtB,CAACvB,IAGDH,EAIAC,EAKH4B,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,IAAK,OAAQC,aAAc,SACxDN,IAAAC,cAAA,UACEM,QAASA,KACP9C,EAAOa,EAAoB,CAAEU,SAAU,IAAM,GAC7Cf,IACAM,EAAsB,KAExB4B,MAAO,CACLK,gBAAiB,qBACjBC,MAAO,QACPC,OAAQ,OACRC,QAAS,YACTC,aAAc,MACdC,OAAQ,YAEX,mBAGDb,IAAAC,cAAA,UACEM,QA9GoBO,IAAMpC,EAAmBO,IAAUA,GA+GvDkB,MAAO,CACLK,gBAAiB,QACjBC,MAAO,OACPC,OAAQ,OACRC,QAAS,YACTC,aAAc,MACdC,OAAQ,YAGTpC,EAAkB,kBAAoB,mBAEzCuB,IAAAC,cAAA,UACEM,QA1HqBQ,KAC3B9C,IACAM,EAAsB,KAyHhB4B,MAAO,CACLK,gBAAiB,QACjBC,MAAO,OACPC,OAAQ,OACRC,QAAS,YACTC,aAAc,MACdC,OAAQ,YAEX,qBAIFpC,GACCuB,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTY,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXT,OAAQ,iBACRC,QAAS,SAGXX,IAAAC,cAAA,YACED,IAAAC,cAAA,cAAQ,cAAmB,IAAE/B,EAAY,KAAO,OAElD8B,IAAAC,cAAA,YACED,IAAAC,cAAA,cAAQ,gBAGXjC,GACCgC,IAAAC,cAAA,OAAKE,MAAO,CAAEM,MAAO,OAAQW,UAAW,SAAUd,aAAc,QAC7DtC,GAGHgC,IAAAC,cAAA,YACEoB,IAAK1C,EACL2C,MAAOhD,EACPiD,SA/FsBC,IAC9BjD,EAAsBiD,EAAEC,OAAOH,QA+FvBnB,MAAO,CACLK,gBAAiB,qBACjBC,MAAO,QACPiB,MAAO,OACPR,OAAQ,QACRR,OAAQ,iBACRC,QAAS,MACTgB,OAAQ,YArFX3B,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uBClEA2B,MAtCIrE,IAAqG,IAApGsE,UAAEA,EAASC,SAAEA,EAAQC,YAAEA,EAAc,IAAGC,WAAEA,EAAa,IAAGC,YAAEA,EAAc,GAAEC,WAAEA,EAAa,IAAI3E,EAEjH,MAAM2D,EAASW,EAAYE,EAAcE,EACnCP,EAAQG,EAAYG,EAAaE,EAEvC,OACElC,IAAAC,cAAA,OAAKkC,UAAU,MAAMhC,MAAO,CAAEC,QAAS,OAAQY,cAAe,SAAUoB,WAAY,WAElFpC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQiC,eAAgB,SAAUX,MAAO,SAC7DI,IACCA,EAASQ,cAAcC,SAAS,QAC9BvC,IAAAC,cAAA,SACEE,MAAO,CAAEqC,SAAU,OAAQ5B,aAAc,MAAO6B,UAAW,SAC3DvB,OAAQA,EACRQ,MAAOA,EACPgB,SAAUb,EACVc,UAAQ,EACRC,MAAM,EACNC,OAAK,GAEL7C,IAAAC,cAAA,UAAQ6C,IAAKhB,EAAUiB,KAAK,cAAc,gDAI5C/C,IAAAC,cAAA,OACE6C,IAAKhB,EACLZ,OAAQA,EACRQ,MAAOA,EACPvB,MAAO,CAAEqC,SAAU,OAAQ5B,aAAc,MAAO6B,UAAW,SAC3DO,IAAI,4BClBpB,IAEIC,EAAW,GAgqBAC,MA7pBSC,IAAU,IAAAC,EAChC,MAAMC,IAAEA,EAAGC,OAAEA,EAAS,IAAOH,GACvB3F,SACJA,EAAQ0D,OACRA,EAAMQ,MACNA,EAAK6B,WACLA,EAAUC,WACVA,EAAU7F,iBACVA,EAAgB8F,WAChBA,EAAUC,QACVA,EAAOC,YACPA,EAAWC,WACXA,EAAUC,UACVA,EAASC,YACTA,EAAWC,cACXA,EAAaC,eACbA,EAAcC,cACdA,GACEX,GACGxB,EAAUoC,GAAe1F,mBAAS8E,EAAOM,aACzCO,EAAeC,GAAoB5F,mBAAS8E,EAAOM,aAEnDS,EAASC,GAAc9F,mBAAS,KAChC+F,EAASC,GAAchG,mBAAS,KAChCd,EAAkB+G,GAAuBjG,oBAAS,IAElDkG,EAAcC,GAAmBnG,oBAAS,IAC1CoG,EAAcC,GAAmBrG,oBAAS,IAC1CsG,EAAYC,GAAiBvG,mBAAS,KACtCZ,EAAeoH,GAAoBxG,oBAAS,IAC5CyG,EAAUC,GAAyB1G,oBAAS,IAC5CN,EAAWiH,GAAgB3G,oBAAS,IAEpC4G,EAAmBC,GAAwB7G,oBAAS,IAGpDX,EAAcyH,GAAmB9G,oBAAS,IAC1CV,EAAgByH,GAAqB/G,oBAAS,IAC9CgH,GAAcC,IAAmBjH,oBAAS,IAE1CkH,GAAqBC,IAAmBnH,mBAAS8E,EAAOU,gBACzD4B,GAAWhH,iBAAO,IAMlBiH,IALgBjH,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBkH,GAAoBC,IAAyBvH,oBAAS,IACtDwH,GAAYC,IAAiBzH,mBAAS,kBACtC0H,GAAmBC,IAAwB3H,mBAAS,cAEpDqD,GAAWuE,IAAgB5H,oBAAS,IACpC6H,GAAiBC,IAAsB9H,mBAAS,KAQhD+H,GAAaC,IAAkBhI,mBAAS,GAGvCiI,GAAoBA,KACF,qBAAXC,QACPF,GAAeE,OAAOC,aAK9B7H,oBAAU,KACN2H,MACD,IAEH3H,oBAAU,KACJ8E,GAEFgD,GAAehD,IAEhB,CAACA,IAEJ,MAAMgD,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,OAAOnD,IAAYoD,IAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBP,EAASQ,MAC/CpD,EAAYiD,GACZ/C,EAAiB6C,GACjB,MAAOM,GACP5H,QAAQ4H,MAAM,6BAA8BA,KAM1CC,GAAgBA,KACpBrC,GAAa,GACbsC,IAAkBD,gBAClB7H,QAAQC,IAAI,mCAAoC1B,IAG5CwJ,GAAqBA,KACzBvC,GAAa,GACbsC,IAAkBE,eAAe,CAC/BC,YAAY,EACZC,SAAU,WAmBhB/I,oBAAU,KACJZ,EACFyB,QAAQC,IAAI,yBAEZD,QAAQC,IAAI,0BAEb,CAAC1B,IAGF,MA6IMT,GAASoJ,MAAOiB,EAAKC,EAAShF,KAClCuB,OAAgByD,EAAkB,SAAW,YAAMD,MACnD,MAAME,EAAO,IAAI/E,EAAU,CAAEgF,KAAMH,IACnCtD,EAAW,IAAIwD,IACf,IACErI,QAAQC,IAAI,wBAAyBmI,GACrC/C,GAAiB,GACjBwC,KAEA,MAAMU,EAAO,CACXC,YAAapF,EACbW,QAASA,EACTsE,KAAMA,EACNpE,WAAYO,EACZiE,UAAWxC,GAAS/F,QACpB8D,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdjG,eAAeA,EACf4H,oBAAoBA,GACpB2C,iBAAkBhC,IAEpB1G,QAAQC,IAAI,OACZ,MAAM0H,KAAEA,SAAeP,IAAMuB,KAAKjF,EAAK6E,GAYvC,GAXAvI,QAAQC,IAAI,YAAa0H,EAAMY,GAC3BZ,EAAiB,YAAKA,EAAiB,aAAMnD,GAC/CyC,GAAeU,EAAiB,YAElC9C,EAAW8C,EAAW,MACtBrE,EAAW,IAAIqE,EAAW,MAEtBzB,GAAShG,SACXgG,GAAShG,QAAQ0I,QAGfjB,EAAiB,WAAG,CACtB,MAAMkB,KAAwB3E,IAAYyD,EAAiB,aAC3DzB,GAAShG,QAAU,IAAI4I,MAAMD,GAE7B,UACU3C,GAAShG,QAAQ6I,OAGvBxD,GAAsB,GACtBiB,GAAqB,kBAGf,IAAIwC,QAASC,IACf/C,GAAShG,QAAQgJ,QAAU,MACvBlJ,QAAQC,IAAI,4BACZgJ,QAIV,MAAOrB,GACL5H,QAAQ4H,MAAM,wBAAyBA,GAC1C,QAEG1B,GAAShG,QAAU,KACnBqF,GAAsB,GACtBiB,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBjB,GAAsB,GACtBF,GAAiB,GAGjBP,EAAoB6C,EAAyB,oBAC7C3H,QAAQC,IAAI,qBAAsB0H,EAAyB,mBAAG5J,IAIlC,IAAxB4J,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD3H,QAAQC,IAAI,sBAAuB0H,EAAkB,aAErDZ,OAAOoC,SAASC,KAAOzB,EAAkB,aAGvCxB,GACFC,IAAsB,GAEG,GAAlBrI,GACPiC,QAAQC,IAAI,sCACZuG,GAAqB,sCAEdtI,EACTyH,GAAgB,GAEPE,KACP7F,QAAQC,IAAI,cACZ8H,MAIF,MAAOH,GACP5H,QAAQC,IAAI,6BAA8B2H,GAC1CvC,GAAiB,GACjBM,GAAgB,GAGlBmB,KACA9G,QAAQC,IAAI,kBAGRoJ,IAAmC,OAAXrF,QAAW,IAAXA,OAAW,EAAY,QAAZP,EAAXO,EAAasF,kBAAU,IAAA7F,OAAA,EAAvBA,EAAyB4F,wBAAyB,cAE1EE,gBADatF,EAAWuF,MAAM,KAAK,KAKzC,OAHAxJ,QAAQC,IAAI,iBAAkB9B,GAI5BkC,IAAAC,cAAAD,IAAAE,SAAA,KAEEF,IAAAC,cAAA,OAAKkC,UAAU,OACbnC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQY,cAAe,SAAUU,MAAO,SAE7D1B,IAAAC,cAAA,WAEED,IAAAC,cAAC2B,EAAY,CACXC,UAAWA,GACXC,SAAUA,EACVC,YAAa,IACbC,WAAY,IACZC,YAAa,GACbC,WAAY,MAKhBlC,IAAAC,cAAA,OAAKE,MAAO,CAAEiJ,KAAMvH,GAAY,EAAI,OAAQV,UAAW,OAAQF,UAAW,UACvEmE,GACCpF,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTY,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXT,OAAQ,iBACRC,QAAS,SAGV4D,EAAQ8E,IAAI,CAACC,EAAQC,IACpBvJ,IAAAC,cAAA,OACEuJ,IAAKD,EACLpH,UAAU,yBACVhC,MAAO,CACLG,aAAc,MACdK,QAAS,MACTC,aAAc,MACdF,OAAQ,iBACR+I,UAAW,iCAGbzJ,IAAAC,cAAA,OACEkC,UAAU,YACVhC,MAAO,CACLK,gBAAiB,UACjBkJ,UAAW,QACXC,WAAY,OACZhJ,QAAS,QAGVmD,EAAY,KAAE9D,IAAAC,cAAA,YAAOqJ,EAAOrB,OAE/BjI,IAAAC,cAAA,OACEkC,UAAU,0BACVhC,MAAO,CACLC,QAAS,OACTgC,WAAY,aACZ5B,gBAAiBwI,GACjBrI,QAAS,SAGVmB,GACC9B,IAAAC,cAAA,OAAKkC,UAAU,aAAahC,MAAO,CAAEyJ,YAAa,SAChD5J,IAAAC,cAAA,OAAK6C,IAAKhB,EAAUkB,IAAI,WAAW7C,MAAO,CAAEuB,MAAO,WAG/D1B,IAAAC,cAAA,OACEkC,UAAU,qBACVhC,MAAO,CAAEiJ,KAAM,EAAGS,UAAW,eAE5BP,EAAOQ,KACJ9J,IAAAC,cAAA,QAAM8J,wBAAyB,CAAEC,OAAQV,EAAOQ,QAChD9J,IAAAC,cAAA,QAAMkC,UAAU,mBAW3BqB,GACCxD,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAE8J,OAAQ,WACnBjK,IAAAC,cAAA,OAAKkC,UAAU,cACbnC,IAAAC,cAAA,SACEkC,UAAU,eACVY,KAAK,OACLmG,YAAaA,GACb5H,MAAOwD,EACPvD,SAhUW2I,IAEvBnF,EAAcmF,EAAMzI,OAAOH,OAG3ByE,IAAsB,IA4TVoE,UAzTW3I,IACT,UAAVA,EAAEgI,MACJ7J,QAAQC,IAAI,kBAAmBkF,GAC/BrH,GAAOqH,EAAY,CAAE9F,SAAU,CAAEQ,QAAS,KAAQ,GAClDuF,EAAc,SAyTR/E,IAAAC,cAAA,MAAIE,MAAO,CAAE8J,OAAQ,YAM3BjK,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQgK,UAAW,QAExCpK,IAAAC,cAAA,OAAKE,MAAO,CAAEiJ,KAAM,EAAGM,UAAW,WAChC1J,IAAAC,cAAA,UACEE,MAAO,CACLkK,SAAU,OACV1J,QAAS,MACTsJ,OAAQ,QACRzJ,gBAAiB3C,EAAe,UAAW,qBAC3C4C,MAAO,QACPC,OAAQ,oBACRE,aAAc,MACdC,OAAQ,UACRa,MAAO,OAETnB,QArPiB+J,KACzBhF,GAAgB,GACXpH,GACHwJ,KAEFzB,GAAc,gBACdtG,QAAQC,IAAI,iCACZD,QAAQC,IAAI/B,KAgPHmI,KAMLhG,IAAAC,cAAA,OAAKE,MAAO,CAAEiJ,KAAM,EAAGM,UAAW,WAChC1J,IAAAC,cAAA,UACEE,MAAO,CACLkK,SAAU,OACV1J,QAAS,MACTsJ,OAAQ,QACRzJ,gBAAiBgF,GAAe,oBAAqB,qBACrD/E,MAAO,QACPC,OAAQ,oBACRE,aAAc,MACdC,OAAQ,UACRa,MAAO,OAETnB,QAlaOgK,KACjB5K,QAAQC,IAAI,aAAc1B,GACrBA,GAKHyB,QAAQC,IAAI,yBACZ6F,IAAgB,GAChB+B,OANA7H,QAAQC,IAAI,yBACZ6F,IAAgB,GAChBiC,QA+ZSlC,GAAe,mBAAqB,sBAGtCtH,GACe8B,IAAAC,cAAA,OACEE,MAAO,CACLuB,MAAO,MACPR,OAAQ,OACRsJ,gBAAiB,wDACjBC,UAAW,wBACXL,UAAW,QAGbpK,IAAAC,cAAA,OAAKE,MAAO,CAAEkK,SAAU,OAAQ5J,MAAO,UAAYyF,KAIpEjB,GACCjF,IAAAC,cAAA,OACEE,MAAO,CAELe,OAAQ,OACRwJ,WAAY,uDACZD,UAAW,4BACXL,UAAW,MACXxJ,aAAc,SAGhBZ,IAAAC,cAAA,OAAKE,MAAO,CAAEkK,SAAU,OAAQ5J,MAAO,UAAW,cAQxDT,IAAAC,cAAA,OAAKE,MAAO,CAAEiJ,KAAM,EAAGM,UAAW,WAChC1J,IAAAC,cAAA,UACEE,MAAO,CACLkK,SAAU,OACV1J,QAAS,MACTsJ,OAAQ,QACRzJ,gBAAiB1C,EAAiB,qBAAsB,qBACxD2C,MAAO,QACPC,OAAQ,oBACRE,aAAc,MACdC,OAAQ,UACRa,MAAO,OAETnB,QA/bYoK,KAEpBpF,GADIzH,KAgcKA,EAAiB,eAAiB,iBAEpCA,GACCkC,IAAAC,cAAA,OACEE,MAAO,CACLuB,MAAO,MACPR,OAAQ,OACRsJ,gBAAiB,0DACjBC,UAAW,wBACXL,UAAW,QAGbpK,IAAAC,cAAA,OAAKE,MAAO,CAAEkK,SAAU,OAAQ5J,MAAO,UAAW,sBAQ3DmK,MAAMC,QAAQ5G,IAAkBA,EAAc5E,OAAS,GACtDW,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACT0K,SAAU,OACVzI,eAAgB,SAChB+H,UAAW,MACX/J,IAAK,QAGN4D,EAAcoF,IAAI,CAAC0B,EAAQxB,KAC1B,MAAMyB,EAAW3E,GAAgB4E,SAASF,GAC1C,OACE/K,IAAAC,cAAA,UACEuJ,IAAKD,EACLhJ,QAASA,KAEL+F,GADE0E,EACiB3E,GAAgB6E,OAAQC,GAAMA,IAAMJ,GAEpC,IAAI1E,GAAiB0E,KAG5C5K,MAAO,CACLkK,SAAU,OACV1J,QAAS,WACTH,gBAAiBwK,EAAW,UAAY,UACxCvK,MAAOuK,EAAW,QAAU,QAC5BtK,OAAQ,oBACRE,aAAc,MACdC,OAAQ,YAGTkK,MASP/K,IAAAC,cAAA,OAAKkC,UAAU,MAAMhC,MAAO,CAAEG,aAAc,SAC1CN,IAAAC,cAAC3C,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,EAChBI,UAAWA,QChpBRkN,kBAVDjI,IACZ,MAAME,IAAEA,EAAGC,OAAEA,GAAWH,EAAMkI,KAE9B,OADAvM,oBAAU,IAAMwM,IAAUC,kBAExBvL,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACuL,EAAQ,CAACnI,IAAKA,EAAKC,OAAQA,uCCLlC,MAAMmI,EAAS,IAAIC,IAGnBC,IAASC,OACP5L,IAAAC,cAACD,IAAM6L,WAAU,KACf7L,IAAAC,cAAC6L,IAAiB,CAACxK,MAAOmK,GACxBzL,IAAAC,cAAC8L,IAAa,CAACC,MAAOC,KACpBjM,IAAAC,cAACiM,EAAI,SAIXC,SAASC,eAAe","file":"static/js/main.0f22dcdf.chunk.js","sourcesContent":["import React, { useState, useEffect, useRef } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  apiInProgress = false,\n  listenButton = false,\n  session_listen = false,\n}) => {\n  const {\n    finalTranscript,\n    interimTranscript,\n    resetTranscript,\n    listening,\n    browserSupportsSpeechRecognition,\n    isMicrophoneAvailable,\n  } = useSpeechRecognition();\n\n  const [editableTranscript, setEditableTranscript] = useState(\"\"); // State for editable transcript\n  const [show_transcript, setShowTranscript] = useState(true);\n\n  const showTranscript_func = () => setShowTranscript((prev) => !prev);\n  const clearTranscript_func = () => {\n    resetTranscript();\n    setEditableTranscript(\"\"); // Clear editable transcript\n  };\n  const textareaRef = useRef(null);\n  const cursorPosRef = useRef(null);\n  // Logic to process transcript based on session_listen\n  const processTranscript = () => {\n    if (finalTranscript !== \"\") {\n      // console.log(\"Listening?\", listening);\n      // console.log(\"listenAfterReply:\", listenAfterReply);\n      // console.log(\"session_listen:\", session_listen);\n      // console.log(\"apiInProgress:\", apiInProgress);\n  \n      if (listenButton) {\n      // When session_listen is false and not using listenButton, just append\n      myFunc(finalTranscript, { api_body: {} }, 5);\n      setEditableTranscript((prev) => `${prev} ${finalTranscript}`.trim());\n      resetTranscript();\n      setEditableTranscript(\"\");\n      return;\n      }\n\n\n      if (session_listen) {\n        // Check for keywords only when session_listen is true\n        let keywordFound = false;\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n  \n            if (isKeywordFound && !apiInProgress) {\n              console.log(`Keyword found: ${keywords[j]}`);\n              myFunc(finalTranscript, commands[i], 1);\n              resetTranscript(); // Reset transcript after processing keyword\n              setEditableTranscript(\"\"); // Clear editable transcript state\n              keywordFound = true;\n              return;\n            }\n          }\n        }\n  \n        if (!keywordFound) {\n          // Append transcript if no keyword is found\n          setEditableTranscript((prev) => `${prev} ${finalTranscript}`.trim());\n          resetTranscript(); // Clear finalTranscript after appending\n        }\n      } else {\n        // When session_listen is false, focus on capturing speech-to-text\n        if (textareaRef.current) {\n          cursorPosRef.current = textareaRef.current.selectionStart;\n        }\n\n        console.log(\"Recording speech-to-text without keyword triggers\");\n        setEditableTranscript((prev) => `${prev} ${finalTranscript}`.trim());\n        resetTranscript(); // Clear finalTranscript after appending\n      }\n    }\n  };\n\n  // Use processTranscript in useEffect to handle updates\n  useEffect(() => {\n    processTranscript();\n  }, [finalTranscript]);\n\n  const handleTranscriptChange = (e) => {\n    setEditableTranscript(e.target.value); // Update editable transcript based on user input\n  };\n\n  useEffect(() => {\n    if (textareaRef.current && cursorPosRef.current !== null) {\n      textareaRef.current.selectionStart = cursorPosRef.current;\n      textareaRef.current.selectionEnd = cursorPosRef.current;\n      cursorPosRef.current = null;\n    }\n    }, [editableTranscript]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      <div style={{ display: \"flex\", gap: \"10px\", marginBottom: \"10px\" }}>\n        <button\n          onClick={() => {\n            myFunc(editableTranscript, { api_body: {} }, 5);\n            resetTranscript();\n            setEditableTranscript(\"\");\n          }}\n          style={{\n            backgroundColor: \"rgb(196, 230, 252)\",\n            color: \"black\",\n            border: \"none\",\n            padding: \"10px 20px\",\n            borderRadius: \"5px\",\n            cursor: \"pointer\",\n          }}\n        >\n          Send Transcript\n        </button>\n        <button\n          onClick={showTranscript_func}\n          style={{\n            backgroundColor: \"white\",\n            color: \"grey\",\n            border: \"none\",\n            padding: \"10px 20px\",\n            borderRadius: \"5px\",\n            cursor: \"pointer\",\n          }}\n        >\n          {show_transcript ? \"Hide Transcript\" : \"Show Transcript\"}\n        </button>\n        <button\n          onClick={clearTranscript_func}\n          style={{\n            backgroundColor: \"white\",\n            color: \"grey\",\n            border: \"none\",\n            padding: \"10px 20px\",\n            borderRadius: \"5px\",\n            cursor: \"pointer\",\n          }}\n        >\n          Clear Transcript\n        </button>\n      </div>\n      {show_transcript && (\n        <div\n          style={{\n            display: \"flex\",\n            flexDirection: \"column\",\n            maxHeight: \"800px\",\n            height: \"550px\",\n            overflowY: \"auto\",\n            border: \"1px solid #ccc\",\n            padding: \"10px\",\n          }}\n        >\n          <span>\n            <strong>Listening:</strong> {listening ? \"on\" : \"off\"}\n          </span>\n          <span>\n            <strong>Transcript:</strong>\n          </span>\n      {/* Live preview of interim transcript */}\n        {interimTranscript && (\n          <div style={{ color: \"#888\", fontStyle: \"italic\", marginBottom: \"8px\" }}>\n            {interimTranscript}\n          </div>\n        )}\n          <textarea\n            ref={textareaRef}\n            value={editableTranscript}\n            onChange={handleTranscriptChange}\n            style={{\n              backgroundColor: \"rgb(238, 242, 245)\",\n              color: \"black\",\n              width: \"100%\",\n              height: \"550px\",\n              border: \"1px solid #ccc\",\n              padding: \"5px\",\n              resize: \"none\",\n            }}\n          />\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;","import React from 'react';\n\nconst MediaDisplay = ({ showImage, imageSrc, largeHeight = 100, largeWidth = 100, smallHeight = 40, smallWidth = 40 }) => {\n    // Determine the dimensions based on `showImage` status\n    const height = showImage ? largeHeight : smallHeight;\n    const width = showImage ? largeWidth : smallWidth;\n  \n    return (\n      <div className=\"p-2\" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center' }}>\n        {/* Always show the image or video at the top center based on `showImage` */}\n        <div style={{ display: 'flex', justifyContent: 'center', width: '100%' }}>\n          {imageSrc && (\n            imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                height={height}\n                width={width}\n                controls={showImage} // Only show controls if `showImage` is true\n                autoPlay\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img\n                src={imageSrc}\n                height={height}\n                width={width}\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                alt=\"Media Preview\"\n              />\n            )\n          )}\n        </div>\n      </div>\n    );\n  };\n  \n  export default MediaDisplay;","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\n// import { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\nimport MediaDisplay from \"./MediaDisplay\";\nimport './spinner.css';\nimport ReactMarkdown from 'react-markdown';\n\n// import Dictaphone_ss from \"./Dictaphone_ss\";\n// import * as faceapi from \"@vladmandic/face-api\";\n// import DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n    agent_actions,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progresslistening\n  const [listening, setlistening] = useState(false); // Added state for API in progress\n\n  const [show_conversation, setshow_conversation] = useState(true); // Added state for API in progress\n  \n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n  const [convo_button, setconvo_button] = useState(false); // Added state for API in progress\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n  const [selectedActions, setSelectedActions] = useState([]);\n\n  \n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  const [windowWidth, setWindowWidth] = useState(0); // Initial value\n\n    // Create a reusable function for getting the window width\n    const updateWindowWidth = () => {\n      if (typeof window !== 'undefined') {\n          setWindowWidth(window.innerWidth);\n      }\n  };\n\n  // Call the function on component mount to set the initial window width\n  useEffect(() => {\n      updateWindowWidth();\n  }, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n\n\n  const stopListening = () => {\n    setlistening(false);\n    SpeechRecognition.stopListening();\n    console.log(\"Stopping Listening, isListening=\", listening)\n  }\n\n  const listenContinuously = () =>{\n    setlistening(true)\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n\n}\n\n\nconst convo_mode = () => {\n  console.log(\"listening?\", listening);\n  if (!listening) {\n    console.log(\"Starting to listen...\");\n    setconvo_button(true)\n    listenContinuously();\n  } else {\n    console.log(\"Stopping listening...\");\n    setconvo_button(false)\n    stopListening();\n  }\n};\n\nuseEffect(() => {\n  if (listening) {\n    console.log(\"Listening has started\");\n  } else {\n    console.log(\"Listening has stopped\");\n  }\n}, [listening]);\n\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  // useEffect(() => {\n  //   const loadModels = async () => {\n  //     const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n  //     Promise.all([\n  //       faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n  //     ]).then(() => setModelsLoaded(true));\n  //   };\n  //   loadModels();\n  //   const interval = setInterval(() => {\n  //     // console.log(\"faceData.current :>> \", faceData.current);\n  //   }, 3000);\n  //   return () => clearInterval(interval);\n  // }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  // const startVideo = () => {\n  //   setCaptureVideo(true);\n  //   navigator.mediaDevices\n  //     .getUserMedia({ video: { width: 300 } })\n  //     .then((stream) => {\n  //       let video = videoRef.current;\n  //       video.srcObject = stream;\n  //       video.play();\n  //     })\n  //     .catch((err) => {\n  //       console.error(\"error:\", err);\n  //     });\n  // };\n\n  // const handleVideoOnPlay = () => {\n  //   setInterval(async () => {\n  //     if (canvasRef && canvasRef.current) {\n  //       canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n  //         videoRef.current\n  //       );\n  //       const displaySize = {\n  //         width: videoWidth,\n  //         height: videoHeight,\n  //       };\n\n  //       faceapi.matchDimensions(canvasRef.current, displaySize);\n\n  //       const detections = await faceapi\n  //         .detectAllFaces(\n  //           videoRef.current,\n  //           new faceapi.TinyFaceDetectorOptions()\n  //         )\n  //         .withFaceLandmarks()\n  //         .withFaceExpressions();\n\n  //       const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n  //       if (resizedDetections.length > 0) {\n  //         faceData.current = resizedDetections;\n  //         if (!faceTriggered.current && face_recon) {\n  //           myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n  //           faceTriggered.current = true;\n  //         }\n  //       } else {\n  //         faceTimer && clearTimeout(faceTimer);\n  //         setTimeout(() => {\n  //           faceData.current = [];\n  //         }, 1000);\n  //       }\n\n  //       if (resizedDetections.length > 0 && !firstFace) {\n  //         firstFace = true;\n  //         if (kwargs.hello_audio) {\n  //           const audio = new Audio(kwargs.hello_audio);\n  //           audio.play();\n  //         }\n  //       }\n\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         canvasRef.current\n  //           .getContext(\"2d\")\n  //           .clearRect(0, 0, videoWidth, videoHeight);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceExpressions(\n  //           canvasRef.current,\n  //           resizedDetections\n  //         );\n  //     }\n  //   }, 300);\n  // };\n\n  // const closeWebcam = () => {\n  //   videoRef.current.pause();\n  //   videoRef.current.srcObject.getTracks()[0].stop();\n  //   setCaptureVideo(false);\n  // };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    if (!listening) {\n      listenContinuously()\n    }\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n        selected_actions: selectedActions,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"], listenAfterReply);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n\n      if (UserUsedChatWindow) {\n        setUserUsedChatWindow(false)\n      }\n      else if (listenAfterReply==true) {\n        console.log(\"API END HIT listenAfterReply==TRUE\")\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (convo_button){\n        console.log(\"convo mode\")\n        listenContinuously()\n      }\n\n      \n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n\n    updateWindowWidth();\n    console.log(\"ReSize Window\")\n  };\n  \n  const background_color_chat = refresh_ask?.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n  console.log(\"session_listen\", session_listen)\n\n\n  return (\n    <>\n\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'column', width: '100%' }}>\n          {/* Image or video section */}\n          <div>\n            {/* Media Display */}\n            <MediaDisplay\n              showImage={showImage}\n              imageSrc={imageSrc}\n              largeHeight={100}   // Customize as needed\n              largeWidth={100}    // Customize as needed\n              smallHeight={40}    // Customize as needed\n              smallWidth={40}     // Customize as needed\n            />\n          </div>\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '350px' }}>\n            {show_conversation && (\n              <div\n                style={{\n                  display: 'flex',\n                  flexDirection: 'column',\n                  maxHeight: '350px',\n                  height: '350px',\n                  overflowY: 'auto',\n                  border: '1px solid #ccc',\n                  padding: '10px',\n                }}\n              >\n                {answers.map((answer, idx) => (\n                  <div\n                    key={idx}\n                    className=\"chat-message-container\"\n                    style={{\n                      marginBottom: '5px',\n                      padding: '5px',\n                      borderRadius: '4px',\n                      border: '1px solid #ccc',\n                      boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',\n                    }}\n                  >\n                    <div\n                      className=\"chat-user\"\n                      style={{\n                        backgroundColor: '#e4eafe',\n                        textAlign: 'right',\n                        marginLeft: 'auto',\n                        padding: '5px',\n                      }}\n                    >\n                      {client_user}: <span>{answer.user}</span>\n                    </div>\n                    <div\n                      className=\"chat-response-container\"\n                      style={{\n                        display: 'flex',\n                        alignItems: 'flex-start',\n                        backgroundColor: background_color_chat,\n                        padding: '10px',\n                      }}\n                    >\n                      {imageSrc && (\n                        <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                          <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} />\n                        </div>\n                      )}\n              <div\n                className=\"chat-response-text\"\n                style={{ flex: 1, wordBreak: 'break-word' }}\n              >\n                {answer.resp\n                  ? <span dangerouslySetInnerHTML={{ __html: answer.resp }} />\n                  : <span className=\"spinner\" />}\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n    )}\n  </div>\n</div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '3px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n\n            </div>\n            <hr style={{ margin: '3px 0' }} />\n          </>\n        )}\n\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '3px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: listenButton ? '#478728': \"rgb(196, 230, 252)\",\n              color: 'black',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: convo_button ? \"rgb(87, 188, 100)\": \"rgb(196, 230, 252)\",\n              color: 'black',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={convo_mode}\n          >\n            {convo_button ? \"End Conversation\" : \"Start Conversation\"}\n          </button>\n          \n          {listening && (\n                          <div\n                            style={{\n                              width: '89%',\n                              height: '10px',\n                              backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                              animation: 'flashLine 1s infinite',\n                              marginTop: '5px',\n                            }}\n                          >\n                            <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n                          </div>\n                        )}\n\n          {speaking && (\n            <div\n              style={{\n                // width: '89%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            \n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: session_listen ? \"rgb(250, 234, 131)\": \"rgb(196, 230, 252)\",\n              color: 'black',\n              border: '1px solid #2980b9',\n              borderRadius: '1px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={listenSession}\n          >\n            {session_listen ? \"Stop Session\" : \"Start Session\"}\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n      </div>\n\n    {/* Agent Actions Horizontal Button-Style Multi-Select */}\n    {Array.isArray(agent_actions) && agent_actions.length > 0 && (\n      <div\n        style={{\n          display: 'flex',\n          flexWrap: 'wrap',\n          justifyContent: 'center',\n          marginTop: '8px',\n          gap: '6px',\n        }}\n      >\n        {agent_actions.map((action, idx) => {\n          const selected = selectedActions.includes(action);\n          return (\n            <button\n              key={idx}\n              onClick={() => {\n                if (selected) {\n                  setSelectedActions(selectedActions.filter((a) => a !== action));\n                } else {\n                  setSelectedActions([...selectedActions, action]);\n                }\n              }}\n              style={{\n                fontSize: '12px',\n                padding: '5px 10px',\n                backgroundColor: selected ? '#1abc9c' : '#ecf0f1',\n                color: selected ? 'white' : 'black',\n                border: '1px solid #bdc3c7',\n                borderRadius: '4px',\n                cursor: 'pointer',\n              }}\n            >\n              {action}\n            </button>\n          );\n        })}\n      </div>\n    )}\n\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\" style={{ marginBottom: '15px' }}>\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n            listening={listening}\n          />\n        </div>\n  \n\n      </div>\n\n\n\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}