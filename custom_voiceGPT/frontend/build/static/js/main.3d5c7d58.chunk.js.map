{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","show_conversation","apiInProgress","listenButton","session_listen","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","i","timer","setTimeout","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","maxHeight","overflowY","border","padding","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","height","width","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","imageSrc","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistenButton","setsession_listen","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","isListening","setIsListening","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","showImage","setShowImage","handleResize","setWindowWidth","window","innerWidth","addEventListener","removeEventListener","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","Streamlit","setFrameHeight","intervalId","setInterval","SpeechRecognition","browserSupportsContinuousListening","listenContinuously","clearInterval","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","ret","command","type","text","user","stopListening","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","location","href","resizeWindow","resizeBy","background_color_chat","color_dict","splitImage","placeholder","className","flex","toLowerCase","endsWith","maxWidth","controls","autoPlay","loop","muted","src","borderRadius","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","textAlign","marginLeft","dangerouslySetInnerHTML","__html","alignItems","marginRight","alt","resp","margin","value","onChange","event","target","onKeyDown","marginTop","fontSize","color","cursor","onClick","click_listenButton","backgroundImage","animation","background","listenSession","toggleShowImage","prevShowImage","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICsFVC,MA3FIC,IASZ,IATa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,kBACpBC,GAAoB,EAAI,cACxBC,GAAgB,EAAK,aACrBC,GAAe,EAAK,eACpBC,GAAe,GAChBR,EACC,MAAOS,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IAyD7C,OAvDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAO1B,GALAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAC1BO,QAAQC,IAAI,oBAAqBrB,GAG7BK,GAAkBM,EAAgBW,MAAM,KAAKC,OAAS,IAIxD,OAHAH,QAAQC,IAAI,8BACZtB,EAAOY,EAAiBb,EAAS0B,GAAI,QACrCZ,IAIF,GAAoB,GAAhBP,GAAyBM,EAAgBW,MAAM,KAAKC,OAAS,IAG/D,OAFAH,QAAQC,IAAI,wFACZT,IAKFM,EAAcP,GAGd,MAAMc,EAAQC,WAAW,KACvB,IAAK,IAAIF,EAAI,EAAGA,EAAI1B,EAASyB,OAAQC,IAAK,CACxC,MAAM,SAAEG,EAAQ,SAAEC,GAAa9B,EAAS0B,GACxC,IAAK,IAAIK,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,IAAKE,GAAkBhC,GAAoBI,KAAkBD,EAU3D,OATIH,EACFD,EAAOY,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACTjC,EAAOY,EAAiBb,EAAS0B,GAAI,GAE9BpB,GACPL,EAAOY,EAAiBb,EAAS0B,GAAI,QAEvCZ,KAMNQ,QAAQC,IAAI,gDACQ,IAAnBpB,GAEH,MAAO,IAAMiC,aAAaT,KAE3B,CAACd,EAAiBX,EAAkBF,EAAUG,EAAkBW,EAAiBT,EAAeC,IAG9FU,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGnC,GACGiC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SAClIT,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,SARpCsB,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,aCjEjB,IAEIS,EAAW,GA0oBAC,MAvoBSC,IAAW,IAADC,EAChC,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOH,GACvB,SACJjD,EAAQ,OACRqD,EAAM,MACNC,EAAK,kBACLlD,EAAiB,WACjBmD,EAAU,WACVC,EAAU,iBACVrD,EAAgB,WAChBsD,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,EAAa,eACbC,GACEZ,GACGa,EAAUC,GAAexD,mBAAS0C,EAAOQ,aACzCO,EAAeC,GAAoB1D,mBAAS0C,EAAOQ,aAEnDS,EAASC,GAAc5D,mBAAS,KAChC6D,EAASC,GAAc9D,mBAAS,KAChCR,EAAkBuE,GAAuB/D,oBAAS,IAElDgE,EAAcC,GAAmBjE,oBAAS,IAC1CkE,EAAcC,GAAmBnE,oBAAS,IAC1CoE,EAAYC,GAAiBrE,mBAAS,KACtCL,EAAe2E,GAAoBtE,oBAAS,IAC5CuE,EAAUC,GAAyBxE,oBAAS,IAE5CJ,EAAc6E,GAAmBzE,oBAAS,IAC1CH,EAAgB6E,GAAqB1E,oBAAS,IAE9C2E,EAAqBC,GAAmB5E,mBAAS0C,EAAOY,gBACzDuB,EAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBE,GAAaC,IAAkBjF,oBAAS,IACxCkF,GAAoBC,IAAyBnF,oBAAS,IAEtDoF,GAAYC,IAAiBrF,mBAAS,kBACtCsF,GAAmBC,IAAwBvF,mBAAS,cAEpDwF,GAAWC,IAAgBzF,oBAAS,GAM3CW,oBAAU,KACR,MAAM+E,EAAeA,KAEjBC,eAAeC,OAAOC,aAG1B,OADAD,OAAOE,iBAAiB,SAAUJ,GAC3B,IAAME,OAAOG,oBAAoB,SAAUL,IACnD,IAED/E,oBAAU,KACJuC,GAEF8C,GAAe9C,IAEhB,CAACA,IAEJ,MAAM8C,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAIlD,GAASkD,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/CnD,EAAYgD,GACZ9C,EAAiB4C,GACjB,MAAOM,OACPhG,QAAQgG,MAAM,6BAA8BA,SAYhDjG,oBAAU,KACRkG,IAAUC,iBAGV,MAAMC,EAAaC,YAAY,KACxBC,IAAkBC,uCAErBtG,QAAQC,IAAI,iCAAkC+F,OAC9CO,OAED,KAEH,MAAO,KACLC,cAAcL,KAEf,IAEH,MAqBMI,GAAqBA,KACrBnC,GACFC,IAAe,IAGjBgC,IAAkBI,eAAe,CAC/BC,YAAY,EACZC,SAAU,UAEZtC,IAAe,KAajBtE,oBAAU,KACWsF,WAGjBuB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAMjE,GAAgB,KAEhCkE,GACA,MAAMC,EAAWpB,YAAY,OAE1B,KACH,MAAO,IAAMI,cAAcgB,IAC1B,IAoHH,MAAM7I,GAAS0G,MAAOoC,EAAKC,EAASC,KAClC3E,EAAW,KAADyC,OAAMiC,EAAkB,SAAW,QAAC,MAAAjC,OAAKgC,EAAG,MACtD,MAAMG,EAAO,IAAInG,EAAU,CAAEoG,KAAMJ,IACnCvE,EAAW,IAAI0E,IACf,IACE5H,QAAQC,IAAI,wBAAyByH,GACrChE,GAAiB,GA5KnB2C,IAAkByB,gBAClBzD,IAAe,GACfrE,QAAQC,IAAI,mCAAoCmE,IA6K9C,MAAM2D,EAAO,CACXC,YAAaL,EACbvF,QAASA,EACTwF,KAAMA,EACNtF,WAAYO,EACZoF,UAAWhE,EAASiE,QACpB7F,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdxD,eAAeA,EACf8E,oBAAoBA,GAEtB/D,QAAQC,IAAI,OACZ,MAAM,KAAE8F,SAAeR,IAAM4C,KAAKtG,EAAKkG,GAYvC,GAXA/H,QAAQC,IAAI,YAAa8F,EAAMgC,GAC3BhC,EAAiB,YAAKA,EAAiB,aAAMlD,GAC/CuC,GAAeW,EAAiB,YAElC7C,EAAW6C,EAAW,MACtBtE,EAAW,IAAIsE,EAAW,MAEtB5B,GAAS+D,SACX/D,GAAS+D,QAAQE,QAGfrC,EAAiB,WAAG,CACtB,MAAMsC,EAAkB,GAAA5C,OAAMlD,GAASkD,OAAGM,EAAiB,YAC3D5B,GAAS+D,QAAU,IAAII,MAAMD,GAE7B,UACUlE,GAAS+D,QAAQK,OAGvB3E,GAAsB,GACtBe,GAAqB,kBAGf,IAAIiC,QAASxI,IACf+F,GAAS+D,QAAQM,QAAU,KACvBxI,QAAQC,IAAI,4BACZ7B,OAIV,MAAO4H,OACLhG,QAAQgG,MAAM,wBAAyBA,OAC1C,QAEG7B,GAAS+D,QAAU,KACnBtE,GAAsB,GACtBe,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBf,GAAsB,GACtBF,GAAiB,GAEjB1D,QAAQC,IAAI,kCAEZkD,EAAoB4C,EAAyB,oBAC7C/F,QAAQC,IAAI,qBAAsB8F,EAAyB,qBAI/B,IAAxBA,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD/F,QAAQC,IAAI,sBAAuB8F,EAAkB,aAErDf,OAAOyD,SAASC,KAAO3C,EAAkB,aAGrB,GAAlBnH,GAA2BI,GAAiBsF,GAIvCtF,EACT6E,GAAgB,GAEPS,GACPC,IAAsB,IAGtBgC,KACA5B,GAAqB,2BAXrB4B,KACA5B,GAAqB,sCAavB3E,QAAQC,IAAI,cAAemE,IAE3B,MAAO4B,OACPhG,QAAQC,IAAI,6BAA8B+F,OAC1CtC,GAAiB,GACjBG,GAAgB,KAIpB9D,oBAAU,KAER,MAAM4I,EAAeA,KACnB3D,OAAO4D,SAAS,EAAG,IAQrB,OAHA5D,OAAOE,iBAAiB,wBAAyByD,GAG1C,KACL3D,OAAOG,oBAAoB,wBAAyBwD,KAErD,IAGH,MAAME,IAA8C,QAAtBjH,EAAAS,EAAYyG,kBAAU,IAAAlH,OAAA,EAAtBA,EAAwBiH,wBAAyB,cACzEE,GAAazG,EAAWpC,MAAM,KAAK,GACnC8I,GAAW,aAAAvD,OAAgBsD,IAEjC,OACEhI,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKiI,UAAU,OACblI,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,MAAOY,MAAO,SAEzD4C,IACC7D,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,IACjBvG,IACCA,EAASwG,cAAcC,SAAS,QAC9BrI,IAAAC,cAAA,SACEE,MAAO,CAAEmI,SAAU,QACnBtH,OAAQA,GAAU,IAClBC,MAAOA,GAAS,IAChBsH,UAAQ,EACRC,UAAQ,EACRC,MAAM,EACNC,OAAK,GAEL1I,IAAAC,cAAA,UAAQ0I,IAAK/G,EAAUgF,KAAK,cAAc,gDAI5C5G,IAAAC,cAAA,OAAK0I,IAAK/G,EAAUZ,OAAQA,GAAU,IAAKC,MAAOA,GAAS,IAAKd,MAAO,CAAEmI,SAAU,YAO3FtI,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAMtE,GAAY,EAAI,OAAQtD,UAAW,OAAQD,UAAW,UACzEvC,GACCiC,IAAAC,cAAA,OACEE,MAAO,CACLK,OAAQ,oBACRoI,aAAc,MACdrI,UAAW,OACXD,UAAW,QACXG,QAAS,SAGZyB,EAAQ2G,IAAI,CAACC,EAAQC,IACpB/I,IAAAC,cAAA,OACE+I,IAAKD,EACL5I,MAAO,CACL8I,aAAc,MACdxI,QAAS,MACTmI,aAAc,MACdpI,OAAQ,iBACR0I,UAAW,iCAIblJ,IAAAC,cAAA,OAAKiI,UAAU,YAAc/H,MAAO,CACFgJ,gBAAiB,UACjBC,UAAW,QACXC,WAAY,OACZ5I,QAAS,QAExCgB,EAAY,KAAEzB,IAAAC,cAAA,QAAMqJ,wBAAyB,CAAEC,OAAQT,EAAOhC,SAEjE9G,IAAAC,cAAA,OAAKiI,UAAU,YAAY/H,MAAO,CAAEC,QAAS,OAAQoJ,WAAY,aAAcL,gBAAiBrB,KAE9F9H,IAAAC,cAAA,OAAKiI,UAAU,aAAa/H,MAAO,CAAEsJ,YAAa,SAChDzJ,IAAAC,cAAA,OAAK0I,IAAK/G,EAAU8H,IAAI,WAAWvJ,MAAO,CAAEc,MAAO,UAAY,KAGjEjB,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,IAAK,IACvBnI,IAAAC,cAAA,QAAMqJ,wBAAyB,CAAEC,OAAQT,EAAOa,MAAQ,wBAWnExI,GACCnB,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAEyJ,OAAQ,YACnB5J,IAAAC,cAAA,OAAKiI,UAAU,cACblI,IAAAC,cAAA,SACEiI,UAAU,eACVtB,KAAK,OACLqB,YAAaA,GACb4B,MAAOpH,EACPqH,SAtUWC,IAEvBrH,EAAcqH,EAAMC,OAAOH,OAG3BrG,IAAsB,IAkUVyG,UA/TWhN,IACT,UAAVA,EAAE+L,MACJ/J,QAAQC,IAAI,kBAAmBuD,GAC/B7E,GAAO6E,EAAY,CAAEhD,SAAU,CAAEE,QAAS,KAAQ,GAClD+C,EAAc,SA8TR1C,IAAAC,cAAA,MAAIE,MAAO,CAAEyJ,OAAQ,aAK3B5J,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQ8J,UAAW,SAExClK,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,EAAGiB,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLgK,SAAU,OACV1J,QAAS,MACTmJ,OAAQ,QACRT,gBAAiB,UACjBiB,MAAO,QACP5J,OAAQ,oBACRoI,aAAc,MACdyB,OAAQ,WAEVC,QAxPiBC,KACzBzH,GAAgB,GAChB0C,KACA9B,GAAc,gBACdzE,QAAQC,IAAI,iCACZD,QAAQC,IAAIjB,KAqPHwF,IAEFJ,IACCrD,IAAAC,cAAA,OACEE,MAAO,CACLc,MAAO,OACPD,OAAQ,OACRwJ,gBAAiB,wDACjBC,UAAW,wBACXP,UAAW,QAGblK,IAAAC,cAAA,OAAKE,MAAO,CAAEgK,SAAU,OAAQC,MAAO,UAAYzG,MAMzD3D,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,EAAGiB,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLgK,SAAU,OACV1J,QAAS,MACTmJ,OAAQ,QACRT,gBAAiB,UACjBiB,MAAO,QACP5J,OAAQ,oBACRoI,aAAc,MACdyB,OAAQ,WAEVC,QAAS9E,IACV,uBAGA5C,GACC5C,IAAAC,cAAA,OACEE,MAAO,CACLc,MAAO,OACPD,OAAQ,OACR0J,WAAY,uDACZD,UAAW,4BACXP,UAAW,MACXtB,aAAc,SAGhB5I,IAAAC,cAAA,OAAKE,MAAO,CAAEgK,SAAU,OAAQC,MAAO,UAAW,cAMxDpK,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,EAAGiB,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLgK,SAAU,OACV1J,QAAS,MACTmJ,OAAQ,QACRT,gBAAiB,UACjBiB,MAAO,QACP5J,OAAQ,oBACRoI,aAAc,MACdyB,OAAQ,WAEVC,QA3bYK,KAEpB5H,GADI7E,KA2bG,mBAGAA,GACC8B,IAAAC,cAAA,OACEE,MAAO,CACLc,MAAO,OACPD,OAAQ,OACRwJ,gBAAiB,0DACjBC,UAAW,wBACXP,UAAW,QAGblK,IAAAC,cAAA,OAAKE,MAAO,CAAEgK,SAAU,OAAQC,MAAO,UAAW,qBAMxDpK,IAAAC,cAAA,OAAKE,MAAO,CAAEgI,KAAM,EAAGiB,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLgK,SAAU,OACV1J,QAAS,MACTmJ,OAAQ,QACRT,gBAAiB,UACjBiB,MAAO,QACP5J,OAAQ,oBACRoI,aAAc,MACdyB,OAAQ,WAEVC,QAvjBcM,KACtB9G,GAAc+G,IAAmBA,KAwjBxBhH,GAAY,aAAe,gBAMhC7D,IAAAC,cAAA,OAAKiI,UAAU,OACblI,IAAAC,cAACxC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,kBAAmBA,EACnBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,QCznBb4M,kBAVDlK,IACZ,MAAM,IAAEE,EAAG,OAAEC,GAAWH,EAAMmK,KAE9B,OADA/L,oBAAU,IAAMkG,IAAUC,kBAExBnF,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAC+K,EAAQ,CAAClK,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAMkK,EAAS,IAAIC,IAGnBC,IAASC,OACPpL,IAAAC,cAACD,IAAMqL,WAAU,KACfrL,IAAAC,cAACqL,IAAiB,CAACzB,MAAOoB,GACxBjL,IAAAC,cAACsL,IAAa,CAACC,MAAOC,KACpBzL,IAAAC,cAACyL,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.3d5c7d58.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  show_conversation = true,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n  session_listen=false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      // Add logs to check the conditions\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (session_listen && finalTranscript.split(\" \").length > 500000){\n        console.log(\"Transcript exceeds X words\");\n        myFunc(finalTranscript, commands[i], 6);\n        resetTranscript();\n        return;\n      }\n\n      if (session_listen==false && finalTranscript.split(\" \").length > 10000) {\n        console.log(\"Transcript exceeds 89 words. Clearing You really should call func-api to save .\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword or API is in progress\n        console.log(\"Waiting for a keyword or API is in progress\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n          <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"200px\", overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          {/* Add other conversation messages here */}\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progress\n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [isListening, setIsListening] = useState(false);\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  useEffect(() => {\n    const handleResize = () => {\n        // Trigger a re-render on resize to adjust layout\n        setWindowWidth(window.innerWidth);\n    };\n    window.addEventListener(\"resize\", handleResize);\n    return () => window.removeEventListener(\"resize\", handleResize);\n}, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n  const checkListeningStatus = () => {\n    // Check if continuous listening is active\n    if (!SpeechRecognition.browserSupportsContinuousListening()) {\n      // If not, restart continuous listening\n      startContinuousListening();\n    }\n  };\n\n  useEffect(() => {\n    Streamlit.setFrameHeight();\n\n    // Check listening status every minute\n    const intervalId = setInterval(() => {\n      if (!SpeechRecognition.browserSupportsContinuousListening()) {\n        // If continuous listening is not active, start it\n        console.log(\"LISTEN STOPPED TURNING BACK ON\", error);\n        listenContinuously();\n      }\n    }, 60000);\n\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  const startContinuousListening = () => {\n    // Start continuous listening\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n    setIsListening(true)\n  };\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n    setIsListening(false);\n    console.log(\"Stopping Listening, isListening=\", isListening)\n\n    \n  }\n  \n  const startListening = () => {\n    SpeechRecognition.startListening();\n  };\n\n  const listenContinuously = () =>{\n    if (isListening) {\n      setIsListening(false)\n    }\n    else {\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n    setIsListening(true)\n  }\n    }\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    listenContinuously()\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  function isHTML(str) {\n    return /^</.test(str);\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"]);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n      \n      if (listenAfterReply==true && !listenButton && !UserUsedChatWindow) {\n        listenContinuously()\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (UserUsedChatWindow){\n        setUserUsedChatWindow(false)\n      }\n      else {\n        listenContinuously()\n        setButtonName_listen(\"listeing for key word\")\n      }\n      \n      console.log(\"listing end\", isListening)\n\n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n  };\n\n  useEffect(() => {\n    // Function to resize the window\n    const resizeWindow = () => {\n      window.resizeBy(0, 1); // Resize the window by 1 pixel vertically\n    };\n\n    // Resize the window after the response finishes\n    // Replace `RESPONSE_FINISH_EVENT` with the event that indicates the response finished\n    window.addEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n\n    // Cleanup the event listener\n    return () => {\n      window.removeEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n    };\n  }, []); // Run only once after component mounts\n\n  \n  const background_color_chat = refresh_ask.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'row', width: '100%' }}>\n          {/* Image or video section */}\n          {showImage && (\n            <div style={{ flex: 1 }}>\n              {imageSrc && (\n                imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n                  <video\n                    style={{ maxWidth: '100%' }}\n                    height={height || 100}\n                    width={width || 100}\n                    controls\n                    autoPlay\n                    loop={false}\n                    muted\n                  >\n                    <source src={imageSrc} type=\"video/mp4\" />\n                    Your browser does not support the video tag.\n                  </video>\n                ) : (\n                  <img src={imageSrc} height={height || 100} width={width || 100} style={{ maxWidth: '100%' }} />\n                )\n              )}\n            </div>\n          )}\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '400px' }}>\n          {show_conversation && (\n            <div\n              style={{\n                border: '2px solid #2980b9', // Outer border\n                borderRadius: '6px', // Slightly round the corners of the outer border\n                overflowY: 'auto', // Enable vertical scrolling\n                maxHeight: '400px', // Set maximum height for scrolling\n                padding: '10px', // Add padding inside the outer border\n              }}\n            >\n            {answers.map((answer, idx) => (\n              <div\n                key={idx}\n                style={{\n                  marginBottom: '5px',\n                  padding: '5px',\n                  borderRadius: '4px',\n                  border: '1px solid #ccc', // Inner border for each message\n                  boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)', // Optional: add shadow for depth\n                  // backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2' // Background color if needed\n                }}\n              >\n                <div className=\"chat-user\"   style={{\n                                                  backgroundColor: '#f2f2f2',\n                                                  textAlign: 'right', // Align text to the right\n                                                  marginLeft: 'auto', // Push content to the right side\n                                                  padding: '5px', // Optional padding for spacing\n                                                }}>\n                  {client_user}: <span dangerouslySetInnerHTML={{ __html: answer.user }} />\n                </div>\n                <div className=\"chat-resp\" style={{ display: 'flex', alignItems: 'flex-start', backgroundColor: background_color_chat }}>\n                  {/* Displaying image on the left side */}\n                  <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                    <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} /> {/* Adjusted width */}\n                  </div>\n                  {/* Rendering the response text with HTML formatting */}\n                  <div style={{ flex: 1 }}> {/* Flex container to allow text wrapping */}\n                    <span dangerouslySetInnerHTML={{ __html: answer.resp || \"thinking...\" }} />\n                  </div>\n                </div>\n              </div>\n            ))}\n            </div>\n          )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '20px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '20px 0' }} />\n          </>\n        )}\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '10px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          {isListening && (\n            <div\n              style={{\n                width: '100%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={listenContinuously}\n          >\n            Conversational Mode\n          </button>\n          {speaking && (\n            <div\n              style={{\n                width: '100%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={listenSession}\n          >\n            Start A Session\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '100%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n        {/* Toggle Image Button */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={toggleShowImage}\n          >\n            {showImage ? \"Hide Image\" : \"Show Image\"}\n          </button>\n        </div>\n      </div>\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            show_conversation={show_conversation}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n          />\n        </div>\n  \n\n      </div>\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}