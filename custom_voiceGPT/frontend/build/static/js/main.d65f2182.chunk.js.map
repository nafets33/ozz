{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","noResponseTime","show_conversation","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","timer","setTimeout","i","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","g_anwers","firstFace","CustomVoiceGPT","props","api","kwargs","height","width","show_video","input_text","no_response_time","face_recon","api_key","refresh_ask","imageSrc","setImageSrc","self_image","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","faceData","useRef","faceTriggered","videoRef","canvasRef","audioRef","async","ret","command","type","concat","text","user","body","tigger_type","face_data","current","data","axios","post","pause","stopListening","Audio","play","onended","listenContinuously","window","location","reload","error","SpeechRecognition","startListening","continuous","language","Streamlit","setFrameHeight","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","then","loadModels","interval","setInterval","clearInterval","className","src","onClick","placeholder","value","onChange","target","onKeyDown","key","map","answer","idx","resp","textAlign","padding","closeWebcam","srcObject","getTracks","stop","cursor","backgroundColor","color","fontSize","border","borderRadius","startVideo","navigator","mediaDevices","getUserMedia","video","stream","catch","err","justifyContent","position","opacity","ref","onPlay","handleVideoOnPlay","innerHTML","displaySize","detections","withFaceLandmarks","withFaceExpressions","resizedDetections","hello_audio","getContext","clearRect","drawDetections","drawFaceLandmarks","drawFaceExpressions","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICyEVC,MA9EIC,IAMZ,IANa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAiB,EAAK,eACtBC,EAAiB,EAAC,kBAClBC,GAAoB,GACrBL,EACC,MAAOM,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IA+C7C,OA7CAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAQ1B,GAPAS,QAAQC,IAAI,oBAAqBV,GAGjCS,QAAQC,IAAI,oBAAqBlB,GACjCiB,QAAQC,IAAI,mBAAoBV,EAAgBW,MAAM,KAAKC,QAGvDZ,EAAgBW,MAAM,KAAKC,OAAS,GAGtC,OAFAH,QAAQC,IAAI,+CACZT,IAKFM,EAAcP,GAGd,MAAMa,EAAQC,WAAW,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAIzB,EAASsB,OAAQG,IAAK,CACxC,MAAM,SAAEC,EAAQ,SAAEC,GAAa3B,EAASyB,GACxC,IAAK,IAAIG,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,GADAV,QAAQC,IAAI,oBAAqBlB,GAC7B6B,GAAkB7B,EAOpB,OANIA,EACFD,EAAOS,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,GACT9B,EAAOS,EAAiBV,EAASyB,GAAI,QAEvCd,KAMNQ,QAAQC,IAAI,0BACM,IAAjBjB,GAEH,MAAO,IAAM8B,aAAaV,KAE3B,CAACb,EAAiBR,EAAkBF,EAAUG,EAAgBQ,IAE5DE,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGhC,GACC8B,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,WAC5CL,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,OACrCsB,IAAAC,cAAA,YAAM,+BAA6B3B,EAA0B,KAAO,SATnE0B,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,OC3CjB,IAEIK,EAAW,GACXC,GAAY,EAgWDC,MA9VSC,IACtB,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOF,GACvB,SACJ3C,EAAQ,OACR8C,EAAM,MACNC,EAAK,kBACL3C,EAAiB,WACjB4C,EAAU,WACVC,EAAU,iBACVC,EAAgB,WAChBC,EAAU,QACVC,EAAO,YACPC,GACER,GACGS,EAAUC,GAAehD,mBAASsC,EAAOW,aACzCC,EAASC,GAAcnD,mBAAS,KAChCoD,EAASC,GAAcrD,mBAAS,KAChCL,EAAkB2D,GAAuBtD,oBAAS,IAClDuD,EAAcC,GAAmBxD,oBAAS,IAC1CyD,EAAcC,GAAmB1D,oBAAS,IAC1C2D,EAAYC,GAAiB5D,mBAAS,IAEvC6D,EAAWC,iBAAO,IAClBC,EAAgBD,kBAAO,GACvBE,EAAWF,mBAGXG,EAAYH,mBACZI,EAAWJ,iBAAO,MA8GlBpE,EAASyE,MAAOC,EAAKC,EAASC,KAClCnB,EAAW,KAADoB,OAAMF,EAAkB,SAAW,QAAC,MAAAE,OAAKH,EAAG,MACtD,MAAMI,EAAO,IAAIvC,EAAU,CAAEwC,KAAML,IACnCf,EAAW,IAAImB,IACf,IACE5D,QAAQC,IAAI,wBAAyBwD,GACrC,MAAMK,EAAO,CACXC,YAAaL,EACbzB,QAASA,EACT2B,KAAMA,EACNvB,WAAYF,EACZ6B,UAAWf,EAASgB,QACpB/B,YAAaA,GAEflC,QAAQC,IAAI,OACZ,MAAM,KAAEiE,SAAeC,IAAMC,KAAK3C,EAAKqC,GACvC9D,QAAQC,IAAI,YAAaiE,EAAMJ,GAC/BI,EAAiB,YAAK9B,EAAY8B,EAAiB,YAC/CZ,EAASW,SACXX,EAASW,QAAQI,QAGnBC,IAEAhB,EAASW,QAAU,IAAIM,MAAML,EAAiB,YAC9CZ,EAASW,QAAQO,OAEjBlB,EAASW,QAAQQ,QAAU,KACzBzE,QAAQC,IAAI,4BAEZyE,KAEmC,IAA/BR,EAAyB,oBAC3BxB,EAAoBwB,EAAyB,oBAG/ClE,QAAQC,IAAI,qBAAsBiE,EAAyB,oBAE3DzB,EAAWyB,EAAW,MACtB7C,EAAW,IAAI6C,EAAW,OAEE,IAAxBA,EAAkB,cACpBlE,QAAQC,IAAI,sBAAuBiE,EAAkB,aACrDS,OAAOC,SAASC,WAGpB,MAAOC,GACP9E,QAAQC,IAAI,8BAA+B6E,KAIzCR,EAAgBA,KACpBS,IAAkBT,iBAMdI,EAAqBA,IACzBK,IAAkBC,eAAe,CAC/BC,YAAY,EACZC,SAAU,UAgCd,OAtBAnF,oBAAU,IAAMoF,IAAUC,kBAE1BrF,oBAAU,OAAU,CAACyB,IAErBzB,oBAAU,KACWwD,WAGjB8B,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,cAOfI,KAAKlD,GAAgB,KAE1BmD,GACA,MAAMC,EAAWC,YAAY,KAC3BjG,QAAQC,IAAI,wBAAyBgD,EAASgB,UAC7C,KACH,MAAO,IAAMiC,cAAcF,IAC1B,IAGDjF,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKmF,UAAU,OACbpF,IAAAC,cAAA,WACED,IAAAC,cAAA,OAAKoF,IAAKjE,EAAUR,OAAQA,GAAU,IAAKC,MAAOA,GAAS,OAE7Db,IAAAC,cAAA,OAAKmF,UAAU,OACbpF,IAAAC,cAACrC,EAAU,CACTE,SAAUA,EACVC,OAAQA,EACRC,iBAAkBA,EAClBC,eAAgB+C,EAChB9C,kBAAmBA,KAGvB8B,IAAAC,cAAA,OAAKmF,UAAU,cACbpF,IAAAC,cAAA,UAAQmF,UAAU,kBAAkBE,QAAS3B,GAAoB,wBAIlE5C,GACCf,IAAAC,cAAA,OAAKmF,UAAU,cACbpF,IAAAC,cAAA,SACEmF,UAAU,eACVzC,KAAK,OACL4C,YAAY,kBACZC,MAAOxD,EACPyD,SApOarI,IACvB,MAAM,MAAEoI,GAAUpI,EAAEsI,OACpBzD,EAAcuD,IAmOJG,UAhOavI,IACT,UAAVA,EAAEwI,MACJ3G,QAAQC,IAAI,kBAAmB8C,GAC/BjE,EAAOiE,EAAY,CAAEvC,SAAU,CAAEE,QAAS,KAAQ,GAClDsC,EAAc,UAgOW,IAAtB/D,GACC8B,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,WAAK,SAAOsB,GACXE,EAAQoE,IAAI,CAACC,EAAQC,IACpB/F,IAAAC,cAAA,OAAK2F,IAAKG,GACR/F,IAAAC,cAAA,WAAK,UAAQ6F,EAAOhD,MACpB9C,IAAAC,cAAA,WAAK,UAAQ6F,EAAOE,KAAOF,EAAOE,KAAO,mBAMnDhG,IAAAC,cAAA,YAMAD,IAAAC,cAAA,WACGgB,GACCjB,IAAAC,cAAA,OAAKE,MAAO,CAAE8F,UAAW,SAAUC,QAAS,SACzCpE,GAAgBF,EACf5B,IAAAC,cAAA,UACEqF,QAvKMa,KAClB9D,EAASa,QAAQI,QACjBjB,EAASa,QAAQkD,UAAUC,YAAY,GAAGC,OAC1CvE,GAAgB,IAqKJ5B,MAAO,CACLoG,OAAQ,UACRC,gBAAiB,QACjBC,MAAO,QACPP,QAAS,OACTQ,SAAU,OACVC,OAAQ,OACRC,aAAc,SAEjB,gBAID5G,IAAAC,cAAA,UACEqF,QAlQKuB,KACjB9E,GAAgB,GAChB+E,UAAUC,aACPC,aAAa,CAAEC,MAAO,CAAEpG,MAAO,OAC/BkE,KAAMmC,IACL,IAAID,EAAQ5E,EAASa,QACrB+D,EAAMb,UAAYc,EAClBD,EAAMxD,SAEP0D,MAAOC,IACNnI,QAAQ8E,MAAM,SAAUqD,MAyPhBjH,MAAO,CACLoG,OAAQ,UACRC,gBAAiB,QACjBC,MAAO,QACPP,QAAS,OACTQ,SAAU,OACVC,OAAQ,OACRC,aAAc,SAEjB,gBAMN9E,EACCF,EACE5B,IAAAC,cAAA,WACED,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTiH,eAAgB,SAChBnB,QAAS,OACToB,SAAUxG,EAAa,GAAK,WAC5ByG,QAASzG,EAAa,EAAI,KAG5Bd,IAAAC,cAAA,SACEuH,IAAKnF,EACLzB,OAlTI,IAmTJC,MAlTG,IAmTH4G,OApRUC,KACxBxC,YAAY1C,UACV,GAAIF,GAAaA,EAAUY,QAAS,CAClCZ,EAAUY,QAAQyE,UAAYnD,IAC5BnC,EAASa,SAEX,MAAM0E,EAAc,CAClB/G,MAtCW,IAuCXD,OAxCY,KA2Cd4D,IAAwBlC,EAAUY,QAAS0E,GAE3C,MAAMC,QAAmBrD,IAErBnC,EAASa,QACT,IAAIsB,KAELsD,oBACAC,sBAEGC,EAAoBxD,IAAsBqD,EAAYD,GAe5D,GAbII,EAAkB5I,OAAS,GAC7B8C,EAASgB,QAAU8E,GACd5F,EAAcc,SAAWjC,IAC5BlD,EAAO,GAAI,CAAE0B,SAAU,CAAEE,QAAS,KAAQ,GAC1CyC,EAAcc,SAAU,IAI1B5D,WAAW,KACT4C,EAASgB,QAAU,IAClB,KAGD8E,EAAkB5I,OAAS,IAAMmB,IACnCA,GAAY,EACRI,EAAOsH,aAAa,CACR,IAAIzE,MAAM7C,EAAOsH,aACzBxE,OAIVnB,GACEA,EAAUY,SACVZ,EAAUY,QACPgF,WAAW,MACXC,UAAU,EAAG,EA/EL,IADC,KAiFd7F,GACEA,EAAUY,SACVsB,IAAa4D,eAAe9F,EAAUY,QAAS8E,GACjD1F,GACEA,EAAUY,SACVsB,IAAa6D,kBAAkB/F,EAAUY,QAAS8E,GACpD1F,GACEA,EAAUY,SACVsB,IAAa8D,oBAAoBhG,EAAUY,QAAS8E,KAEvD,MA0NW7H,MAAO,CAAEyG,aAAc,UAEzB5G,IAAAC,cAAA,UAAQuH,IAAKlF,EAAWnC,MAAO,CAAEmH,SAAU,gBAI/CtH,IAAAC,cAAA,WAAK,cAGPD,IAAAC,cAAAD,IAAAE,SAAA,SC5VKqI,kBAVD9H,IACZ,MAAM,IAAEC,EAAG,OAAEC,GAAWF,EAAM+H,KAE9B,OADAxJ,oBAAU,IAAMoF,IAAUC,kBAExBrE,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACwI,EAAQ,CAAC/H,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAM+H,EAAS,IAAIC,IAGnBC,IAASC,OACP7I,IAAAC,cAACD,IAAM8I,WAAU,KACf9I,IAAAC,cAAC8I,IAAiB,CAACvD,MAAOkD,GACxB1I,IAAAC,cAAC+I,IAAa,CAACC,MAAOC,KACpBlJ,IAAAC,cAACkJ,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.d65f2182.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply=false,\n  noResponseTime = 1,\n  show_conversation = true,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      \n      // Add logs to check the conditions\n      console.log(\"listenAfterReply:\", listenAfterReply);\n      console.log(\"Number of words:\", finalTranscript.split(\" \").length);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (finalTranscript.split(\" \").length > 89) {\n        console.log(\"Transcript exceeds 89 words. Clearing.\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n            console.log(\"listenAfterReply:\", listenAfterReply);\n            if (isKeywordFound || listenAfterReply) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword\n        console.log(\"Waiting for a keyword\");\n      }, noResponseTime * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, noResponseTime, resetTranscript]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n        <div style={{ display: \"flex\", flexDirection: \"column\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          <span>Clear Transcript On Listen: {clearTranscriptOnListen ? \"on\" : \"off\"}</span>\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, FC, memo, useMemo, useRef } from \"react\"\nimport axios from \"axios\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\"\nimport Dictaphone from \"./Dictaphone\"\nimport * as faceapi from \"@vladmandic/face-api\"\n\nconst imageUrls = {\n  hoots: \"/hoots.png\",\n  hootsAndHootie: \"/hootsAndhootie.png\",\n}\n\nlet timer = null\nlet faceTimer = null\nlet g_anwers = []\nlet firstFace = false\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n  } = kwargs\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image)\n  const [message, setMessage] = useState(\"\")\n  const [answers, setAnswers] = useState([])\n  const [listenAfterReply, setListenAfterReply] = useState(false)\n  const [modelsLoaded, setModelsLoaded] = useState(false)\n  const [captureVideo, setCaptureVideo] = useState(false)\n  const [textString, setTextString] = useState(\"\")\n\n  const faceData = useRef([])\n  const faceTriggered = useRef(false)\n  const videoRef = useRef()\n  const videoHeight = 480\n  const videoWidth = 640\n  const canvasRef = useRef()\n  const audioRef = useRef(null)\n\n  const handleInputText = (e) => {\n    const { value } = e.target\n    setTextString(value)\n  }\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString)\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4)\n      setTextString(\"\")\n    }\n  }\n\n  const startVideo = () => {\n    setCaptureVideo(true)\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current\n        video.srcObject = stream\n        video.play()\n      })\n      .catch((err) => {\n        console.error(\"error:\", err)\n      })\n  }\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        )\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        }\n\n        faceapi.matchDimensions(canvasRef.current, displaySize)\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions()\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize)\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2)\n            faceTriggered.current = true\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer)\n          setTimeout(() => {\n            faceData.current = []\n          }, 1000)\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio)\n            audio.play()\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight)\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections)\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections)\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections)\n      }\n    }, 300)\n  }\n\n  const closeWebcam = () => {\n    videoRef.current.pause()\n    videoRef.current.srcObject.getTracks()[0].stop()\n    setCaptureVideo(false)\n  }\n  const testFunc = async () => {\n    const audio = new Audio(\"./test_audio.mp3s\")\n    console.log(audio.play())\n    const response = await axios.post(\n      \"http://192.168.143.97:8000/api/data/voiceGPT\",\n      {\n        api_key: \"sdf\",\n        text: \"text\",\n        self_image: \"something\",\n      }\n    )\n    console.log(\"response :>> \", response)\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`)\n    const text = [...g_anwers, { user: ret }]\n    setAnswers([...text])\n    try {\n      console.log(\"api call on listen...\", command)\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n      }\n      console.log(\"api\")\n      const { data } = await axios.post(api, body)\n      console.log(\"data :>> \", data, body)\n      data[\"self_image\"] && setImageSrc(data[\"self_image\"])\n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      stopListening() // turn off listen\n\n      audioRef.current = new Audio(data[\"audio_path\"]);\n      audioRef.current.play();\n      \n      audioRef.current.onended = () => {\n        console.log(\"Audio playback finished.\");\n        \n        listenContinuously()\n\n        if (data[\"listen_after_reply\"] === true) {\n          setListenAfterReply(data[\"listen_after_reply\"]);\n        }\n        \n        console.log(\"listen after reply\", data[\"listen_after_reply\"])\n        \n        setAnswers(data[\"text\"]);\n        g_anwers = [...data[\"text\"]];\n\n        if (data[\"page_direct\"] === true) {\n          console.log(\"api has page direct\", data[\"page_direct\"]);\n          window.location.reload();\n        }\n      } \n    } catch (error) {\n      console.log(\"api call on listen failded!\", error)\n    }\n  }\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n};\n  const startListening = () => {\n    SpeechRecognition.startListening();\n};\n\n  const listenContinuously = () =>\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n  const listenContinuouslyInChinese = () =>\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"zh-CN\",\n    })\n  const listenOnce = () =>\n    SpeechRecognition.startListening({ continuous: false })\n\n  useEffect(() => Streamlit.setFrameHeight())\n\n  useEffect(() => {}, [props])\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\"\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n      ]).then(setModelsLoaded(true))\n    }\n    loadModels()\n    const interval = setInterval(() => {\n      console.log(\"faceData.current :>> \", faceData.current)\n    }, 3000)\n    return () => clearInterval(interval)\n  }, [])\n\n  return (\n    <>\n      <div className=\"p-2\">\n        <div>\n          <img src={imageSrc} height={height || 100} width={width || 100} />\n        </div>\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            noResponseTime={no_response_time}\n            show_conversation={show_conversation}\n          />\n        </div>\n        <div className=\"form-group\">\n          <button className=\"btn btn-primary\" onClick={listenContinuously}>\n            Listen continuously\n          </button>\n        </div>\n        {input_text && (\n          <div className=\"form-group\">\n            <input\n              className=\"form-control\"\n              type=\"text\"\n              placeholder=\"Chat with Hoots\"\n              value={textString}\n              onChange={handleInputText}\n              onKeyDown={handleOnKeyDown}\n            />\n          </div>\n        )}\n        {show_conversation === true && (\n          <>\n            <div> You: {message}</div>\n            {answers.map((answer, idx) => (\n              <div key={idx}>\n                <div>-user: {answer.user}</div>\n                <div>-resp: {answer.resp ? answer.resp : \"thinking...\"}</div>\n              </div>\n            ))}\n          </>\n        )}\n      </div>\n      <div>\n        {/* <button onClick={listenOnce}>Listen Once</button> */}\n        {/* <button onClick={listenContinuouslyInChinese}></button> */}\n        {/* <button onClick={SpeechRecognition.stopListening}>Stop</button> */}\n        {/* <button onClick={testFunc}>test</button> */}\n      </div>\n      <div>\n        {face_recon && (\n          <div style={{ textAlign: \"center\", padding: \"10px\" }}>\n            {captureVideo && modelsLoaded ? (\n              <button\n                onClick={closeWebcam}\n                style={{\n                  cursor: \"pointer\",\n                  backgroundColor: \"green\",\n                  color: \"white\",\n                  padding: \"15px\",\n                  fontSize: \"25px\",\n                  border: \"none\",\n                  borderRadius: \"10px\",\n                }}\n              >\n                Close Webcam\n              </button>\n            ) : (\n              <button\n                onClick={startVideo}\n                style={{\n                  cursor: \"pointer\",\n                  backgroundColor: \"green\",\n                  color: \"white\",\n                  padding: \"15px\",\n                  fontSize: \"25px\",\n                  border: \"none\",\n                  borderRadius: \"10px\",\n                }}\n              >\n                Open Webcam\n              </button>\n            )}\n          </div>\n        )}\n        {captureVideo ? (\n          modelsLoaded ? (\n            <div>\n              <div\n                style={{\n                  display: \"flex\",\n                  justifyContent: \"center\",\n                  padding: \"10px\",\n                  position: show_video ? \"\" : \"absolute\",\n                  opacity: show_video ? 1 : 0.3,\n                }}\n              >\n                <video\n                  ref={videoRef}\n                  height={videoHeight}\n                  width={videoWidth}\n                  onPlay={handleVideoOnPlay}\n                  style={{ borderRadius: \"10px\" }}\n                />\n                <canvas ref={canvasRef} style={{ position: \"absolute\" }} />\n              </div>\n            </div>\n          ) : (\n            <div>loading...</div>\n          )\n        ) : (\n          <></>\n        )}\n      </div>\n    </>\n  )\n}\n\nexport default CustomVoiceGPT\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}