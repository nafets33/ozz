{"version":3,"sources":["Dictaphone.jsx","MediaDisplay.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","apiInProgress","listenButton","session_listen","finalTranscript","interimTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","show_transcript","setShowTranscript","useState","useEffect","processTranscript","console","log","split","length","i","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","React","createElement","Fragment","style","display","flexDirection","maxHeight","height","overflowY","border","padding","color","onClick","showTranscript_func","prev","marginTop","clearTranscript_func","MediaDisplay","showImage","imageSrc","largeHeight","largeWidth","smallHeight","smallWidth","width","className","alignItems","justifyContent","toLowerCase","endsWith","maxWidth","borderRadius","objectFit","controls","autoPlay","loop","muted","src","type","alt","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","agent_actions","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistening","show_conversation","setshow_conversation","setlistenButton","setsession_listen","convo_button","setconvo_button","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","setShowImage","selectedActions","setSelectedActions","windowWidth","setWindowWidth","updateWindowWidth","window","innerWidth","fetchImageData","async","response","axios","get","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","stopListening","SpeechRecognition","listenContinuously","startListening","continuous","language","ret","command","text","user","body","tigger_type","face_data","current","selected_actions","post","pause","apiUrlWithFileName","Audio","play","Promise","resolve","onended","location","href","background_color_chat","color_dict","placeholder","flex","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","textAlign","marginLeft","marginRight","wordBreak","dangerouslySetInnerHTML","__html","resp","margin","value","onChange","event","target","onKeyDown","e","backgroundImage","animation","fontSize","cursor","click_listenButton","convo_mode","background","listenSession","Array","isArray","flexWrap","gap","action","selected","includes","filter","a","withStreamlitConnection","args","Streamlit","setFrameHeight","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"wMAgHeA,MA7GIC,IAQb,IARcC,SAClBA,EAAQC,OACRA,EAAMC,iBACNA,GAAmB,EAAKC,iBACxBA,EAAmB,EAACC,cACpBA,GAAgB,EAAKC,aACrBA,GAAe,EAAKC,eACpBA,GAAiB,GAClBP,EACC,MAAMQ,gBACJA,EAAeC,kBACfA,EAAiBC,gBACjBA,EAAeC,UACfA,EAASC,iCACTA,EAAgCC,sBAChCA,GACEC,kCAEGC,EAAiBC,GAAqBC,oBAAS,GA+CtD,OAJAC,oBAAU,KAtCgBC,MACxB,GAAwB,KAApBX,EAAwB,CAK1B,GAJAY,QAAQC,IAAI,oBAAqBb,GACjCY,QAAQC,IAAI,aAAcV,GAC1BS,QAAQC,IAAI,oBAAqBlB,GAE7BI,GAAkBC,EAAgBc,MAAM,KAAKC,OAAS,IAAQ,CAChEH,QAAQC,IAAI,8BACZ,IAAK,IAAIG,EAAI,EAAGA,EAAIvB,EAASsB,OAAQC,IACnCtB,EAAOM,EAAiBP,EAASuB,GAAI,GAGvC,YADAd,IAIF,IAAK,IAAIc,EAAI,EAAGA,EAAIvB,EAASsB,OAAQC,IAAK,CACxC,MAAMC,SAAEA,EAAQC,SAAEA,GAAazB,EAASuB,GACxC,IAAK,IAAIG,EAAI,EAAGA,EAAIF,EAASF,OAAQI,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCtB,EAAgBuB,OAAOH,GAE9C,IAAKE,GAAkB3B,GAAoBG,KAAkBD,EAS3D,OARIF,EACFD,EAAOM,EAAiB,CAAEkB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACT5B,EAAOM,EAAiBP,EAASuB,GAAI,GAC5BlB,GACTJ,EAAOM,EAAiBP,EAASuB,GAAI,QAEvCd,KAKNU,QAAQC,IAAI,2BAKdF,IACC,CAACX,IAECI,EAIAC,EAKHmB,IAAAC,cAAAD,IAAAE,SAAA,KACGnB,GACCiB,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTC,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXC,OAAQ,iBACRC,QAAS,SAGXV,IAAAC,cAAA,YACED,IAAAC,cAAA,cAAQ,cAAmB,IAAEtB,EAAY,KAAO,OAElDqB,IAAAC,cAAA,YACED,IAAAC,cAAA,cAAQ,eAAqB,IAC7BD,IAAAC,cAAA,YACGzB,EACDwB,IAAAC,cAAA,QAAME,MAAO,CAAEQ,MAAO,SAAWlC,MAKzCuB,IAAAC,cAAA,UAAQW,QA/EgBC,IAAM7B,EAAmB8B,IAAUA,GA+ErBX,MAAO,CAAEY,UAAW,SACvDhC,EAAkB,kBAAoB,mBAEzCiB,IAAAC,cAAA,UAAQW,QAjFiBI,IAAMtC,IAiFQyB,MAAO,CAAEY,UAAW,SAAU,qBAhChEf,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uBC7BAgB,MAtCIjD,IAAqG,IAApGkD,UAAEA,EAASC,SAAEA,EAAQC,YAAEA,EAAc,IAAGC,WAAEA,EAAa,IAAGC,YAAEA,EAAc,GAAEC,WAAEA,EAAa,IAAIvD,EAEjH,MAAMuC,EAASW,EAAYE,EAAcE,EACnCE,EAAQN,EAAYG,EAAaE,EAEvC,OACEvB,IAAAC,cAAA,OAAKwB,UAAU,MAAMtB,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUqB,WAAY,WAElF1B,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQuB,eAAgB,SAAUH,MAAO,SAC7DL,IACCA,EAASS,cAAcC,SAAS,QAC9B7B,IAAAC,cAAA,SACEE,MAAO,CAAE2B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DzB,OAAQA,EACRiB,MAAOA,EACPS,SAAUf,EACVgB,UAAQ,EACRC,MAAM,EACNC,OAAK,GAELpC,IAAAC,cAAA,UAAQoC,IAAKlB,EAAUmB,KAAK,cAAc,gDAI5CtC,IAAAC,cAAA,OACEoC,IAAKlB,EACLZ,OAAQA,EACRiB,MAAOA,EACPrB,MAAO,CAAE2B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DO,IAAI,4BCpBpB,IAEIC,EAAW,GA2qBAC,MAxqBSC,IAAU,IAAAC,EAChC,MAAMC,IAAEA,EAAGC,OAAEA,EAAS,IAAOH,GACvBzE,SACJA,EAAQsC,OACRA,EAAMiB,MACNA,EAAKsB,WACLA,EAAUC,WACVA,EAAU3E,iBACVA,EAAgB4E,WAChBA,EAAUC,QACVA,EAAOC,YACPA,EAAWC,WACXA,EAAUC,UACVA,EAASC,YACTA,EAAWC,cACXA,EAAaC,eACbA,EAAcC,cACdA,GACEX,GACG1B,EAAUsC,GAAexE,mBAAS4D,EAAOM,aACzCO,EAAeC,GAAoB1E,mBAAS4D,EAAOM,aAEnDS,EAASC,GAAc5E,mBAAS,KAChC6E,EAASC,GAAc9E,mBAAS,KAChCd,EAAkB6F,GAAuB/E,oBAAS,IAElDgF,EAAcC,GAAmBjF,oBAAS,IAC1CkF,EAAcC,GAAmBnF,oBAAS,IAC1CoF,EAAYC,GAAiBrF,mBAAS,KACtCZ,EAAekG,GAAoBtF,oBAAS,IAC5CuF,EAAUC,GAAyBxF,oBAAS,IAC5CN,EAAW+F,GAAgBzF,oBAAS,IAEpC0F,EAAmBC,GAAwB3F,oBAAS,IAGpDX,EAAcuG,GAAmB5F,oBAAS,IAC1CV,EAAgBuG,GAAqB7F,oBAAS,IAC9C8F,GAAcC,IAAmB/F,oBAAS,IAE1CgG,GAAqBC,IAAmBjG,mBAAS4D,EAAOU,gBACzD4B,GAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBE,GAAoBC,IAAyBtG,oBAAS,IACtDuG,GAAYC,IAAiBxG,mBAAS,kBACtCyG,GAAmBC,IAAwB1G,mBAAS,cAEpDiC,GAAW0E,IAAgB3G,oBAAS,IACpC4G,GAAiBC,IAAsB7G,mBAAS,KAQhD8G,GAAaC,IAAkB/G,mBAAS,GAGvCgH,GAAoBA,KACF,qBAAXC,QACPF,GAAeE,OAAOC,aAK9BjH,oBAAU,KACN+G,MACD,IAEH/G,oBAAU,KACJiE,GAEFiD,GAAejD,IAEhB,CAACA,IAEJ,MAAMiD,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,OAAOpD,IAAYqD,IAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBP,EAASQ,MAC/CrD,EAAYkD,GACZhD,EAAiB8C,GACjB,MAAOM,GACP3H,QAAQ2H,MAAM,6BAA8BA,KAM1CC,GAAgBA,KACpBtC,GAAa,GACbuC,IAAkBD,gBAClB5H,QAAQC,IAAI,mCAAoCV,IAG5CuI,GAAqBA,KACzBxC,GAAa,GACbuC,IAAkBE,eAAe,CAC/BC,YAAY,EACZC,SAAU,WAmBhBnI,oBAAU,KACJP,EACFS,QAAQC,IAAI,yBAEZD,QAAQC,IAAI,0BAEb,CAACV,IAGF,MA6IMT,GAASmI,MAAOiB,EAAKC,EAASjF,KAClCuB,OAAgB0D,EAAkB,SAAW,YAAMD,MACnD,MAAME,EAAO,IAAIhF,EAAU,CAAEiF,KAAMH,IACnCvD,EAAW,IAAIyD,IACf,IACEpI,QAAQC,IAAI,wBAAyBkI,GACrChD,GAAiB,GACjByC,KAEA,MAAMU,EAAO,CACXC,YAAarF,EACbW,QAASA,EACTuE,KAAMA,EACNrE,WAAYO,EACZkE,UAAWzC,GAAS0C,QACpB3E,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACd/E,eAAeA,EACf0G,oBAAoBA,GACpB6C,iBAAkBjC,IAEpBzG,QAAQC,IAAI,OACZ,MAAMyH,KAAEA,SAAeP,IAAMwB,KAAKnF,EAAK8E,GAYvC,GAXAtI,QAAQC,IAAI,YAAayH,EAAMY,GAC3BZ,EAAiB,YAAKA,EAAiB,aAAMpD,GAC/C0C,GAAeU,EAAiB,YAElC/C,EAAW+C,EAAW,MACtBtE,EAAW,IAAIsE,EAAW,MAEtBzB,GAASwC,SACXxC,GAASwC,QAAQG,QAGflB,EAAiB,WAAG,CACtB,MAAMmB,KAAwB7E,IAAY0D,EAAiB,aAC3DzB,GAASwC,QAAU,IAAIK,MAAMD,GAE7B,UACU5C,GAASwC,QAAQM,OAGvB1D,GAAsB,GACtBkB,GAAqB,kBAGf,IAAIyC,QAASC,IACfhD,GAASwC,QAAQS,QAAU,MACvBlJ,QAAQC,IAAI,4BACZgJ,QAIV,MAAOtB,GACL3H,QAAQ2H,MAAM,wBAAyBA,GAC1C,QAEG1B,GAASwC,QAAU,KACnBpD,GAAsB,GACtBkB,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBlB,GAAsB,GACtBF,GAAiB,GAGjBP,EAAoB8C,EAAyB,oBAC7C1H,QAAQC,IAAI,qBAAsByH,EAAyB,mBAAG3I,IAIlC,IAAxB2I,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD1H,QAAQC,IAAI,sBAAuByH,EAAkB,aAErDZ,OAAOqC,SAASC,KAAO1B,EAAkB,aAGvCxB,GACFC,IAAsB,GAEG,GAAlBpH,GACPiB,QAAQC,IAAI,sCACZsG,GAAqB,sCAEdrH,EACTuG,GAAgB,GAEPE,KACP3F,QAAQC,IAAI,cACZ6H,MAIF,MAAOH,GACP3H,QAAQC,IAAI,6BAA8B0H,GAC1CxC,GAAiB,GACjBM,GAAgB,GAGlBoB,KACA7G,QAAQC,IAAI,kBAGRoJ,IAAmC,OAAXvF,QAAW,IAAXA,OAAW,EAAY,QAAZP,EAAXO,EAAawF,kBAAU,IAAA/F,OAAA,EAAvBA,EAAyB8F,wBAAyB,cAE1EE,gBADaxF,EAAW7D,MAAM,KAAK,KAGzC,OACEU,IAAAC,cAAAD,IAAAE,SAAA,KAEEF,IAAAC,cAAA,OAAKwB,UAAU,OACbzB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUmB,MAAO,SAE7DxB,IAAAC,cAAA,WAEED,IAAAC,cAACgB,EAAY,CACXC,UAAWA,GACXC,SAAUA,EACVC,YAAa,IACbC,WAAY,IACZC,YAAa,GACbC,WAAY,MAKhBvB,IAAAC,cAAA,OAAKE,MAAO,CAAEyI,KAAM1H,GAAY,EAAI,OAAQV,UAAW,OAAQF,UAAW,UACvEqE,GACC3E,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTC,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXC,OAAQ,iBACRC,QAAS,SAGVoD,EAAQ+E,IAAI,CAACC,EAAQC,IACpB/I,IAAAC,cAAA,OACE+I,IAAKD,EACLtH,UAAU,yBACVtB,MAAO,CACL8I,aAAc,MACdvI,QAAS,MACTqB,aAAc,MACdtB,OAAQ,iBACRyI,UAAW,iCAGblJ,IAAAC,cAAA,OACEwB,UAAU,YACVtB,MAAO,CACLgJ,gBAAiB,UACjBC,UAAW,QACXC,WAAY,OACZ3I,QAAS,QAGV2C,EAAY,KAAErD,IAAAC,cAAA,YAAO6I,EAAOrB,OAE/BzH,IAAAC,cAAA,OACEwB,UAAU,0BACVtB,MAAO,CACLC,QAAS,OACTsB,WAAY,aACZyH,gBAAiBV,GACjB/H,QAAS,SAGVS,GACCnB,IAAAC,cAAA,OAAKwB,UAAU,aAAatB,MAAO,CAAEmJ,YAAa,SAChDtJ,IAAAC,cAAA,OAAKoC,IAAKlB,EAAUoB,IAAI,WAAWpC,MAAO,CAAEqB,MAAO,WAGvDxB,IAAAC,cAAA,OACEwB,UAAU,qBACVtB,MAAO,CAAEyI,KAAM,EAAGW,UAAW,cAC7BC,wBAAyB,CAAEC,OAAQX,EAAOY,MAAQ,uBAWjE3G,GACC/C,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAEwJ,OAAQ,WACnB3J,IAAAC,cAAA,OAAKwB,UAAU,cACbzB,IAAAC,cAAA,SACEwB,UAAU,eACVa,KAAK,OACLqG,YAAaA,GACbiB,MAAOvF,EACPwF,SA3TWC,IAEvBxF,EAAcwF,EAAMC,OAAOH,OAG3BrE,IAAsB,IAuTVyE,UApTWC,IACT,UAAVA,EAAEjB,MACJ5J,QAAQC,IAAI,kBAAmBgF,GAC/BnG,GAAOmG,EAAY,CAAE3E,SAAU,CAAEE,QAAS,KAAQ,GAClD0E,EAAc,QAmTL3F,GACWqB,IAAAC,cAAA,OACEE,MAAO,CACLqB,MAAO,MACPjB,OAAQ,OACR2J,gBAAiB,wDACjBC,UAAW,wBACXpJ,UAAW,QAGbf,IAAAC,cAAA,OAAKE,MAAO,CAAEiK,SAAU,OAAQzJ,MAAO,UAAY+E,MAMnE1F,IAAAC,cAAA,MAAIE,MAAO,CAAEwJ,OAAQ,YAM3B3J,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQW,UAAW,QAExCf,IAAAC,cAAA,OAAKE,MAAO,CAAEyI,KAAM,EAAGQ,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLiK,SAAU,OACV1J,QAAS,MACTiJ,OAAQ,QACRR,gBAAiB,UACjBxI,MAAO,QACPF,OAAQ,oBACRsB,aAAc,MACdsI,OAAQ,UACR7I,MAAO,OAETZ,QA/PiB0J,KACzBzF,GAAgB,GACXlG,GACHuI,KAEFzB,GAAc,gBACdrG,QAAQC,IAAI,iCACZD,QAAQC,IAAIf,KA0PHkH,KAMLxF,IAAAC,cAAA,OAAKE,MAAO,CAAEyI,KAAM,EAAGQ,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLiK,SAAU,OACV1J,QAAS,MACTiJ,OAAQ,QACRR,gBAAiB,UACjBxI,MAAO,QACPF,OAAQ,oBACRsB,aAAc,MACdsI,OAAQ,UACR7I,MAAO,OAETZ,QA5aO2J,KACjBnL,QAAQC,IAAI,aAAcV,GACrBA,GAKHS,QAAQC,IAAI,yBACZ2F,IAAgB,GAChBgC,OANA5H,QAAQC,IAAI,yBACZ2F,IAAgB,GAChBkC,QAyaSnC,GAAe,mBAAqB,sBAEtCP,GACCxE,IAAAC,cAAA,OACEE,MAAO,CAELI,OAAQ,OACRiK,WAAY,uDACZL,UAAW,4BACXpJ,UAAW,MACXgB,aAAc,SAGhB/B,IAAAC,cAAA,OAAKE,MAAO,CAAEiK,SAAU,OAAQzJ,MAAO,UAAW,cAMxDX,IAAAC,cAAA,OAAKE,MAAO,CAAEyI,KAAM,EAAGQ,UAAW,WAChCpJ,IAAAC,cAAA,UACEE,MAAO,CACLiK,SAAU,OACV1J,QAAS,MACTiJ,OAAQ,QACRR,gBAAiB,UACjBxI,MAAO,QACPF,OAAQ,oBACRsB,aAAc,MACdsI,OAAQ,UACR7I,MAAO,OAETZ,QAxbY6J,KAEpB3F,GADIvG,KAybKA,EAAiB,eAAiB,iBAEpCA,GACCyB,IAAAC,cAAA,OACEE,MAAO,CACLqB,MAAO,MACPjB,OAAQ,OACR2J,gBAAiB,0DACjBC,UAAW,wBACXpJ,UAAW,QAGbf,IAAAC,cAAA,OAAKE,MAAO,CAAEiK,SAAU,OAAQzJ,MAAO,UAAW,sBA0B3D+J,MAAMC,QAAQnH,IAAkBA,EAAcjE,OAAS,GACtDS,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTwK,SAAU,OACVjJ,eAAgB,SAChBZ,UAAW,MACX8J,IAAK,QAGNrH,EAAcqF,IAAI,CAACiC,EAAQ/B,KAC1B,MAAMgC,EAAWlF,GAAgBmF,SAASF,GAC1C,OACE9K,IAAAC,cAAA,UACE+I,IAAKD,EACLnI,QAASA,KAELkF,GADEiF,EACiBlF,GAAgBoF,OAAQC,GAAMA,IAAMJ,GAEpC,IAAIjF,GAAiBiF,KAG5C3K,MAAO,CACLiK,SAAU,OACV1J,QAAS,WACTyI,gBAAiB4B,EAAW,UAAY,UACxCpK,MAAOoK,EAAW,QAAU,QAC5BtK,OAAQ,oBACRsB,aAAc,MACdsI,OAAQ,YAGTS,MASP9K,IAAAC,cAAA,OAAKwB,UAAU,MAAMtB,MAAO,CAAE8I,aAAc,SAC1CjJ,IAAAC,cAAClC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,EAChBI,UAAWA,QCzpBRwM,kBAVDzI,IACZ,MAAME,IAAEA,EAAGC,OAAEA,GAAWH,EAAM0I,KAE9B,OADAlM,oBAAU,IAAMmM,IAAUC,kBAExBtL,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACsL,EAAQ,CAAC3I,IAAKA,EAAKC,OAAQA,uCCLlC,MAAM2I,EAAS,IAAIC,IAGnBC,IAASC,OACP3L,IAAAC,cAACD,IAAM4L,WAAU,KACf5L,IAAAC,cAAC4L,IAAiB,CAACjC,MAAO4B,GACxBxL,IAAAC,cAAC6L,IAAa,CAACC,MAAOC,KACpBhM,IAAAC,cAACgM,EAAI,SAIXC,SAASC,eAAe","file":"static/js/main.7b99651d.chunk.js","sourcesContent":["import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  apiInProgress = false,\n  listenButton = false,\n  session_listen = false,\n}) => {\n  const {\n    finalTranscript,\n    interimTranscript,\n    resetTranscript,\n    listening,\n    browserSupportsSpeechRecognition,\n    isMicrophoneAvailable,\n  } = useSpeechRecognition();\n  \n  const [show_transcript, setShowTranscript] = useState(true);\n\n  const showTranscript_func = () => setShowTranscript((prev) => !prev);\n  const clearTranscript_func = () => resetTranscript();\n\n  const processTranscript = () => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"Listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n      if (session_listen && finalTranscript.split(\" \").length > 500000) {\n        console.log(\"Transcript exceeds X words\");\n        for (let i = 0; i < commands.length; i++) {\n          myFunc(finalTranscript, commands[i], 6);\n        }\n        resetTranscript();\n        return;\n      }\n\n      for (let i = 0; i < commands.length; i++) {\n        const { keywords, api_body } = commands[i];\n        for (let j = 0; j < keywords.length; j++) {\n          const keyword = new RegExp(keywords[j], \"i\");\n          const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n          if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n            if (listenAfterReply) {\n              myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n            } else if (isKeywordFound) {\n              myFunc(finalTranscript, commands[i], 1);\n            } else if (listenButton) {\n              myFunc(finalTranscript, commands[i], 5);\n            }\n            resetTranscript();\n            return;\n          }\n        }\n      }\n      console.log(\"Waiting for a keyword\");\n    }\n  };\n\n  useEffect(() => {\n    processTranscript();\n  }, [finalTranscript]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_transcript && (\n        <div\n          style={{\n            display: \"flex\",\n            flexDirection: \"column\",\n            maxHeight: \"250px\",\n            height: \"250px\",\n            overflowY: \"auto\",\n            border: \"1px solid #ccc\",\n            padding: \"10px\",\n          }}\n        >\n          <span>\n            <strong>Listening:</strong> {listening ? \"on\" : \"off\"}\n          </span>\n          <span>\n            <strong>Transcript:</strong>{\" \"}\n            <span>\n              {finalTranscript}\n              <span style={{ color: \"gray\" }}>{interimTranscript}</span>\n            </span>\n          </span>\n        </div>\n      )}\n      <button onClick={showTranscript_func} style={{ marginTop: \"10px\" }}>\n        {show_transcript ? \"Hide Transcript\" : \"Show Transcript\"}\n      </button>\n      <button onClick={clearTranscript_func} style={{ marginTop: \"10px\" }}>\n        Clear Transcript\n      </button>\n    </>\n  );\n}\n\nexport default Dictaphone;","import React from 'react';\n\nconst MediaDisplay = ({ showImage, imageSrc, largeHeight = 100, largeWidth = 100, smallHeight = 40, smallWidth = 40 }) => {\n    // Determine the dimensions based on `showImage` status\n    const height = showImage ? largeHeight : smallHeight;\n    const width = showImage ? largeWidth : smallWidth;\n  \n    return (\n      <div className=\"p-2\" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center' }}>\n        {/* Always show the image or video at the top center based on `showImage` */}\n        <div style={{ display: 'flex', justifyContent: 'center', width: '100%' }}>\n          {imageSrc && (\n            imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                height={height}\n                width={width}\n                controls={showImage} // Only show controls if `showImage` is true\n                autoPlay\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img\n                src={imageSrc}\n                height={height}\n                width={width}\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                alt=\"Media Preview\"\n              />\n            )\n          )}\n        </div>\n      </div>\n    );\n  };\n  \n  export default MediaDisplay;","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\nimport MediaDisplay from \"./MediaDisplay\";\n\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n    agent_actions,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progresslistening\n  const [listening, setlistening] = useState(false); // Added state for API in progress\n\n  const [show_conversation, setshow_conversation] = useState(true); // Added state for API in progress\n  \n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n  const [convo_button, setconvo_button] = useState(false); // Added state for API in progress\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n  const [selectedActions, setSelectedActions] = useState([]);\n\n  \n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  const [windowWidth, setWindowWidth] = useState(0); // Initial value\n\n    // Create a reusable function for getting the window width\n    const updateWindowWidth = () => {\n      if (typeof window !== 'undefined') {\n          setWindowWidth(window.innerWidth);\n      }\n  };\n\n  // Call the function on component mount to set the initial window width\n  useEffect(() => {\n      updateWindowWidth();\n  }, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n\n\n  const stopListening = () => {\n    setlistening(false);\n    SpeechRecognition.stopListening();\n    console.log(\"Stopping Listening, isListening=\", listening)\n  }\n\n  const listenContinuously = () =>{\n    setlistening(true)\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n\n}\n\n\nconst convo_mode = () => {\n  console.log(\"listening?\", listening);\n  if (!listening) {\n    console.log(\"Starting to listen...\");\n    setconvo_button(true)\n    listenContinuously();\n  } else {\n    console.log(\"Stopping listening...\");\n    setconvo_button(false)\n    stopListening();\n  }\n};\n\nuseEffect(() => {\n  if (listening) {\n    console.log(\"Listening has started\");\n  } else {\n    console.log(\"Listening has stopped\");\n  }\n}, [listening]);\n\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  // useEffect(() => {\n  //   const loadModels = async () => {\n  //     const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n  //     Promise.all([\n  //       faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n  //     ]).then(() => setModelsLoaded(true));\n  //   };\n  //   loadModels();\n  //   const interval = setInterval(() => {\n  //     // console.log(\"faceData.current :>> \", faceData.current);\n  //   }, 3000);\n  //   return () => clearInterval(interval);\n  // }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  // const startVideo = () => {\n  //   setCaptureVideo(true);\n  //   navigator.mediaDevices\n  //     .getUserMedia({ video: { width: 300 } })\n  //     .then((stream) => {\n  //       let video = videoRef.current;\n  //       video.srcObject = stream;\n  //       video.play();\n  //     })\n  //     .catch((err) => {\n  //       console.error(\"error:\", err);\n  //     });\n  // };\n\n  // const handleVideoOnPlay = () => {\n  //   setInterval(async () => {\n  //     if (canvasRef && canvasRef.current) {\n  //       canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n  //         videoRef.current\n  //       );\n  //       const displaySize = {\n  //         width: videoWidth,\n  //         height: videoHeight,\n  //       };\n\n  //       faceapi.matchDimensions(canvasRef.current, displaySize);\n\n  //       const detections = await faceapi\n  //         .detectAllFaces(\n  //           videoRef.current,\n  //           new faceapi.TinyFaceDetectorOptions()\n  //         )\n  //         .withFaceLandmarks()\n  //         .withFaceExpressions();\n\n  //       const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n  //       if (resizedDetections.length > 0) {\n  //         faceData.current = resizedDetections;\n  //         if (!faceTriggered.current && face_recon) {\n  //           myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n  //           faceTriggered.current = true;\n  //         }\n  //       } else {\n  //         faceTimer && clearTimeout(faceTimer);\n  //         setTimeout(() => {\n  //           faceData.current = [];\n  //         }, 1000);\n  //       }\n\n  //       if (resizedDetections.length > 0 && !firstFace) {\n  //         firstFace = true;\n  //         if (kwargs.hello_audio) {\n  //           const audio = new Audio(kwargs.hello_audio);\n  //           audio.play();\n  //         }\n  //       }\n\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         canvasRef.current\n  //           .getContext(\"2d\")\n  //           .clearRect(0, 0, videoWidth, videoHeight);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceExpressions(\n  //           canvasRef.current,\n  //           resizedDetections\n  //         );\n  //     }\n  //   }, 300);\n  // };\n\n  // const closeWebcam = () => {\n  //   videoRef.current.pause();\n  //   videoRef.current.srcObject.getTracks()[0].stop();\n  //   setCaptureVideo(false);\n  // };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    if (!listening) {\n      listenContinuously()\n    }\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n        selected_actions: selectedActions,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"], listenAfterReply);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n\n      if (UserUsedChatWindow) {\n        setUserUsedChatWindow(false)\n      }\n      else if (listenAfterReply==true) {\n        console.log(\"API END HIT listenAfterReply==TRUE\")\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (convo_button){\n        console.log(\"convo mode\")\n        listenContinuously()\n      }\n\n      \n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n\n    updateWindowWidth();\n    console.log(\"ReSize Window\")\n  };\n  \n  const background_color_chat = refresh_ask?.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'column', width: '100%' }}>\n          {/* Image or video section */}\n          <div>\n            {/* Media Display */}\n            <MediaDisplay\n              showImage={showImage}\n              imageSrc={imageSrc}\n              largeHeight={100}   // Customize as needed\n              largeWidth={100}    // Customize as needed\n              smallHeight={40}    // Customize as needed\n              smallWidth={40}     // Customize as needed\n            />\n          </div>\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '350px' }}>\n            {show_conversation && (\n              <div\n                style={{\n                  display: 'flex',\n                  flexDirection: 'column',\n                  maxHeight: '350px',\n                  height: '350px',\n                  overflowY: 'auto',\n                  border: '1px solid #ccc',\n                  padding: '10px',\n                }}\n              >\n                {answers.map((answer, idx) => (\n                  <div\n                    key={idx}\n                    className=\"chat-message-container\"\n                    style={{\n                      marginBottom: '5px',\n                      padding: '5px',\n                      borderRadius: '4px',\n                      border: '1px solid #ccc',\n                      boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',\n                    }}\n                  >\n                    <div\n                      className=\"chat-user\"\n                      style={{\n                        backgroundColor: '#e4eafe',\n                        textAlign: 'right',\n                        marginLeft: 'auto',\n                        padding: '5px',\n                      }}\n                    >\n                      {client_user}: <span>{answer.user}</span>\n                    </div>\n                    <div\n                      className=\"chat-response-container\"\n                      style={{\n                        display: 'flex',\n                        alignItems: 'flex-start',\n                        backgroundColor: background_color_chat,\n                        padding: '10px',\n                      }}\n                    >\n                      {imageSrc && (\n                        <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                          <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} />\n                        </div>\n                      )}\n                      <div\n                        className=\"chat-response-text\"\n                        style={{ flex: 1, wordBreak: 'break-word' }}\n                        dangerouslySetInnerHTML={{ __html: answer.resp || \"thinking...\" }}\n                      />\n                    </div>\n                  </div>\n                ))}\n              </div>\n            )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '3px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n\n              {listening && (\n                          <div\n                            style={{\n                              width: '89%',\n                              height: '10px',\n                              backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                              animation: 'flashLine 1s infinite',\n                              marginTop: '5px',\n                            }}\n                          >\n                            <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n                          </div>\n                        )}\n\n\n            </div>\n            <hr style={{ margin: '3px 0' }} />\n          </>\n        )}\n\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '3px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={convo_mode}\n          >\n            {convo_button ? \"End Conversation\" : \"Start Conversation\"}\n          </button>\n          {speaking && (\n            <div\n              style={{\n                // width: '89%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={listenSession}\n          >\n            {session_listen ? \"Stop Session\" : \"Start Session\"}\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n        {/* Toggle Image Button\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={stopListening}\n          >\n            {listening ? \"Stop Listening\" : \"\"}\n          </button>\n        </div> */}\n      </div>\n\n    {/* Agent Actions Horizontal Button-Style Multi-Select */}\n    {Array.isArray(agent_actions) && agent_actions.length > 0 && (\n      <div\n        style={{\n          display: 'flex',\n          flexWrap: 'wrap',\n          justifyContent: 'center',\n          marginTop: '8px',\n          gap: '6px',\n        }}\n      >\n        {agent_actions.map((action, idx) => {\n          const selected = selectedActions.includes(action);\n          return (\n            <button\n              key={idx}\n              onClick={() => {\n                if (selected) {\n                  setSelectedActions(selectedActions.filter((a) => a !== action));\n                } else {\n                  setSelectedActions([...selectedActions, action]);\n                }\n              }}\n              style={{\n                fontSize: '12px',\n                padding: '5px 10px',\n                backgroundColor: selected ? '#1abc9c' : '#ecf0f1',\n                color: selected ? 'white' : 'black',\n                border: '1px solid #bdc3c7',\n                borderRadius: '4px',\n                cursor: 'pointer',\n              }}\n            >\n              {action}\n            </button>\n          );\n        })}\n      </div>\n    )}\n\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\" style={{ marginBottom: '15px' }}>\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n            listening={listening}\n          />\n        </div>\n  \n\n      </div>\n\n\n\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}