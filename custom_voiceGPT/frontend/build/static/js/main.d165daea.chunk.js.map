{"version":3,"sources":["Dictaphone.jsx","MediaDisplay.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","apiInProgress","listenButton","session_listen","finalTranscript","interimTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","showTranscript","setShowTranscript","useState","fullTranscript","setFullTranscript","lastSpokenTimeRef","useRef","Date","now","silenceTimeoutRef","useEffect","prev","trim","current","clearTimeout","setTimeout","console","log","split","length","forEach","cmd","keywords","api_body","kw","keywordRegex","RegExp","found","search","keyword","SpeechRecognition","startListening","continuous","interimResults","React","createElement","Fragment","style","display","flexDirection","maxHeight","height","overflowY","border","padding","color","onClick","showTranscript_func","marginTop","clearTranscript_func","MediaDisplay","showImage","imageSrc","largeHeight","largeWidth","smallHeight","smallWidth","width","className","alignItems","justifyContent","toLowerCase","endsWith","maxWidth","borderRadius","objectFit","controls","autoPlay","loop","muted","src","type","alt","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","agent_actions","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistening","show_conversation","setshow_conversation","setlistenButton","setsession_listen","convo_button","setconvo_button","before_trigger_vars","before_trigger_","faceData","audioRef","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","setShowImage","selectedActions","setSelectedActions","windowWidth","setWindowWidth","updateWindowWidth","window","innerWidth","fetchImageData","async","response","axios","get","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","stopListening","listenContinuously","language","ret","command","text","user","body","tigger_type","face_data","selected_actions","post","pause","apiUrlWithFileName","Audio","play","Promise","resolve","onended","location","href","background_color_chat","color_dict","placeholder","flex","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","textAlign","marginLeft","marginRight","wordBreak","dangerouslySetInnerHTML","__html","resp","margin","value","onChange","event","target","onKeyDown","e","backgroundImage","animation","fontSize","cursor","click_listenButton","convo_mode","background","listenSession","Array","isArray","flexWrap","gap","action","selected","includes","filter","a","withStreamlitConnection","args","Streamlit","setFrameHeight","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"wMAsIeA,MAnIIC,IAQb,IARcC,SAClBA,EAAW,GAAEC,OACbA,EAAMC,iBACNA,GAAmB,EAAKC,iBACxBA,EAAmB,EAACC,cACpBA,GAAgB,EAAKC,aACrBA,GAAe,EAAKC,eACpBA,GAAiB,GAClBP,EACC,MAAMQ,gBACJA,EAAeC,kBACfA,EAAiBC,gBACjBA,EAAeC,UACfA,EAASC,iCACTA,EAAgCC,sBAChCA,GACEC,kCAEGC,EAAgBC,GAAqBC,oBAAS,IAC9CC,EAAgBC,GAAqBF,mBAAS,IAC/CG,EAAoBC,iBAAOC,KAAKC,OAChCC,EAAoBH,iBAAO,MAgFjC,OAvEAI,oBAAU,KACJjB,IACFW,EAAkBO,MAAWA,KAAQlB,IAAkBmB,QACvDjB,IACAU,EAAkBQ,QAAUN,KAAKC,QAElC,CAACf,IAGJiB,oBAAU,KACJhB,GACFW,EAAkBQ,QAAUN,KAAKC,MACjCM,aAAaL,EAAkBI,UACtBV,IACTM,EAAkBI,QAAUE,WAAW,KAErC,GADYR,KAAKC,MACPH,EAAkBQ,SAA8B,IAAnBxB,EAAyB,CAI9D,GAHA2B,QAAQC,IAAI,4CAA6Cd,GAG3B,KAA1BA,EAAeS,OAAe,OAGlC,GAAIpB,GAAkBW,EAAee,MAAM,KAAKC,OAAS,IAGvD,OAFAjC,EAASkC,QAAQC,GAAOlC,EAAOgB,EAAgBkB,EAAK,SACpDjB,EAAkB,IAUpB,IAAK,MAAMiB,KAAOnC,EAAU,CAC1B,MAAMoC,SAAEA,EAAQC,SAAEA,GAAaF,EAC/B,IAAK,MAAMG,KAAMF,EAAU,CACzB,MAAMG,EAAe,IAAIC,OAAOF,EAAI,KAC9BG,GAAiD,IAAzCxB,EAAeyB,OAAOH,GAEpC,IAAKE,GAASvC,GAAoBG,KAAkBD,EASlD,OARIF,EACFD,EAAOgB,EAAgB,CAAEoB,SAAU,CAAEM,QAAS,KAAQ,GAC7CF,EACTxC,EAAOgB,EAAgBkB,EAAK,GACnB9B,GACTJ,EAAOgB,EAAgBkB,EAAK,QAE9BjB,EAAkB,KAMxBY,QAAQC,IAAI,yBAEM,IAAnB5B,IAGE,IAAMyB,aAAaL,EAAkBI,UAC3C,CAACnB,EAAmBS,EAAgBd,EAAkBH,EAAUE,EAAkBG,EAAcD,EAAeH,EAAQK,IAI1HkB,oBAAU,MACHlB,GAAkBD,GAAgBH,KAAsBQ,GAC3DkC,IAAkBC,eAAe,CAAEC,YAAY,EAAMC,gBAAgB,KAEtE,CAACzC,EAAgBD,EAAcH,EAAkBQ,IAE/CC,EAIAC,EAKHoC,IAAAC,cAAAD,IAAAE,SAAA,KACGpC,GACCkC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,OAAQ,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SACjJV,IAAAC,cAAA,YAAMD,IAAAC,cAAA,cAAQ,cACdD,IAAAC,cAAA,YACGhC,EAAgB,IACjB+B,IAAAC,cAAA,QAAME,MAAO,CAAEQ,MAAO,SAAWnD,IAEnCwC,IAAAC,cAAA,YAAMD,IAAAC,cAAA,cAAQ,cAAmB,IAAEvC,EAAY,KAAO,QAG1DsC,IAAAC,cAAA,UAAQW,QAlGgBC,IAAM9C,EAAmBU,IAAUA,GAkGrB0B,MAAO,CAAEW,UAAW,SACvDhD,EAAiB,kBAAoB,mBAExCkC,IAAAC,cAAA,UAAQW,QApGiBG,KAC3BtD,IACAS,EAAkB,KAkGuBiC,MAAO,CAAEW,UAAW,SAAU,qBAlBhEd,IAAAC,cAAA,YAAM,oCAJND,IAAAC,cAAA,YAAM,sDCjEAe,MAtCIjE,IAAqG,IAApGkE,UAAEA,EAASC,SAAEA,EAAQC,YAAEA,EAAc,IAAGC,WAAEA,EAAa,IAAGC,YAAEA,EAAc,GAAEC,WAAEA,EAAa,IAAIvE,EAEjH,MAAMwD,EAASU,EAAYE,EAAcE,EACnCE,EAAQN,EAAYG,EAAaE,EAEvC,OACEtB,IAAAC,cAAA,OAAKuB,UAAU,MAAMrB,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUoB,WAAY,WAElFzB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQsB,eAAgB,SAAUH,MAAO,SAC7DL,IACCA,EAASS,cAAcC,SAAS,QAC9B5B,IAAAC,cAAA,SACEE,MAAO,CAAE0B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DxB,OAAQA,EACRgB,MAAOA,EACPS,SAAUf,EACVgB,UAAQ,EACRC,MAAM,EACNC,OAAK,GAELnC,IAAAC,cAAA,UAAQmC,IAAKlB,EAAUmB,KAAK,cAAc,gDAI5CrC,IAAAC,cAAA,OACEmC,IAAKlB,EACLX,OAAQA,EACRgB,MAAOA,EACPpB,MAAO,CAAE0B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DO,IAAI,4BCpBpB,IAEIC,EAAW,GA2qBAC,MAxqBSC,IAAU,IAAAC,EAChC,MAAMC,IAAEA,EAAGC,OAAEA,EAAS,IAAOH,GACvBzF,SACJA,EAAQuD,OACRA,EAAMgB,MACNA,EAAKsB,WACLA,EAAUC,WACVA,EAAU3F,iBACVA,EAAgB4F,WAChBA,EAAUC,QACVA,EAAOC,YACPA,EAAWC,WACXA,EAAUC,UACVA,EAASC,YACTA,EAAWC,cACXA,EAAaC,eACbA,EAAcC,cACdA,GACEX,GACG1B,EAAUsC,GAAexF,mBAAS4E,EAAOM,aACzCO,EAAeC,GAAoB1F,mBAAS4E,EAAOM,aAEnDS,EAASC,GAAc5F,mBAAS,KAChC6F,EAASC,GAAc9F,mBAAS,KAChCd,EAAkB6G,GAAuB/F,oBAAS,IAElDgG,EAAcC,GAAmBjG,oBAAS,IAC1CkG,EAAcC,GAAmBnG,oBAAS,IAC1CoG,EAAYC,GAAiBrG,mBAAS,KACtCZ,EAAekH,GAAoBtG,oBAAS,IAC5CuG,EAAUC,GAAyBxG,oBAAS,IAC5CN,EAAW+G,GAAgBzG,oBAAS,IAEpC0G,EAAmBC,GAAwB3G,oBAAS,IAGpDX,EAAcuH,GAAmB5G,oBAAS,IAC1CV,EAAgBuH,GAAqB7G,oBAAS,IAC9C8G,GAAcC,IAAmB/G,oBAAS,IAE1CgH,GAAqBC,IAAmBjH,mBAAS4E,EAAOU,gBACzD4B,GAAW9G,iBAAO,IAMlB+G,IALgB/G,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBgH,GAAoBC,IAAyBrH,oBAAS,IACtDsH,GAAYC,IAAiBvH,mBAAS,kBACtCwH,GAAmBC,IAAwBzH,mBAAS,cAEpDiD,GAAWyE,IAAgB1H,oBAAS,IACpC2H,GAAiBC,IAAsB5H,mBAAS,KAQhD6H,GAAaC,IAAkB9H,mBAAS,GAGvC+H,GAAoBA,KACF,qBAAXC,QACPF,GAAeE,OAAOC,aAK9BzH,oBAAU,KACNuH,MACD,IAEHvH,oBAAU,KACJ0E,GAEFgD,GAAehD,IAEhB,CAACA,IAEJ,MAAMgD,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,OAAOnD,IAAYoD,IAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBP,EAASQ,MAC/CpD,EAAYiD,GACZ/C,EAAiB6C,GACjB,MAAOM,GACP/H,QAAQ+H,MAAM,6BAA8BA,KAM1CC,GAAgBA,KACpBrC,GAAa,GACb7E,IAAkBkH,gBAClBhI,QAAQC,IAAI,mCAAoCrB,IAG5CqJ,GAAqBA,KACzBtC,GAAa,GACb7E,IAAkBC,eAAe,CAC/BC,YAAY,EACZkH,SAAU,WAmBhBxI,oBAAU,KACJd,EACFoB,QAAQC,IAAI,yBAEZD,QAAQC,IAAI,0BAEb,CAACrB,IAGF,MA6IMT,GAASkJ,MAAOc,EAAKC,EAAS7E,KAClCuB,OAAgBsD,EAAkB,SAAW,YAAMD,MACnD,MAAME,EAAO,IAAI5E,EAAU,CAAE6E,KAAMH,IACnCnD,EAAW,IAAIqD,IACf,IACErI,QAAQC,IAAI,wBAAyBmI,GACrC5C,GAAiB,GACjBwC,KAEA,MAAMO,EAAO,CACXC,YAAajF,EACbW,QAASA,EACTmE,KAAMA,EACNjE,WAAYO,EACZ8D,UAAWrC,GAASvG,QACpBsE,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACd/F,eAAeA,EACf0H,oBAAoBA,GACpBwC,iBAAkB7B,IAEpB7G,QAAQC,IAAI,OACZ,MAAM6H,KAAEA,SAAeP,IAAMoB,KAAK9E,EAAK0E,GAYvC,GAXAvI,QAAQC,IAAI,YAAa6H,EAAMS,GAC3BT,EAAiB,YAAKA,EAAiB,aAAMnD,GAC/CyC,GAAeU,EAAiB,YAElC9C,EAAW8C,EAAW,MACtBrE,EAAW,IAAIqE,EAAW,MAEtBzB,GAASxG,SACXwG,GAASxG,QAAQ+I,QAGfd,EAAiB,WAAG,CACtB,MAAMe,KAAwBxE,IAAYyD,EAAiB,aAC3DzB,GAASxG,QAAU,IAAIiJ,MAAMD,GAE7B,UACUxC,GAASxG,QAAQkJ,OAGvBrD,GAAsB,GACtBiB,GAAqB,kBAGf,IAAIqC,QAASC,IACf5C,GAASxG,QAAQqJ,QAAU,MACvBlJ,QAAQC,IAAI,4BACZgJ,QAIV,MAAOlB,GACL/H,QAAQ+H,MAAM,wBAAyBA,GAC1C,QAEG1B,GAASxG,QAAU,KACnB6F,GAAsB,GACtBiB,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBjB,GAAsB,GACtBF,GAAiB,GAGjBP,EAAoB6C,EAAyB,oBAC7C9H,QAAQC,IAAI,qBAAsB6H,EAAyB,mBAAG1J,IAIlC,IAAxB0J,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD9H,QAAQC,IAAI,sBAAuB6H,EAAkB,aAErDZ,OAAOiC,SAASC,KAAOtB,EAAkB,aAGvCxB,GACFC,IAAsB,GAEG,GAAlBnI,GACP4B,QAAQC,IAAI,sCACZ0G,GAAqB,sCAEdpI,EACTuH,GAAgB,GAEPE,KACPhG,QAAQC,IAAI,cACZgI,MAIF,MAAOF,GACP/H,QAAQC,IAAI,6BAA8B8H,GAC1CvC,GAAiB,GACjBM,GAAgB,GAGlBmB,KACAjH,QAAQC,IAAI,kBAGRoJ,IAAmC,OAAXlF,QAAW,IAAXA,OAAW,EAAY,QAAZP,EAAXO,EAAamF,kBAAU,IAAA1F,OAAA,EAAvBA,EAAyByF,wBAAyB,cAE1EE,gBADanF,EAAWlE,MAAM,KAAK,KAGzC,OACEgB,IAAAC,cAAAD,IAAAE,SAAA,KAEEF,IAAAC,cAAA,OAAKuB,UAAU,OACbxB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUkB,MAAO,SAE7DvB,IAAAC,cAAA,WAEED,IAAAC,cAACe,EAAY,CACXC,UAAWA,GACXC,SAAUA,EACVC,YAAa,IACbC,WAAY,IACZC,YAAa,GACbC,WAAY,MAKhBtB,IAAAC,cAAA,OAAKE,MAAO,CAAEmI,KAAMrH,GAAY,EAAI,OAAQT,UAAW,OAAQF,UAAW,UACvEoE,GACC1E,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTC,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXC,OAAQ,iBACRC,QAAS,SAGVmD,EAAQ0E,IAAI,CAACC,EAAQC,IACpBzI,IAAAC,cAAA,OACEyI,IAAKD,EACLjH,UAAU,yBACVrB,MAAO,CACLwI,aAAc,MACdjI,QAAS,MACToB,aAAc,MACdrB,OAAQ,iBACRmI,UAAW,iCAGb5I,IAAAC,cAAA,OACEuB,UAAU,YACVrB,MAAO,CACL0I,gBAAiB,UACjBC,UAAW,QACXC,WAAY,OACZrI,QAAS,QAGV0C,EAAY,KAAEpD,IAAAC,cAAA,YAAOuI,EAAOpB,OAE/BpH,IAAAC,cAAA,OACEuB,UAAU,0BACVrB,MAAO,CACLC,QAAS,OACTqB,WAAY,aACZoH,gBAAiBV,GACjBzH,QAAS,SAGVQ,GACClB,IAAAC,cAAA,OAAKuB,UAAU,aAAarB,MAAO,CAAE6I,YAAa,SAChDhJ,IAAAC,cAAA,OAAKmC,IAAKlB,EAAUoB,IAAI,WAAWnC,MAAO,CAAEoB,MAAO,WAGvDvB,IAAAC,cAAA,OACEuB,UAAU,qBACVrB,MAAO,CAAEmI,KAAM,EAAGW,UAAW,cAC7BC,wBAAyB,CAAEC,OAAQX,EAAOY,MAAQ,uBAWjEtG,GACC9C,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAEkJ,OAAQ,WACnBrJ,IAAAC,cAAA,OAAKuB,UAAU,cACbxB,IAAAC,cAAA,SACEuB,UAAU,eACVa,KAAK,OACLgG,YAAaA,GACbiB,MAAOlF,EACPmF,SA3TWC,IAEvBnF,EAAcmF,EAAMC,OAAOH,OAG3BjE,IAAsB,IAuTVqE,UApTWC,IACT,UAAVA,EAAEjB,MACJ5J,QAAQC,IAAI,kBAAmBqF,GAC/BnH,GAAOmH,EAAY,CAAE/E,SAAU,CAAEM,QAAS,KAAQ,GAClD0E,EAAc,QAmTL3G,GACWsC,IAAAC,cAAA,OACEE,MAAO,CACLoB,MAAO,MACPhB,OAAQ,OACRqJ,gBAAiB,wDACjBC,UAAW,wBACX/I,UAAW,QAGbd,IAAAC,cAAA,OAAKE,MAAO,CAAE2J,SAAU,OAAQnJ,MAAO,UAAY6E,MAMnExF,IAAAC,cAAA,MAAIE,MAAO,CAAEkJ,OAAQ,YAM3BrJ,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQU,UAAW,QAExCd,IAAAC,cAAA,OAAKE,MAAO,CAAEmI,KAAM,EAAGQ,UAAW,WAChC9I,IAAAC,cAAA,UACEE,MAAO,CACL2J,SAAU,OACVpJ,QAAS,MACT2I,OAAQ,QACRR,gBAAiB,UACjBlI,MAAO,QACPF,OAAQ,oBACRqB,aAAc,MACdiI,OAAQ,UACRxI,MAAO,OAETX,QA/PiBoJ,KACzBpF,GAAgB,GACXlH,GACHqJ,KAEFxB,GAAc,gBACdzG,QAAQC,IAAI,iCACZD,QAAQC,IAAI1B,KA0PHiI,KAMLtF,IAAAC,cAAA,OAAKE,MAAO,CAAEmI,KAAM,EAAGQ,UAAW,WAChC9I,IAAAC,cAAA,UACEE,MAAO,CACL2J,SAAU,OACVpJ,QAAS,MACT2I,OAAQ,QACRR,gBAAiB,UACjBlI,MAAO,QACPF,OAAQ,oBACRqB,aAAc,MACdiI,OAAQ,UACRxI,MAAO,OAETX,QA5aOqJ,KACjBnL,QAAQC,IAAI,aAAcrB,GACrBA,GAKHoB,QAAQC,IAAI,yBACZgG,IAAgB,GAChB+B,OANAhI,QAAQC,IAAI,yBACZgG,IAAgB,GAChBgC,QAyaSjC,GAAe,mBAAqB,sBAEtCP,GACCvE,IAAAC,cAAA,OACEE,MAAO,CAELI,OAAQ,OACR2J,WAAY,uDACZL,UAAW,4BACX/I,UAAW,MACXgB,aAAc,SAGhB9B,IAAAC,cAAA,OAAKE,MAAO,CAAE2J,SAAU,OAAQnJ,MAAO,UAAW,cAMxDX,IAAAC,cAAA,OAAKE,MAAO,CAAEmI,KAAM,EAAGQ,UAAW,WAChC9I,IAAAC,cAAA,UACEE,MAAO,CACL2J,SAAU,OACVpJ,QAAS,MACT2I,OAAQ,QACRR,gBAAiB,UACjBlI,MAAO,QACPF,OAAQ,oBACRqB,aAAc,MACdiI,OAAQ,UACRxI,MAAO,OAETX,QAxbYuJ,KAEpBtF,GADIvH,KAybKA,EAAiB,eAAiB,iBAEpCA,GACC0C,IAAAC,cAAA,OACEE,MAAO,CACLoB,MAAO,MACPhB,OAAQ,OACRqJ,gBAAiB,0DACjBC,UAAW,wBACX/I,UAAW,QAGbd,IAAAC,cAAA,OAAKE,MAAO,CAAE2J,SAAU,OAAQnJ,MAAO,UAAW,sBA0B3DyJ,MAAMC,QAAQ9G,IAAkBA,EAActE,OAAS,GACtDe,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTkK,SAAU,OACV5I,eAAgB,SAChBZ,UAAW,MACXyJ,IAAK,QAGNhH,EAAcgF,IAAI,CAACiC,EAAQ/B,KAC1B,MAAMgC,EAAW9E,GAAgB+E,SAASF,GAC1C,OACExK,IAAAC,cAAA,UACEyI,IAAKD,EACL7H,QAASA,KAELgF,GADE6E,EACiB9E,GAAgBgF,OAAQC,GAAMA,IAAMJ,GAEpC,IAAI7E,GAAiB6E,KAG5CrK,MAAO,CACL2J,SAAU,OACVpJ,QAAS,WACTmI,gBAAiB4B,EAAW,UAAY,UACxC9J,MAAO8J,EAAW,QAAU,QAC5BhK,OAAQ,oBACRqB,aAAc,MACdiI,OAAQ,YAGTS,MASPxK,IAAAC,cAAA,OAAKuB,UAAU,MAAMrB,MAAO,CAAEwI,aAAc,SAC1C3I,IAAAC,cAACnD,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,EAChBI,UAAWA,QCzpBRmN,kBAVDpI,IACZ,MAAME,IAAEA,EAAGC,OAAEA,GAAWH,EAAMqI,KAE9B,OADAtM,oBAAU,IAAMuM,IAAUC,kBAExBhL,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACgL,EAAQ,CAACtI,IAAKA,EAAKC,OAAQA,uCCLlC,MAAMsI,EAAS,IAAIC,IAGnBC,IAASC,OACPrL,IAAAC,cAACD,IAAMsL,WAAU,KACftL,IAAAC,cAACsL,IAAiB,CAACjC,MAAO4B,GACxBlL,IAAAC,cAACuL,IAAa,CAACC,MAAOC,KACpB1L,IAAAC,cAAC0L,EAAI,SAIXC,SAASC,eAAe","file":"static/js/main.d165daea.chunk.js","sourcesContent":["import React, { useState, useEffect, useRef } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands = [],\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  apiInProgress = false,\n  listenButton = false,\n  session_listen = false,\n}) => {\n  const {\n    finalTranscript,\n    interimTranscript,\n    resetTranscript,\n    listening,\n    browserSupportsSpeechRecognition,\n    isMicrophoneAvailable,\n  } = useSpeechRecognition();\n\n  const [showTranscript, setShowTranscript] = useState(true);\n  const [fullTranscript, setFullTranscript] = useState(\"\");\n  const lastSpokenTimeRef = useRef(Date.now());\n  const silenceTimeoutRef = useRef(null);\n\n  const showTranscript_func = () => setShowTranscript((prev) => !prev);\n  const clearTranscript_func = () => {\n    resetTranscript();\n    setFullTranscript(\"\");\n  };\n\n  // Accumulate final transcripts\n  useEffect(() => {\n    if (finalTranscript) {\n      setFullTranscript(prev => `${prev} ${finalTranscript}`.trim());\n      resetTranscript();\n      lastSpokenTimeRef.current = Date.now(); // Update last spoken time\n    }\n  }, [finalTranscript]);\n\n  // Detect silence\n  useEffect(() => {\n    if (interimTranscript) {\n      lastSpokenTimeRef.current = Date.now();\n      clearTimeout(silenceTimeoutRef.current);\n    } else if (fullTranscript) {\n      silenceTimeoutRef.current = setTimeout(() => {\n        const now = Date.now();\n        if (now - lastSpokenTimeRef.current >= no_response_time * 1000) {\n          console.log(\"Processing full transcript after silence:\", fullTranscript);\n\n          // Ensure transcript is not reset prematurely\n          if (fullTranscript.trim() === \"\") return;\n\n          // Process based on session mode\n          if (session_listen && fullTranscript.split(\" \").length > 500000) {\n            commands.forEach(cmd => myFunc(fullTranscript, cmd, 6));\n            setFullTranscript(\"\");\n            return;\n          }\n\n          // if (!session_listen && fullTranscript.split(\" \").length > 10000) {\n          //   setFullTranscript(\"\");\n          //   return;\n          // }\n\n          // Match keywords\n          for (const cmd of commands) {\n            const { keywords, api_body } = cmd;\n            for (const kw of keywords) {\n              const keywordRegex = new RegExp(kw, \"i\");\n              const found = fullTranscript.search(keywordRegex) !== -1;\n\n              if ((found || listenAfterReply || listenButton) && !apiInProgress) {\n                if (listenAfterReply) {\n                  myFunc(fullTranscript, { api_body: { keyword: \"\" } }, 3);\n                } else if (found) {\n                  myFunc(fullTranscript, cmd, 1);\n                } else if (listenButton) {\n                  myFunc(fullTranscript, cmd, 5);\n                }\n                setFullTranscript(\"\");\n                return;\n              }\n            }\n          }\n\n          console.log(\"No keyword matched.\");\n        }\n      }, no_response_time * 1000);\n    }\n\n    return () => clearTimeout(silenceTimeoutRef.current);\n  }, [interimTranscript, fullTranscript, no_response_time, commands, listenAfterReply, listenButton, apiInProgress, myFunc, session_listen]);\n\n\n  // Start listening on mount if needed\n  useEffect(() => {\n    if ((session_listen || listenButton || listenAfterReply) && !listening) {\n      SpeechRecognition.startListening({ continuous: true, interimResults: true });\n    }\n  }, [session_listen, listenButton, listenAfterReply, listening]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Your browser does not support speech recognition.</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please enable microphone access.</span>;\n  }\n\n  return (\n    <>\n      {showTranscript && (\n        <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"250px\", height: '250px', overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span><strong>You said:</strong></span>\n          <span>\n            {fullTranscript}{\" \"}\n            <span style={{ color: \"gray\" }}>{interimTranscript}</span>\n          </span>\n          <span><strong>Listening:</strong> {listening ? \"on\" : \"off\"}</span>\n        </div>\n      )}\n      <button onClick={showTranscript_func} style={{ marginTop: \"10px\" }}>\n        {showTranscript ? \"Hide Transcript\" : \"Show Transcript\"}\n      </button>\n      <button onClick={clearTranscript_func} style={{ marginTop: \"10px\" }}>\n        Clear Transcript\n      </button>\n    </>\n  );\n};\n\nexport default Dictaphone;","import React from 'react';\n\nconst MediaDisplay = ({ showImage, imageSrc, largeHeight = 100, largeWidth = 100, smallHeight = 40, smallWidth = 40 }) => {\n    // Determine the dimensions based on `showImage` status\n    const height = showImage ? largeHeight : smallHeight;\n    const width = showImage ? largeWidth : smallWidth;\n  \n    return (\n      <div className=\"p-2\" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center' }}>\n        {/* Always show the image or video at the top center based on `showImage` */}\n        <div style={{ display: 'flex', justifyContent: 'center', width: '100%' }}>\n          {imageSrc && (\n            imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                height={height}\n                width={width}\n                controls={showImage} // Only show controls if `showImage` is true\n                autoPlay\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img\n                src={imageSrc}\n                height={height}\n                width={width}\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                alt=\"Media Preview\"\n              />\n            )\n          )}\n        </div>\n      </div>\n    );\n  };\n  \n  export default MediaDisplay;","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\nimport MediaDisplay from \"./MediaDisplay\";\n\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n    agent_actions,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progresslistening\n  const [listening, setlistening] = useState(false); // Added state for API in progress\n\n  const [show_conversation, setshow_conversation] = useState(true); // Added state for API in progress\n  \n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n  const [convo_button, setconvo_button] = useState(false); // Added state for API in progress\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n  const [selectedActions, setSelectedActions] = useState([]);\n\n  \n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  const [windowWidth, setWindowWidth] = useState(0); // Initial value\n\n    // Create a reusable function for getting the window width\n    const updateWindowWidth = () => {\n      if (typeof window !== 'undefined') {\n          setWindowWidth(window.innerWidth);\n      }\n  };\n\n  // Call the function on component mount to set the initial window width\n  useEffect(() => {\n      updateWindowWidth();\n  }, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n\n\n  const stopListening = () => {\n    setlistening(false);\n    SpeechRecognition.stopListening();\n    console.log(\"Stopping Listening, isListening=\", listening)\n  }\n\n  const listenContinuously = () =>{\n    setlistening(true)\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n\n}\n\n\nconst convo_mode = () => {\n  console.log(\"listening?\", listening);\n  if (!listening) {\n    console.log(\"Starting to listen...\");\n    setconvo_button(true)\n    listenContinuously();\n  } else {\n    console.log(\"Stopping listening...\");\n    setconvo_button(false)\n    stopListening();\n  }\n};\n\nuseEffect(() => {\n  if (listening) {\n    console.log(\"Listening has started\");\n  } else {\n    console.log(\"Listening has stopped\");\n  }\n}, [listening]);\n\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  // useEffect(() => {\n  //   const loadModels = async () => {\n  //     const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n  //     Promise.all([\n  //       faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n  //       faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n  //     ]).then(() => setModelsLoaded(true));\n  //   };\n  //   loadModels();\n  //   const interval = setInterval(() => {\n  //     // console.log(\"faceData.current :>> \", faceData.current);\n  //   }, 3000);\n  //   return () => clearInterval(interval);\n  // }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  // const startVideo = () => {\n  //   setCaptureVideo(true);\n  //   navigator.mediaDevices\n  //     .getUserMedia({ video: { width: 300 } })\n  //     .then((stream) => {\n  //       let video = videoRef.current;\n  //       video.srcObject = stream;\n  //       video.play();\n  //     })\n  //     .catch((err) => {\n  //       console.error(\"error:\", err);\n  //     });\n  // };\n\n  // const handleVideoOnPlay = () => {\n  //   setInterval(async () => {\n  //     if (canvasRef && canvasRef.current) {\n  //       canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n  //         videoRef.current\n  //       );\n  //       const displaySize = {\n  //         width: videoWidth,\n  //         height: videoHeight,\n  //       };\n\n  //       faceapi.matchDimensions(canvasRef.current, displaySize);\n\n  //       const detections = await faceapi\n  //         .detectAllFaces(\n  //           videoRef.current,\n  //           new faceapi.TinyFaceDetectorOptions()\n  //         )\n  //         .withFaceLandmarks()\n  //         .withFaceExpressions();\n\n  //       const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n  //       if (resizedDetections.length > 0) {\n  //         faceData.current = resizedDetections;\n  //         if (!faceTriggered.current && face_recon) {\n  //           myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n  //           faceTriggered.current = true;\n  //         }\n  //       } else {\n  //         faceTimer && clearTimeout(faceTimer);\n  //         setTimeout(() => {\n  //           faceData.current = [];\n  //         }, 1000);\n  //       }\n\n  //       if (resizedDetections.length > 0 && !firstFace) {\n  //         firstFace = true;\n  //         if (kwargs.hello_audio) {\n  //           const audio = new Audio(kwargs.hello_audio);\n  //           audio.play();\n  //         }\n  //       }\n\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         canvasRef.current\n  //           .getContext(\"2d\")\n  //           .clearRect(0, 0, videoWidth, videoHeight);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n  //       canvasRef &&\n  //         canvasRef.current &&\n  //         faceapi.draw.drawFaceExpressions(\n  //           canvasRef.current,\n  //           resizedDetections\n  //         );\n  //     }\n  //   }, 300);\n  // };\n\n  // const closeWebcam = () => {\n  //   videoRef.current.pause();\n  //   videoRef.current.srcObject.getTracks()[0].stop();\n  //   setCaptureVideo(false);\n  // };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    if (!listening) {\n      listenContinuously()\n    }\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n        selected_actions: selectedActions,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"], listenAfterReply);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n\n      if (UserUsedChatWindow) {\n        setUserUsedChatWindow(false)\n      }\n      else if (listenAfterReply==true) {\n        console.log(\"API END HIT listenAfterReply==TRUE\")\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (convo_button){\n        console.log(\"convo mode\")\n        listenContinuously()\n      }\n\n      \n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n\n    updateWindowWidth();\n    console.log(\"ReSize Window\")\n  };\n  \n  const background_color_chat = refresh_ask?.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'column', width: '100%' }}>\n          {/* Image or video section */}\n          <div>\n            {/* Media Display */}\n            <MediaDisplay\n              showImage={showImage}\n              imageSrc={imageSrc}\n              largeHeight={100}   // Customize as needed\n              largeWidth={100}    // Customize as needed\n              smallHeight={40}    // Customize as needed\n              smallWidth={40}     // Customize as needed\n            />\n          </div>\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '350px' }}>\n            {show_conversation && (\n              <div\n                style={{\n                  display: 'flex',\n                  flexDirection: 'column',\n                  maxHeight: '350px',\n                  height: '350px',\n                  overflowY: 'auto',\n                  border: '1px solid #ccc',\n                  padding: '10px',\n                }}\n              >\n                {answers.map((answer, idx) => (\n                  <div\n                    key={idx}\n                    className=\"chat-message-container\"\n                    style={{\n                      marginBottom: '5px',\n                      padding: '5px',\n                      borderRadius: '4px',\n                      border: '1px solid #ccc',\n                      boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',\n                    }}\n                  >\n                    <div\n                      className=\"chat-user\"\n                      style={{\n                        backgroundColor: '#e4eafe',\n                        textAlign: 'right',\n                        marginLeft: 'auto',\n                        padding: '5px',\n                      }}\n                    >\n                      {client_user}: <span>{answer.user}</span>\n                    </div>\n                    <div\n                      className=\"chat-response-container\"\n                      style={{\n                        display: 'flex',\n                        alignItems: 'flex-start',\n                        backgroundColor: background_color_chat,\n                        padding: '10px',\n                      }}\n                    >\n                      {imageSrc && (\n                        <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                          <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} />\n                        </div>\n                      )}\n                      <div\n                        className=\"chat-response-text\"\n                        style={{ flex: 1, wordBreak: 'break-word' }}\n                        dangerouslySetInnerHTML={{ __html: answer.resp || \"thinking...\" }}\n                      />\n                    </div>\n                  </div>\n                ))}\n              </div>\n            )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '3px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n\n              {listening && (\n                          <div\n                            style={{\n                              width: '89%',\n                              height: '10px',\n                              backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                              animation: 'flashLine 1s infinite',\n                              marginTop: '5px',\n                            }}\n                          >\n                            <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n                          </div>\n                        )}\n\n\n            </div>\n            <hr style={{ margin: '3px 0' }} />\n          </>\n        )}\n\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '3px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={convo_mode}\n          >\n            {convo_button ? \"End Conversation\" : \"Start Conversation\"}\n          </button>\n          {speaking && (\n            <div\n              style={{\n                // width: '89%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={listenSession}\n          >\n            {session_listen ? \"Stop Session\" : \"Start Session\"}\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n        {/* Toggle Image Button\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={stopListening}\n          >\n            {listening ? \"Stop Listening\" : \"\"}\n          </button>\n        </div> */}\n      </div>\n\n    {/* Agent Actions Horizontal Button-Style Multi-Select */}\n    {Array.isArray(agent_actions) && agent_actions.length > 0 && (\n      <div\n        style={{\n          display: 'flex',\n          flexWrap: 'wrap',\n          justifyContent: 'center',\n          marginTop: '8px',\n          gap: '6px',\n        }}\n      >\n        {agent_actions.map((action, idx) => {\n          const selected = selectedActions.includes(action);\n          return (\n            <button\n              key={idx}\n              onClick={() => {\n                if (selected) {\n                  setSelectedActions(selectedActions.filter((a) => a !== action));\n                } else {\n                  setSelectedActions([...selectedActions, action]);\n                }\n              }}\n              style={{\n                fontSize: '12px',\n                padding: '5px 10px',\n                backgroundColor: selected ? '#1abc9c' : '#ecf0f1',\n                color: selected ? 'white' : 'black',\n                border: '1px solid #bdc3c7',\n                borderRadius: '4px',\n                cursor: 'pointer',\n              }}\n            >\n              {action}\n            </button>\n          );\n        })}\n      </div>\n    )}\n\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\" style={{ marginBottom: '15px' }}>\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n            listening={listening}\n          />\n        </div>\n  \n\n      </div>\n\n\n\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}