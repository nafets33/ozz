{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","MediaDisplay.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","apiInProgress","listenButton","session_listen","finalTranscript","interimTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","show_transcript","setShowTranscript","useState","useEffect","console","log","split","length","i","timer","setTimeout","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","maxHeight","height","overflowY","border","padding","onClick","showTranscript_func","prev","marginTop","clearTranscript_func","MediaDisplay","showImage","imageSrc","largeHeight","largeWidth","smallHeight","smallWidth","width","className","alignItems","justifyContent","toLowerCase","endsWith","maxWidth","borderRadius","objectFit","controls","autoPlay","loop","muted","src","type","alt","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistening","show_conversation","setshow_conversation","setlistenButton","setsession_listen","convo_button","setconvo_button","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","setShowImage","windowWidth","setWindowWidth","updateWindowWidth","window","innerWidth","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","stopListening","SpeechRecognition","listenContinuously","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","setInterval","clearInterval","ret","command","text","user","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","location","href","background_color_chat","color_dict","splitImage","placeholder","flex","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","textAlign","marginLeft","marginRight","wordBreak","resp","margin","value","onChange","event","target","onKeyDown","fontSize","color","cursor","click_listenButton","backgroundImage","animation","convo_mode","background","listenSession","withStreamlitConnection","args","Streamlit","setFrameHeight","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,gJCqGVC,MA1GIC,IAQZ,IARa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,cACpBC,GAAgB,EAAK,aACrBC,GAAe,EAAK,eACpBC,GAAiB,GAClBP,EACC,MAAM,gBACJQ,EAAe,kBACfC,EAAiB,gBACjBC,EAAe,UACfC,EAAS,iCACTC,EAAgC,sBAChCC,GACEC,kCAEGC,EAAiBC,GAAqBC,oBAAS,GA8DtD,OAzDAC,oBAAU,KACR,GAAwB,KAApBV,EAAwB,CAM1B,GALAW,QAAQC,IAAI,oBAAqBZ,GACjCW,QAAQC,IAAI,aAAcT,GAC1BQ,QAAQC,IAAI,oBAAqBjB,GAG7BI,GAAkBC,EAAgBa,MAAM,KAAKC,OAAS,IAAQ,CAChEH,QAAQC,IAAI,8BACZ,IAAK,IAAIG,EAAI,EAAGA,EAAItB,EAASqB,OAAQC,IACnCrB,EAAOM,EAAiBP,EAASsB,GAAI,GAGvC,YADAb,IAIF,IAAKH,GAAkBC,EAAgBa,MAAM,KAAKC,OAAS,IAGzD,OAFAH,QAAQC,IAAI,kDACZV,IAKF,MAAMc,EAAQC,WAAW,KAEvB,GAAIhB,EACFU,QAAQC,IAAI,kDADd,CAMA,IAAK,IAAIG,EAAI,EAAGA,EAAItB,EAASqB,OAAQC,IAAK,CACxC,MAAM,SAAEG,EAAQ,SAAEC,GAAa1B,EAASsB,GACxC,IAAK,IAAIK,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCvB,EAAgBwB,OAAOH,GAE9C,IAAKE,GAAkB5B,GAAoBG,KAAkBD,EAS3D,OARIF,EACFD,EAAOM,EAAiB,CAAEmB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACT7B,EAAOM,EAAiBP,EAASsB,GAAI,GAC5BjB,GACTJ,EAAOM,EAAiBP,EAASsB,GAAI,QAEvCb,KAKNS,QAAQC,IAAI,2BACQ,IAAnBhB,GAEH,MAAO,IAAM6B,aAAaT,KAE3B,CAAChB,EAAiBC,EAAmBE,EAAWR,EAAkBF,EAAUG,EAAkBM,EAAiBL,EAAeC,IAE5HM,EAIAC,EAKHqB,IAAAC,cAAAD,IAAAE,SAAA,KACGrB,GACCmB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,OAAQ,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SACjJV,IAAAC,cAAA,YAAM,aAAW3B,GAAmBC,GACpCyB,IAAAC,cAAA,YAAM,cAAYxB,EAAY,KAAO,QAGzCuB,IAAAC,cAAA,UAAQU,QA5EgBC,IAAM9B,EAAmB+B,IAAUA,GA4ErBV,MAAO,CAAEW,UAAW,SACvDjC,EAAkB,kBAAoB,mBAEzCmB,IAAAC,cAAA,UAAQU,QA9EiBI,IAAMvC,IA8EQ2B,MAAO,CAAEW,UAAW,SAAU,qBAdhEd,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uBC5CAe,MAtCIlD,IAAsG,IAArG,UAAEmD,EAAS,SAAEC,EAAQ,YAAEC,EAAc,IAAG,WAAEC,EAAa,IAAG,YAAEC,EAAc,GAAE,WAAEC,EAAa,IAAIxD,EAEjH,MAAMyC,EAASU,EAAYE,EAAcE,EACnCE,EAAQN,EAAYG,EAAaE,EAEvC,OACEtB,IAAAC,cAAA,OAAKuB,UAAU,MAAMrB,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUoB,WAAY,WAElFzB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQsB,eAAgB,SAAUH,MAAO,SAC7DL,IACCA,EAASS,cAAcC,SAAS,QAC9B5B,IAAAC,cAAA,SACEE,MAAO,CAAE0B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DxB,OAAQA,EACRgB,MAAOA,EACPS,SAAUf,EACVgB,UAAQ,EACRC,MAAM,EACNC,OAAK,GAELnC,IAAAC,cAAA,UAAQmC,IAAKlB,EAAUmB,KAAK,cAAc,gDAI5CrC,IAAAC,cAAA,OACEmC,IAAKlB,EACLX,OAAQA,EACRgB,MAAOA,EACPpB,MAAO,CAAE0B,SAAU,OAAQC,aAAc,MAAOC,UAAW,SAC3DO,IAAI,sB,aCpBpB,IAEIC,EAAW,GA+nBAC,MA5nBSC,IAAW,IAADC,EAChC,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOH,GACvB,SACJ1E,EAAQ,OACRwC,EAAM,MACNgB,EAAK,WACLsB,EAAU,WACVC,EAAU,iBACV5E,EAAgB,WAChB6E,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,EAAa,eACbC,GACEV,GACG1B,EAAUqC,GAAexE,mBAAS6D,EAAOM,aACzCM,EAAeC,GAAoB1E,mBAAS6D,EAAOM,aAEnDQ,EAASC,GAAc5E,mBAAS,KAChC6E,EAASC,GAAc9E,mBAAS,KAChCd,EAAkB6F,GAAuB/E,oBAAS,IAElDgF,EAAcC,GAAmBjF,oBAAS,IAC1CkF,EAAcC,GAAmBnF,oBAAS,IAC1CoF,EAAYC,GAAiBrF,mBAAS,KACtCZ,EAAekG,GAAoBtF,oBAAS,IAC5CuF,EAAUC,GAAyBxF,oBAAS,IAC5CN,EAAW+F,GAAgBzF,oBAAS,IAEpC0F,EAAmBC,GAAwB3F,oBAAS,IAGpDX,EAAcuG,GAAmB5F,oBAAS,IAC1CV,EAAgBuG,GAAqB7F,oBAAS,IAC9C8F,GAAcC,IAAmB/F,oBAAS,IAE1CgG,GAAqBC,IAAmBjG,mBAAS6D,EAAOU,gBACzD2B,GAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBE,GAAoBC,IAAyBtG,oBAAS,IACtDuG,GAAYC,IAAiBxG,mBAAS,kBACtCyG,GAAmBC,IAAwB1G,mBAAS,cAEpDkC,GAAWyE,IAAgB3G,oBAAS,IAQpC4G,GAAaC,IAAkB7G,mBAAS,GAGvC8G,GAAoBA,KACF,qBAAXC,QACPF,GAAeE,OAAOC,aAK9B/G,oBAAU,KACN6G,MACD,IAEH7G,oBAAU,KACJkE,GAEF8C,GAAe9C,IAEhB,CAACA,IAEJ,MAAM8C,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAIlD,GAASkD,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/CpD,EAAYiD,GACZ/C,EAAiB6C,GACjB,MAAOM,GACP3H,QAAQ2H,MAAM,6BAA8BA,KAM1CC,GAAgBA,KACpBrC,GAAa,GACbsC,IAAkBD,gBAClB5H,QAAQC,IAAI,mCAAoCT,IAG5CsI,GAAqBA,KACzBvC,GAAa,GACbsC,IAAkBE,eAAe,CAC/BC,YAAY,EACZC,SAAU,WAmBhBlI,oBAAU,KACJP,EACFQ,QAAQC,IAAI,yBAEZD,QAAQC,IAAI,0BAEb,CAACT,IAYFO,oBAAU,KACWiH,WAGjBkB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAM7D,GAAgB,KAEhC8D,GACA,MAAMC,EAAWC,YAAY,OAE1B,KACH,MAAO,IAAMC,cAAcF,IAC1B,IAsHH,MAAM/J,GAASiI,MAAOiC,EAAKC,EAAS9F,KAClCsB,EAAW,KAAD0C,OAAM8B,EAAkB,SAAW,QAAC,MAAA9B,OAAK6B,EAAG,MACtD,MAAME,EAAO,IAAI7F,EAAU,CAAE8F,KAAMH,IACnCrE,EAAW,IAAIuE,IACf,IACEnJ,QAAQC,IAAI,wBAAyBiJ,GACrC9D,GAAiB,GACjBwC,KAEA,MAAMyB,EAAO,CACXC,YAAalG,EACbW,QAASA,EACToF,KAAMA,EACNlF,WAAYM,EACZgF,UAAWvD,GAASwD,QACpBxF,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdhF,eAAeA,EACf0G,oBAAoBA,IAEtB9F,QAAQC,IAAI,OACZ,MAAM,KAAEyH,SAAeR,IAAMuC,KAAK/F,EAAK2F,GAYvC,GAXArJ,QAAQC,IAAI,YAAayH,EAAM2B,GAC3B3B,EAAiB,YAAKA,EAAiB,aAAMnD,GAC/CwC,GAAeW,EAAiB,YAElC9C,EAAW8C,EAAW,MACtBpE,EAAW,IAAIoE,EAAW,MAEtBxB,GAASsD,SACXtD,GAASsD,QAAQE,QAGfhC,EAAiB,WAAG,CACtB,MAAMiC,EAAkB,GAAAvC,OAAMlD,GAASkD,OAAGM,EAAiB,YAC3DxB,GAASsD,QAAU,IAAII,MAAMD,GAE7B,UACUzD,GAASsD,QAAQK,OAGvBvE,GAAsB,GACtBkB,GAAqB,kBAGf,IAAI0B,QAAS1J,IACf0H,GAASsD,QAAQM,QAAU,KACvB9J,QAAQC,IAAI,4BACZzB,OAIV,MAAOmJ,GACL3H,QAAQ2H,MAAM,wBAAyBA,GAC1C,QAEGzB,GAASsD,QAAU,KACnBlE,GAAsB,GACtBkB,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBlB,GAAsB,GACtBF,GAAiB,GAEjBpF,QAAQC,IAAI,kCAEZ4E,EAAoB6C,EAAyB,oBAC7C1H,QAAQC,IAAI,qBAAsByH,EAAyB,mBAAG1I,IAIlC,IAAxB0I,EAAkB,aAAuC,OAAxBA,EAAkB,cACrD1H,QAAQC,IAAI,sBAAuByH,EAAkB,aAErDb,OAAOkD,SAASC,KAAOtC,EAAkB,aAGvCvB,GACFC,IAAsB,GAEG,GAAlBpH,GACPgB,QAAQC,IAAI,sCACZuG,GAAqB,sCAEdrH,EACTuG,GAAgB,GAEPE,KACP5F,QAAQC,IAAI,cACZ6H,MAIF,MAAOH,GACP3H,QAAQC,IAAI,6BAA8B0H,GAC1CvC,GAAiB,GACjBM,GAAgB,GAGlBkB,KACA5G,QAAQC,IAAI,kBAGRgK,IAA8C,QAAtBxG,EAAAO,EAAYkG,kBAAU,IAAAzG,OAAA,EAAtBA,EAAwBwG,wBAAyB,cACzEE,GAAalG,EAAW/D,MAAM,KAAK,GACnCkK,GAAW,aAAAhD,OAAgB+C,IAEjC,OACEpJ,IAAAC,cAAAD,IAAAE,SAAA,KAEEF,IAAAC,cAAA,OAAKuB,UAAU,OACbxB,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUkB,MAAO,SAE7DvB,IAAAC,cAAA,WAEED,IAAAC,cAACe,EAAY,CACXC,UAAWA,GACXC,SAAUA,EACVC,YAAa,IACbC,WAAY,IACZC,YAAa,GACbC,WAAY,MAKhBtB,IAAAC,cAAA,OAAKE,MAAO,CAAEmJ,KAAMrI,GAAY,EAAI,OAAQT,UAAW,OAAQF,UAAW,UACzEmE,GACCzE,IAAAC,cAAA,OACEE,MAAO,CACLC,QAAS,OACTC,cAAe,SACfC,UAAW,QACXC,OAAQ,QACRC,UAAW,OACXC,OAAQ,iBACRC,QAAS,SAGVkD,EAAQ2F,IAAI,CAACC,EAAQC,IACpBzJ,IAAAC,cAAA,OACEyJ,IAAKD,EACLjI,UAAU,yBACVrB,MAAO,CACLwJ,aAAc,MACdjJ,QAAS,MACToB,aAAc,MACdrB,OAAQ,iBACRmJ,UAAW,iCAIb5J,IAAAC,cAAA,OACEuB,UAAU,YACVrB,MAAO,CACL0J,gBAAiB,UACjBC,UAAW,QACXC,WAAY,OACZrJ,QAAS,QAGV0C,EAAY,KAAEpD,IAAAC,cAAA,YAAOuJ,EAAOnB,OAE/BrI,IAAAC,cAAA,OACEuB,UAAU,0BACVrB,MAAO,CACLC,QAAS,OACTqB,WAAY,aACZoI,gBAAiBX,GACjBxI,QAAS,SAIVQ,GACClB,IAAAC,cAAA,OAAKuB,UAAU,aAAarB,MAAO,CAAE6J,YAAa,SAChDhK,IAAAC,cAAA,OAAKmC,IAAKlB,EAAUoB,IAAI,WAAWnC,MAAO,CAAEoB,MAAO,WAIvDvB,IAAAC,cAAA,OAAKuB,UAAU,qBAAqBrB,MAAO,CAAEmJ,KAAM,EAAGW,UAAW,eAC9DT,EAAOU,MAAQ,qBAW7BpH,GACC9C,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAEgK,OAAQ,WACnBnK,IAAAC,cAAA,OAAKuB,UAAU,cACbxB,IAAAC,cAAA,SACEuB,UAAU,eACVa,KAAK,OACLgH,YAAaA,GACbe,MAAOjG,EACPkG,SA/TWC,IAEvBlG,EAAckG,EAAMC,OAAOH,OAG3B/E,IAAsB,IA2TVmF,UAxTWnN,IACT,UAAVA,EAAEqM,MACJzK,QAAQC,IAAI,kBAAmBiF,GAC/BnG,GAAOmG,EAAY,CAAE1E,SAAU,CAAEE,QAAS,KAAQ,GAClDyE,EAAc,SAuTRpE,IAAAC,cAAA,MAAIE,MAAO,CAAEgK,OAAQ,YAK3BnK,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQU,UAAW,QAExCd,IAAAC,cAAA,OAAKE,MAAO,CAAEmJ,KAAM,EAAGQ,UAAW,WAChC9J,IAAAC,cAAA,UACEE,MAAO,CACLsK,SAAU,OACV/J,QAAS,MACTyJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACPjK,OAAQ,oBACRqB,aAAc,MACd6I,OAAQ,UACRpJ,MAAO,OAETZ,QAlPiBiK,KACzBjG,GAAgB,GACXlG,GACHsI,KAEFxB,GAAc,gBACdtG,QAAQC,IAAI,iCACZD,QAAQC,IAAId,KA6OHkH,IAEF7G,GACCuB,IAAAC,cAAA,OACEE,MAAO,CACLoB,MAAO,MACPhB,OAAQ,OACRsK,gBAAiB,wDACjBC,UAAW,wBACXhK,UAAW,QAGbd,IAAAC,cAAA,OAAKE,MAAO,CAAEsK,SAAU,OAAQC,MAAO,UAAYlF,MAMzDxF,IAAAC,cAAA,OAAKE,MAAO,CAAEmJ,KAAM,EAAGQ,UAAW,WAChC9J,IAAAC,cAAA,UACEE,MAAO,CACLsK,SAAU,OACV/J,QAAS,MACTyJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACPjK,OAAQ,oBACRqB,aAAc,MACd6I,OAAQ,UACRpJ,MAAO,OAETZ,QA3aOoK,KACjB9L,QAAQC,IAAI,aAAcT,GACrBA,GAKHQ,QAAQC,IAAI,yBACZ4F,IAAgB,GAChB+B,OANA5H,QAAQC,IAAI,yBACZ4F,IAAgB,GAChBiC,QAwaSlC,GAAe,mBAAqB,sBAEtCP,GACCtE,IAAAC,cAAA,OACEE,MAAO,CAELI,OAAQ,OACRyK,WAAY,uDACZF,UAAW,4BACXhK,UAAW,MACXgB,aAAc,SAGhB9B,IAAAC,cAAA,OAAKE,MAAO,CAAEsK,SAAU,OAAQC,MAAO,UAAW,cAMxD1K,IAAAC,cAAA,OAAKE,MAAO,CAAEmJ,KAAM,EAAGQ,UAAW,WAChC9J,IAAAC,cAAA,UACEE,MAAO,CACLsK,SAAU,OACV/J,QAAS,MACTyJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACPjK,OAAQ,oBACRqB,aAAc,MACd6I,OAAQ,UACRpJ,MAAO,OAETZ,QAvbYsK,KAEpBrG,GADIvG,KAwbKA,EAAiB,eAAiB,iBAEpCA,GACC2B,IAAAC,cAAA,OACEE,MAAO,CACLoB,MAAO,MACPhB,OAAQ,OACRsK,gBAAiB,0DACjBC,UAAW,wBACXhK,UAAW,QAGbd,IAAAC,cAAA,OAAKE,MAAO,CAAEsK,SAAU,OAAQC,MAAO,UAAW,qBAMxD1K,IAAAC,cAAA,OAAKE,MAAO,CAAEmJ,KAAM,EAAGQ,UAAW,WAChC9J,IAAAC,cAAA,UACEE,MAAO,CACLsK,SAAU,OACV/J,QAAS,MACTyJ,OAAQ,QACRN,gBAAiB,UACjBa,MAAO,QACPjK,OAAQ,oBACRqB,aAAc,MACd6I,OAAQ,WAEVhK,QAASkG,IAERpI,EAAY,iBAAmB,MAMpCuB,IAAAC,cAAA,OAAKuB,UAAU,MAAMrB,MAAO,CAAEwJ,aAAc,SAC1C3J,IAAAC,cAACpC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,EAChBI,UAAWA,QC7mBRyM,kBAVDzI,IACZ,MAAM,IAAEE,EAAG,OAAEC,GAAWH,EAAM0I,KAE9B,OADAnM,oBAAU,IAAMoM,IAAUC,kBAExBrL,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACqL,EAAQ,CAAC3I,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAM2I,EAAS,IAAIC,IAGnBC,IAASC,OACP1L,IAAAC,cAACD,IAAM2L,WAAU,KACf3L,IAAAC,cAAC2L,IAAiB,CAACxB,MAAOmB,GACxBvL,IAAAC,cAAC4L,IAAa,CAACC,MAAOC,KACpB/L,IAAAC,cAAC+L,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.ba8bf9ba.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 20;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  apiInProgress = false,\n  listenButton = false,\n  session_listen = false,\n}) => {\n  const {\n    finalTranscript,\n    interimTranscript,\n    resetTranscript,\n    listening,\n    browserSupportsSpeechRecognition,\n    isMicrophoneAvailable,\n  } = useSpeechRecognition();\n  \n  const [show_transcript, setShowTranscript] = useState(true);\n\n  const showTranscript_func = () => setShowTranscript((prev) => !prev);\n  const clearTranscript_func = () => resetTranscript();\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"Listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds limits\n      if (session_listen && finalTranscript.split(\" \").length > 500000) {\n        console.log(\"Transcript exceeds X words\");\n        for (let i = 0; i < commands.length; i++) {\n          myFunc(finalTranscript, commands[i], 6);\n        }\n        resetTranscript();\n        return;\n      }\n\n      if (!session_listen && finalTranscript.split(\" \").length > 10000) {\n        console.log(\"Transcript exceeds 10000 words. Clearing.\");\n        resetTranscript();\n        return;\n      }\n\n      // Clear any existing timers to prevent multiple triggers\n      const timer = setTimeout(() => {\n        // Check if user is still speaking\n        if (interimTranscript) {\n          console.log(\"User is still speaking, resetting timer...\");\n          return; // Reset timer and do not trigger API\n        }\n\n        // Proceed to check for keywords\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              } else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        console.log(\"Waiting for a keyword\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, interimTranscript, listening, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_transcript && (\n        <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"250px\", height: '250px', overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span>You said: {finalTranscript || interimTranscript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n        </div>\n      )}\n      <button onClick={showTranscript_func} style={{ marginTop: \"10px\" }}>\n        {show_transcript ? \"Hide Transcript\" : \"Show Transcript\"}\n      </button>\n      <button onClick={clearTranscript_func} style={{ marginTop: \"10px\" }}>\n        Clear Transcript\n      </button>\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React from 'react';\n\nconst MediaDisplay = ({ showImage, imageSrc, largeHeight = 100, largeWidth = 100, smallHeight = 40, smallWidth = 40 }) => {\n    // Determine the dimensions based on `showImage` status\n    const height = showImage ? largeHeight : smallHeight;\n    const width = showImage ? largeWidth : smallWidth;\n  \n    return (\n      <div className=\"p-2\" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center' }}>\n        {/* Always show the image or video at the top center based on `showImage` */}\n        <div style={{ display: 'flex', justifyContent: 'center', width: '100%' }}>\n          {imageSrc && (\n            imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                height={height}\n                width={width}\n                controls={showImage} // Only show controls if `showImage` is true\n                autoPlay\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img\n                src={imageSrc}\n                height={height}\n                width={width}\n                style={{ maxWidth: '100%', borderRadius: '8px', objectFit: 'cover' }}\n                alt=\"Media Preview\"\n              />\n            )\n          )}\n        </div>\n      </div>\n    );\n  };\n  \n  export default MediaDisplay;","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\nimport MediaDisplay from \"./MediaDisplay\";\n\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progresslistening\n  const [listening, setlistening] = useState(false); // Added state for API in progress\n\n  const [show_conversation, setshow_conversation] = useState(true); // Added state for API in progress\n  \n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n  const [convo_button, setconvo_button] = useState(false); // Added state for API in progress\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n\n  \n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n  const [windowWidth, setWindowWidth] = useState(0); // Initial value\n\n    // Create a reusable function for getting the window width\n    const updateWindowWidth = () => {\n      if (typeof window !== 'undefined') {\n          setWindowWidth(window.innerWidth);\n      }\n  };\n\n  // Call the function on component mount to set the initial window width\n  useEffect(() => {\n      updateWindowWidth();\n  }, []);\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n\n\n  const stopListening = () => {\n    setlistening(false);\n    SpeechRecognition.stopListening();\n    console.log(\"Stopping Listening, isListening=\", listening)\n  }\n\n  const listenContinuously = () =>{\n    setlistening(true)\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n\n}\n\n\nconst convo_mode = () => {\n  console.log(\"listening?\", listening);\n  if (!listening) {\n    console.log(\"Starting to listen...\");\n    setconvo_button(true)\n    listenContinuously();\n  } else {\n    console.log(\"Stopping listening...\");\n    setconvo_button(false)\n    stopListening();\n  }\n};\n\nuseEffect(() => {\n  if (listening) {\n    console.log(\"Listening has started\");\n  } else {\n    console.log(\"Listening has stopped\");\n  }\n}, [listening]);\n\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    if (!listening) {\n      listenContinuously()\n    }\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  function isHTML(str) {\n    return /^</.test(str);\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"], listenAfterReply);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n\n      if (UserUsedChatWindow) {\n        setUserUsedChatWindow(false)\n      }\n      else if (listenAfterReply==true) {\n        console.log(\"API END HIT listenAfterReply==TRUE\")\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (convo_button){\n        console.log(\"convo mode\")\n        listenContinuously()\n      }\n\n      \n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n\n    updateWindowWidth();\n    console.log(\"ReSize Window\")\n  };\n  \n  const background_color_chat = refresh_ask.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'column', width: '100%' }}>\n          {/* Image or video section */}\n          <div>\n            {/* Media Display */}\n            <MediaDisplay\n              showImage={showImage}\n              imageSrc={imageSrc}\n              largeHeight={100}   // Customize as needed\n              largeWidth={100}    // Customize as needed\n              smallHeight={40}    // Customize as needed\n              smallWidth={40}     // Customize as needed\n            />\n          </div>\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '350px' }}>\n          {show_conversation && (\n            <div\n              style={{\n                display: 'flex',\n                flexDirection: 'column',\n                maxHeight: '350px', // Set your desired max height\n                height: '350px', // Fixed height to ensure no resizing\n                overflowY: 'auto', // Enable scrolling within this container\n                border: '1px solid #ccc',\n                padding: '10px',\n              }}\n            >\n              {answers.map((answer, idx) => (\n                <div\n                  key={idx}\n                  className=\"chat-message-container\"\n                  style={{\n                    marginBottom: '5px',\n                    padding: '5px',\n                    borderRadius: '4px',\n                    border: '1px solid #ccc', // Inner border for each message\n                    boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',\n                    // backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2', // Background color\n                  }}\n                >\n                  <div\n                    className=\"chat-user\"\n                    style={{\n                      backgroundColor: '#f2f2f2',\n                      textAlign: 'right',\n                      marginLeft: 'auto',\n                      padding: '5px',\n                    }}\n                  >\n                    {client_user}: <span>{answer.user}</span>\n                  </div>\n                  <div\n                    className=\"chat-response-container\"\n                    style={{\n                      display: 'flex',\n                      alignItems: 'flex-start',\n                      backgroundColor: background_color_chat,\n                      padding: '10px', // Padding for better spacing\n                    }}\n                  >\n                    {/* Optional image on the left side */}\n                    {imageSrc && (\n                      <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                        <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} />\n                      </div>\n                    )}\n                    {/* Wrapping response text */}\n                    <div className=\"chat-response-text\" style={{ flex: 1, wordBreak: 'break-word' }}>\n                      {answer.resp || \"thinking...\"}\n                    </div>\n                  </div>\n                </div>\n              ))}\n            </div>\n          )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '3px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '3px 0' }} />\n          </>\n        )}\n\n      {/* Buttons with indicators under each */}\n      <div style={{ display: 'flex', marginTop: '3px' }}>\n        {/* Button 1 with Listen Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          {listening && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>{buttonName_listen}</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 2 with Conversational Mode Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={convo_mode}\n          >\n            {convo_button ? \"End Conversation\" : \"Start Conversation\"}\n          </button>\n          {speaking && (\n            <div\n              style={{\n                // width: '89%',\n                height: '10px',\n                background: 'linear-gradient(to right, blue, transparent, purple)',\n                animation: 'waveAnimation 1s infinite',\n                marginTop: '5px',\n                borderRadius: '10px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Speaking</div>\n            </div>\n          )}\n        </div>\n\n        {/* Button 3 with Session Started Indicator */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n              width: '89%',\n            }}\n            onClick={listenSession}\n          >\n            {session_listen ? \"Stop Session\" : \"Start Session\"}\n          </button>\n          {session_listen && (\n            <div\n              style={{\n                width: '89%',\n                height: '10px',\n                backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                animation: 'flashLine 1s infinite',\n                marginTop: '5px',\n              }}\n            >\n              <div style={{ fontSize: '12px', color: 'black' }}>Session Started</div>\n            </div>\n          )}\n        </div>\n\n        {/* Toggle Image Button */}\n        <div style={{ flex: 1, textAlign: 'center' }}>\n          <button\n            style={{\n              fontSize: '12px',\n              padding: '5px',\n              margin: '5px 0',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={stopListening}\n          >\n            {listening ? \"Stop Listening\" : \"\"}\n          </button>\n        </div>\n      </div>\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\" style={{ marginBottom: '15px' }}>\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n            listening={listening}\n          />\n        </div>\n  \n\n      </div>\n\n\n\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}