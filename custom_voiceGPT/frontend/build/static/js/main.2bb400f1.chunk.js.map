{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","show_conversation","apiInProgress","listenButton","session_listen","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","i","timer","setTimeout","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","maxHeight","overflowY","border","padding","g_anwers","CustomVoiceGPT","props","_refresh_ask$color_di","api","kwargs","height","width","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","imageSrc","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistenButton","setsession_listen","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","isListening","setIsListening","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","showImage","setShowImage","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","Streamlit","setFrameHeight","intervalId","setInterval","SpeechRecognition","browserSupportsContinuousListening","listenContinuously","clearInterval","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","ret","command","type","text","user","stopListening","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","window","location","href","resizeWindow","resizeBy","addEventListener","removeEventListener","background_color_chat","color_dict","splitImage","placeholder","className","flex","toLowerCase","endsWith","maxWidth","controls","autoPlay","loop","muted","src","borderRadius","map","answer","idx","key","marginBottom","boxShadow","backgroundColor","dangerouslySetInnerHTML","__html","DOMPurify","sanitize","alignItems","marginRight","alt","resp","margin","value","onChange","event","target","onKeyDown","marginTop","fontSize","color","cursor","onClick","click_listenButton","marginLeft","listenSession","toggleShowImage","prevShowImage","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICsFVC,MA3FIC,IASZ,IATa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,kBACpBC,GAAoB,EAAI,cACxBC,GAAgB,EAAK,aACrBC,GAAe,EAAK,eACpBC,GAAe,GAChBR,EACC,MAAOS,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IAyD7C,OAvDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAO1B,GALAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAC1BO,QAAQC,IAAI,oBAAqBrB,GAG7BK,GAAkBM,EAAgBW,MAAM,KAAKC,OAAS,IAIxD,OAHAH,QAAQC,IAAI,8BACZtB,EAAOY,EAAiBb,EAAS0B,GAAI,QACrCZ,IAIF,GAAoB,GAAhBP,GAAyBM,EAAgBW,MAAM,KAAKC,OAAS,IAG/D,OAFAH,QAAQC,IAAI,wFACZT,IAKFM,EAAcP,GAGd,MAAMc,EAAQC,WAAW,KACvB,IAAK,IAAIF,EAAI,EAAGA,EAAI1B,EAASyB,OAAQC,IAAK,CACxC,MAAM,SAAEG,EAAQ,SAAEC,GAAa9B,EAAS0B,GACxC,IAAK,IAAIK,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,IAAKE,GAAkBhC,GAAoBI,KAAkBD,EAU3D,OATIH,EACFD,EAAOY,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACTjC,EAAOY,EAAiBb,EAAS0B,GAAI,GAE9BpB,GACPL,EAAOY,EAAiBb,EAAS0B,GAAI,QAEvCZ,KAMNQ,QAAQC,IAAI,gDACQ,IAAnBpB,GAEH,MAAO,IAAMiC,aAAaT,KAE3B,CAACd,EAAiBX,EAAkBF,EAAUG,EAAkBW,EAAiBT,EAAeC,IAG9FU,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGnC,GACGiC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SAClIT,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,SARpCsB,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,wBCjEjB,IAEIS,EAAW,GAukBAC,MApkBSC,IAAW,IAADC,EAChC,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOH,GACvB,SACJjD,EAAQ,OACRqD,EAAM,MACNC,EAAK,kBACLlD,EAAiB,WACjBmD,EAAU,WACVC,EAAU,iBACVrD,EAAgB,WAChBsD,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,EAAa,eACbC,GACEZ,GACGa,EAAUC,GAAexD,mBAAS0C,EAAOQ,aACzCO,EAAeC,GAAoB1D,mBAAS0C,EAAOQ,aAEnDS,EAASC,GAAc5D,mBAAS,KAChC6D,EAASC,GAAc9D,mBAAS,KAChCR,EAAkBuE,GAAuB/D,oBAAS,IAElDgE,EAAcC,GAAmBjE,oBAAS,IAC1CkE,EAAcC,GAAmBnE,oBAAS,IAC1CoE,EAAYC,GAAiBrE,mBAAS,KACtCL,EAAe2E,GAAoBtE,oBAAS,IAC5CuE,EAAUC,GAAyBxE,oBAAS,IAE5CJ,EAAc6E,GAAmBzE,oBAAS,IAC1CH,EAAgB6E,GAAqB1E,oBAAS,IAE9C2E,EAAqBC,GAAmB5E,mBAAS0C,EAAOY,gBACzDuB,GAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAGjBE,GAAaC,IAAkBjF,oBAAS,IACxCkF,GAAoBC,IAAyBnF,oBAAS,IAEtDoF,GAAYC,IAAiBrF,mBAAS,kBACtCsF,GAAmBC,IAAwBvF,mBAAS,cAEpDwF,GAAWC,IAAgBzF,oBAAS,GAO3CW,oBAAU,KACJuC,GAEFwC,GAAexC,IAEhB,CAACA,IAEJ,MAAMwC,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAI5C,GAAS4C,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/C7C,EAAY0C,GACZxC,EAAiBsC,GACjB,MAAOM,OACP1F,QAAQ0F,MAAM,6BAA8BA,SAYhD3F,oBAAU,KACR4F,IAAUC,iBAGV,MAAMC,EAAaC,YAAY,KACxBC,IAAkBC,uCAErBhG,QAAQC,IAAI,iCAAkCyF,OAC9CO,OAED,KAEH,MAAO,KACLC,cAAcL,KAEf,IAEH,MAqBMI,GAAqBA,KACzBF,IAAkBI,eAAe,CAC/BC,YAAY,EACZC,SAAU,UAEZhC,IAAe,IAYjBtE,oBAAU,KACWgF,WAGjBuB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAM3D,GAAgB,KAEhC4D,GACA,MAAMC,EAAWpB,YAAY,OAE1B,KACH,MAAO,IAAMI,cAAcgB,IAC1B,IAoHH,MAAMvI,GAASoG,MAAOoC,EAAKC,EAASC,KAClCrE,EAAW,KAADmC,OAAMiC,EAAkB,SAAW,QAAC,MAAAjC,OAAKgC,EAAG,MACtD,MAAMG,EAAO,IAAI7F,EAAU,CAAE8F,KAAMJ,IACnCjE,EAAW,IAAIoE,IACf,IACEtH,QAAQC,IAAI,wBAAyBmH,GACrC1D,GAAiB,GAvKnBqC,IAAkByB,gBAClBnD,IAAe,GACfrE,QAAQC,IAAI,mCAAoCmE,IAwK9C,MAAMqD,EAAO,CACXC,YAAaL,EACbjF,QAASA,EACTkF,KAAMA,EACNhF,WAAYO,EACZ8E,UAAW1D,GAAS2D,QACpBvF,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdxD,eAAeA,EACf8E,oBAAoBA,GAEtB/D,QAAQC,IAAI,OACZ,MAAM,KAAEwF,SAAeR,IAAM4C,KAAKhG,EAAK4F,GAYvC,GAXAzH,QAAQC,IAAI,YAAawF,EAAMgC,GAC3BhC,EAAiB,YAAKA,EAAiB,aAAM5C,GAC/CiC,GAAeW,EAAiB,YAElCvC,EAAWuC,EAAW,MACtBhE,EAAW,IAAIgE,EAAW,MAEtBtB,GAASyD,SACXzD,GAASyD,QAAQE,QAGfrC,EAAiB,WAAG,CACtB,MAAMsC,EAAkB,GAAA5C,OAAM5C,GAAS4C,OAAGM,EAAiB,YAC3DtB,GAASyD,QAAU,IAAII,MAAMD,GAE7B,UACU5D,GAASyD,QAAQK,OAGvBrE,GAAsB,GACtBe,GAAqB,kBAGf,IAAI2B,QAASlI,IACf+F,GAASyD,QAAQM,QAAU,KACvBlI,QAAQC,IAAI,4BACZ7B,OAIV,MAAOsH,OACL1F,QAAQ0F,MAAM,wBAAyBA,OAC1C,QAEGvB,GAASyD,QAAU,KACnBhE,GAAsB,GACtBe,GAAqB,WAI3BF,GAAc,iBACdE,GAAqB,aACrBf,GAAsB,GACtBF,GAAiB,GAEjB1D,QAAQC,IAAI,kCAEZkD,EAAoBsC,EAAyB,oBAC7CzF,QAAQC,IAAI,qBAAsBwF,EAAyB,qBAI/B,IAAxBA,EAAkB,aAAuC,OAAxBA,EAAkB,cACrDzF,QAAQC,IAAI,sBAAuBwF,EAAkB,aAErD0C,OAAOC,SAASC,KAAO5C,EAAkB,aAGrB,GAAlB7G,GAA2BI,GAAiBsF,GAIvCtF,EACT6E,GAAgB,GAEPS,GACPC,IAAsB,IAGtB0B,KACAtB,GAAqB,2BAXrBsB,KACAtB,GAAqB,sCAavB3E,QAAQC,IAAI,cAAemE,IAE3B,MAAOsB,OACP1F,QAAQC,IAAI,6BAA8ByF,OAC1ChC,GAAiB,GACjBG,GAAgB,KAIpB9D,oBAAU,KAER,MAAMuI,EAAeA,KACnBH,OAAOI,SAAS,EAAG,IAQrB,OAHAJ,OAAOK,iBAAiB,wBAAyBF,GAG1C,KACLH,OAAOM,oBAAoB,wBAAyBH,KAErD,IAGH,MAAMI,IAA8C,QAAtB9G,EAAAS,EAAYsG,kBAAU,IAAA/G,OAAA,EAAtBA,EAAwB8G,wBAAyB,cACzEE,GAAatG,EAAWpC,MAAM,KAAK,GACnC2I,GAAW,aAAA1D,OAAgByD,IAEjC,OACE7H,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAK8H,UAAU,OACb/H,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,MAAOY,MAAO,SAEzD4C,IACC7D,IAAAC,cAAA,OAAKE,MAAO,CAAE6H,KAAM,IACjBpG,IACCA,EAASqG,cAAcC,SAAS,QAC9BlI,IAAAC,cAAA,SACEE,MAAO,CAAEgI,SAAU,QACnBnH,OAAQA,GAAU,IAClBC,MAAOA,GAAS,IAChBmH,UAAQ,EACRC,UAAQ,EACRC,MAAM,EACNC,OAAK,GAELvI,IAAAC,cAAA,UAAQuI,IAAK5G,EAAU0E,KAAK,cAAc,gDAI5CtG,IAAAC,cAAA,OAAKuI,IAAK5G,EAAUZ,OAAQA,GAAU,IAAKC,MAAOA,GAAS,IAAKd,MAAO,CAAEgI,SAAU,YAO3FnI,IAAAC,cAAA,OAAKE,MAAO,CAAE6H,KAAMnE,GAAY,EAAI,OAAQtD,UAAW,OAAQD,UAAW,UACzEvC,GACCiC,IAAAC,cAAA,OACEE,MAAO,CACLK,OAAQ,oBACRiI,aAAc,MACdlI,UAAW,OACXD,UAAW,QACXG,QAAS,SAGVyB,EAAQwG,IAAI,CAACC,EAAQC,IACpB5I,IAAAC,cAAA,OACE4I,IAAKD,EACLzI,MAAO,CACL2I,aAAc,MAEdrI,QAAS,MACTgI,aAAc,MACdjI,OAAQ,iBACRuI,UAAW,iCAGb/I,IAAAC,cAAA,OAAK8H,UAAU,YAAY5H,MAAO,CAAE6I,gBAAiB,gBAClDvH,EAAY,KAAEzB,IAAAC,cAAA,QAAMgJ,wBAAyB,CAAEC,OAAQC,IAAUC,SAAST,EAAOnC,UAEpFxG,IAAAC,cAAA,OAAK8H,UAAU,YAAY5H,MAAO,CAAEC,QAAS,OAAQiJ,WAAY,SAAUL,gBAAiBrB,KAE1F3H,IAAAC,cAAA,OAAK8H,UAAU,aAAa5H,MAAO,CAAEmJ,YAAa,SAChDtJ,IAAAC,cAAA,OAAKuI,IAAK5G,EAAU2H,IAAI,WAAWpJ,MAAO,CAAEc,MAAO,UAAY,KAGjEjB,IAAAC,cAAA,YACED,IAAAC,cAAA,QAAMgJ,wBAAyB,CAAEC,OAAQC,IAAUC,SAAST,EAAOa,MAAQ,yBAWxFrI,GACCnB,IAAAC,cAAAD,IAAAE,SAAA,KACAF,IAAAC,cAAA,MAAIE,MAAO,CAAEsJ,OAAQ,YACnBzJ,IAAAC,cAAA,OAAK8H,UAAU,cACb/H,IAAAC,cAAA,SACE8H,UAAU,eACVzB,KAAK,OACLwB,YAAaA,GACb4B,MAAOjH,EACPkH,SAjUWC,IAEvBlH,EAAckH,EAAMC,OAAOH,OAG3BlG,IAAsB,IA6TVsG,UA1TW7M,IACT,UAAVA,EAAE4L,MACJ5J,QAAQC,IAAI,kBAAmBuD,GAC/B7E,GAAO6E,EAAY,CAAEhD,SAAU,CAAEE,QAAS,KAAQ,GAClD+C,EAAc,SAyTR1C,IAAAC,cAAA,MAAIE,MAAO,CAAEsJ,OAAQ,aAKzBzJ,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQ2J,UAAW,SACxC/J,IAAAC,cAAA,UACEE,MAAO,CACL6H,KAAM,EACNgC,SAAU,OACVvJ,QAAS,MACT6I,YAAa,MACbN,gBAAiB,UACjBiB,MAAO,QACPzJ,OAAQ,oBACRiI,aAAc,MACdyB,OAAQ,WAEVC,QAlPiBC,KACzBtH,GAAgB,GAChBoC,KACAxB,GAAc,gBACdzE,QAAQC,IAAI,iCACZD,QAAQC,IAAIjB,KA+OHwF,IAEHzD,IAAAC,cAAA,UACEE,MAAO,CACL6H,KAAM,EACNgC,SAAU,OACVvJ,QAAS,MACT4J,WAAY,MACZrB,gBAAiB,UACjBiB,MAAO,QACPzJ,OAAQ,oBACRiI,aAAc,MACdyB,OAAQ,WAEVC,QAASjF,IACV,uBAGDlF,IAAAC,cAAA,UACEE,MAAO,CACL6H,KAAM,EACNgC,SAAU,OACVvJ,QAAS,MACT4J,WAAY,MACZrB,gBAAiB,UACjBiB,MAAO,QACPzJ,OAAQ,oBACRiI,aAAc,MACdyB,OAAQ,WAEVC,QApZYG,KAEpBvH,GADI7E,KAoZG,mBAGD8B,IAAAC,cAAA,UACEE,MAAO,CACL6H,KAAM,EACNgC,SAAU,OACVvJ,QAAS,MACT4J,WAAY,MACZrB,gBAAiB,UACjBiB,MAAO,QACPzJ,OAAQ,oBACRiI,aAAc,MACdyB,OAAQ,WAEVC,QAnfcI,KACtBzG,GAAc0G,IAAmBA,KAofxB3G,GAAY,aAAe,eAOhC7D,IAAAC,cAAA,OAAK8H,UAAU,OACb/H,IAAAC,cAACxC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,kBAAmBA,EACnBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,QCtjBbuM,kBAVD7J,IACZ,MAAM,IAAEE,EAAG,OAAEC,GAAWH,EAAM8J,KAE9B,OADA1L,oBAAU,IAAM4F,IAAUC,kBAExB7E,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAC0K,EAAQ,CAAC7J,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAM6J,EAAS,IAAIC,IAGnBC,IAASC,OACP/K,IAAAC,cAACD,IAAMgL,WAAU,KACfhL,IAAAC,cAACgL,IAAiB,CAACvB,MAAOkB,GACxB5K,IAAAC,cAACiL,IAAa,CAACC,MAAOC,KACpBpL,IAAAC,cAACoL,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.2bb400f1.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 21;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  show_conversation = true,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n  session_listen=false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      // Add logs to check the conditions\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (session_listen && finalTranscript.split(\" \").length > 500000){\n        console.log(\"Transcript exceeds X words\");\n        myFunc(finalTranscript, commands[i], 6);\n        resetTranscript();\n        return;\n      }\n\n      if (session_listen==false && finalTranscript.split(\" \").length > 10000) {\n        console.log(\"Transcript exceeds 89 words. Clearing You really should call func-api to save .\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword or API is in progress\n        console.log(\"Waiting for a keyword or API is in progress\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n          <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"200px\", overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          {/* Add other conversation messages here */}\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progress\n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n  \n\n  const [isListening, setIsListening] = useState(false);\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  const [showImage, setShowImage] = useState(false); // Step 1: Define showImage state\n\n  const toggleShowImage = () => { // Step 2: Create toggle function\n    setShowImage((prevShowImage) => !prevShowImage);\n  };\n\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n  const checkListeningStatus = () => {\n    // Check if continuous listening is active\n    if (!SpeechRecognition.browserSupportsContinuousListening()) {\n      // If not, restart continuous listening\n      startContinuousListening();\n    }\n  };\n\n  useEffect(() => {\n    Streamlit.setFrameHeight();\n\n    // Check listening status every minute\n    const intervalId = setInterval(() => {\n      if (!SpeechRecognition.browserSupportsContinuousListening()) {\n        // If continuous listening is not active, start it\n        console.log(\"LISTEN STOPPED TURNING BACK ON\", error);\n        listenContinuously();\n      }\n    }, 60000);\n\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  const startContinuousListening = () => {\n    // Start continuous listening\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n    setIsListening(true)\n  };\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n    setIsListening(false);\n    console.log(\"Stopping Listening, isListening=\", isListening)\n\n    \n  }\n  \n  const startListening = () => {\n    SpeechRecognition.startListening();\n  };\n\n  const listenContinuously = () =>{\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n    setIsListening(true)\n  }\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    listenContinuously()\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  function isHTML(str) {\n    return /^</.test(str);\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      if (data[\"audio_path\"]) {\n        const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n        audioRef.current = new Audio(apiUrlWithFileName);\n    \n        try {\n            await audioRef.current.play();\n            \n            // Set state to indicate speaking in progress\n            setSpeakingInProgress(true);\n            setButtonName_listen(\"Speaking\");\n    \n            // Await playback completion\n            await new Promise((resolve) => {\n                audioRef.current.onended = () => {\n                    console.log(\"Audio playback finished.\");\n                    resolve();\n                };\n            });\n    \n        } catch (error) {\n            console.error(\"Audio playback error:\", error);\n        } finally {\n            // Cleanup or reset after playback\n            audioRef.current = null;\n            setSpeakingInProgress(false);\n            setButtonName_listen(\"Listen\");\n        }\n    }\n\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"]);\n\n\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n      \n      if (listenAfterReply==true && !listenButton && !UserUsedChatWindow) {\n        listenContinuously()\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (UserUsedChatWindow){\n        setUserUsedChatWindow(false)\n      }\n      else {\n        listenContinuously()\n        setButtonName_listen(\"listeing for key word\")\n      }\n      \n      console.log(\"listing end\", isListening)\n\n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n  };\n\n  useEffect(() => {\n    // Function to resize the window\n    const resizeWindow = () => {\n      window.resizeBy(0, 1); // Resize the window by 1 pixel vertically\n    };\n\n    // Resize the window after the response finishes\n    // Replace `RESPONSE_FINISH_EVENT` with the event that indicates the response finished\n    window.addEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n\n    // Cleanup the event listener\n    return () => {\n      window.removeEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n    };\n  }, []); // Run only once after component mounts\n\n  \n  const background_color_chat = refresh_ask.color_dict?.background_color_chat || 'transparent';\n  const splitImage = self_image.split('.')[0]; // Split by dot\n  const placeholder = `Chat with ${splitImage}`;\n\n  return (\n    <>\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'row', width: '100%' }}>\n          {/* Image or video section */}\n          {showImage && (\n            <div style={{ flex: 1 }}>\n              {imageSrc && (\n                imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n                  <video\n                    style={{ maxWidth: '100%' }}\n                    height={height || 100}\n                    width={width || 100}\n                    controls\n                    autoPlay\n                    loop={false}\n                    muted\n                  >\n                    <source src={imageSrc} type=\"video/mp4\" />\n                    Your browser does not support the video tag.\n                  </video>\n                ) : (\n                  <img src={imageSrc} height={height || 100} width={width || 100} style={{ maxWidth: '100%' }} />\n                )\n              )}\n            </div>\n          )}\n  \n          {/* Chat window, taking full width if no image is shown */}\n          <div style={{ flex: showImage ? 1 : '100%', overflowY: 'auto', maxHeight: '400px' }}>\n          {show_conversation && (\n            <div\n              style={{\n                border: '2px solid #2980b9', // Outer border\n                borderRadius: '6px', // Slightly round the corners of the outer border\n                overflowY: 'auto', // Enable vertical scrolling\n                maxHeight: '400px', // Set maximum height for scrolling\n                padding: '10px', // Add padding inside the outer border\n              }}\n            >\n              {answers.map((answer, idx) => (\n                <div\n                  key={idx}\n                  style={{\n                    marginBottom: '5px',\n                    // backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2', // Background color for the entire message\n                    padding: '5px',\n                    borderRadius: '4px',\n                    border: '1px solid #ccc', // Inner border for each message\n                    boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)', // Optional: add shadow for depth\n                  }}\n                >\n                  <div className=\"chat-user\" style={{ backgroundColor: 'transparent' }}>\n                    {client_user}: <span dangerouslySetInnerHTML={{ __html: DOMPurify.sanitize(answer.user) }} />\n                  </div>\n                  <div className=\"chat-resp\" style={{ display: 'flex', alignItems: 'center', backgroundColor: background_color_chat }}>\n                    {/* Displaying image in place of -resp */}\n                    <div className=\"chat-image\" style={{ marginRight: '10px' }}>\n                      <img src={imageSrc} alt=\"response\" style={{ width: '50px' }} /> {/* Adjusted width */}\n                    </div>\n                    {/* Displaying the response text without the -resp label */}\n                    <span>\n                      <span dangerouslySetInnerHTML={{ __html: DOMPurify.sanitize(answer.resp || \"thinking...\") }} />\n                    </span>\n                  </div>\n                </div>\n              ))}\n            </div>\n          )}\n          </div>\n        </div>\n\n        {/* Input text section */}\n        {input_text && (\n          <>\n          <hr style={{ margin: '20px 0' }} />\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder={placeholder}\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '20px 0' }} />\n          </>\n        )}\n\n        {/* Buttons with the toggle button included */}\n        <div style={{ display: 'flex', marginTop: '10px' }}>\n          <button\n            style={{\n              flex: 1,\n              fontSize: '12px',\n              padding: '5px',\n              marginRight: '5px',\n              backgroundColor: '#3498db',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          <button\n            style={{\n              flex: 1,\n              fontSize: '12px',\n              padding: '5px',\n              marginLeft: '5px',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={listenContinuously}\n          >\n            Conversational Mode\n          </button>\n          <button\n            style={{\n              flex: 1,\n              fontSize: '12px',\n              padding: '5px',\n              marginLeft: '5px',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              border: '1px solid #2980b9',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={listenSession}\n          >\n            Start A Session\n          </button>\n          <button\n            style={{\n              flex: 1,\n              fontSize: '12px',\n              padding: '5px',\n              marginLeft: '5px',\n              backgroundColor: '#7f8c8d',\n              color: 'white',\n              border: '1px solid #7f8c8d',\n              borderRadius: '4px',\n              cursor: 'pointer',\n            }}\n            onClick={toggleShowImage}\n          >\n            {showImage ? \"Hide Image\" : \"Show Image\"}\n          </button>\n        </div>\n\n\n\n        {/* Dictaphone component */}\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            show_conversation={show_conversation}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n          />\n        </div>\n  \n\n      </div>\n    </>\n  );\n}\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}