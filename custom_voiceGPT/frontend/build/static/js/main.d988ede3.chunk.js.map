{"version":3,"sources":["../node_modules/@vladmandic/face-api/dist sync","Dictaphone.jsx","VoiceGPT.jsx","Main.tsx","index.tsx"],"names":["webpackEmptyContext","req","e","Error","code","keys","resolve","module","exports","id","Dictaphone","_ref","commands","myFunc","listenAfterReply","no_response_time","show_conversation","apiInProgress","listenButton","session_listen","transcribing","setTranscribing","useState","clearTranscriptOnListen","setClearTranscriptOnListen","finalTranscript","resetTranscript","listening","browserSupportsSpeechRecognition","isMicrophoneAvailable","useSpeechRecognition","prevScript","setPrevScript","useEffect","console","log","split","length","i","timer","setTimeout","keywords","api_body","j","keyword","RegExp","isKeywordFound","search","clearTimeout","React","createElement","Fragment","style","display","flexDirection","maxHeight","overflowY","border","padding","g_anwers","CustomVoiceGPT","props","api","kwargs","height","width","show_video","input_text","face_recon","api_key","refresh_ask","self_image","api_audio","client_user","force_db_root","before_trigger","imageSrc","setImageSrc","imageSrc_name","setImageSrc_name","message","setMessage","answers","setAnswers","setListenAfterReply","modelsLoaded","setModelsLoaded","captureVideo","setCaptureVideo","textString","setTextString","setApiInProgress","speaking","setSpeakingInProgress","setlistenButton","setsession_listen","before_trigger_vars","before_trigger_","faceData","useRef","audioRef","isListening","setIsListening","UserUsedChatWindow","setUserUsedChatWindow","buttonName","setButtonName","buttonName_listen","setButtonName_listen","fetchImageData","async","response","axios","get","concat","imageUrl","responseType","objectUrl","URL","createObjectURL","data","error","Streamlit","setFrameHeight","intervalId","setInterval","SpeechRecognition","browserSupportsContinuousListening","listenContinuously","clearInterval","startListening","continuous","language","Promise","all","faceapi","tinyFaceDetector","loadFromUri","process","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","ageGenderNet","then","loadModels","interval","ret","command","type","text","user","stopListening","body","tigger_type","face_data","current","post","pause","apiUrlWithFileName","Audio","play","onended","window","location","href","resizeWindow","resizeBy","addEventListener","removeEventListener","className","flex","toLowerCase","endsWith","controls","autoPlay","loop","muted","src","position","top","left","backgroundImage","animation","transform","color","fontSize","background","borderRadius","right","map","answer","idx","key","marginBottom","backgroundColor","resp","dangerouslySetInnerHTML","__html","DOMPurify","sanitize","marginTop","marginRight","cursor","onClick","click_listenButton","marginLeft","listenSession","placeholder","value","onChange","event","target","onKeyDown","margin","withStreamlitConnection","args","VoiceGPT","engine","Styletron","ReactDOM","render","StrictMode","StyletronProvider","ThemeProvider","theme","LightTheme","Main","document","getElementById"],"mappings":"0HAAA,SAASA,EAAoBC,GAC5B,IAAIC,EAAI,IAAIC,MAAM,uBAAyBF,EAAM,KAEjD,MADAC,EAAEE,KAAO,mBACHF,EAEPF,EAAoBK,KAAO,WAAa,MAAO,IAC/CL,EAAoBM,QAAUN,EAC9BO,EAAOC,QAAUR,EACjBA,EAAoBS,GAAK,I,+ICsFVC,MA3FIC,IASZ,IATa,SAClBC,EAAQ,OACRC,EAAM,iBACNC,GAAmB,EAAK,iBACxBC,EAAmB,EAAC,kBACpBC,GAAoB,EAAI,cACxBC,GAAgB,EAAK,aACrBC,GAAe,EAAK,eACpBC,GAAe,GAChBR,EACC,MAAOS,EAAcC,GAAmBC,oBAAS,IAC1CC,EAAyBC,GAA8BF,oBAAS,IACjE,gBAAEG,EAAe,gBAAEC,EAAe,UAAEC,EAAS,iCAAEC,EAAgC,sBAAEC,GAA0BC,+BAAqB,CAAEV,eAAcG,6BAC/IQ,EAAYC,GAAiBV,mBAAS,IAyD7C,OAvDAW,oBAAU,KACR,GAAwB,KAApBR,EAAwB,CAO1B,GALAS,QAAQC,IAAI,oBAAqBV,GACjCS,QAAQC,IAAI,aAAcR,GAC1BO,QAAQC,IAAI,oBAAqBrB,GAG7BK,GAAkBM,EAAgBW,MAAM,KAAKC,OAAS,IAIxD,OAHAH,QAAQC,IAAI,8BACZtB,EAAOY,EAAiBb,EAAS0B,GAAI,QACrCZ,IAIF,GAAoB,GAAhBP,GAAyBM,EAAgBW,MAAM,KAAKC,OAAS,IAG/D,OAFAH,QAAQC,IAAI,wFACZT,IAKFM,EAAcP,GAGd,MAAMc,EAAQC,WAAW,KACvB,IAAK,IAAIF,EAAI,EAAGA,EAAI1B,EAASyB,OAAQC,IAAK,CACxC,MAAM,SAAEG,EAAQ,SAAEC,GAAa9B,EAAS0B,GACxC,IAAK,IAAIK,EAAI,EAAGA,EAAIF,EAASJ,OAAQM,IAAK,CACxC,MAAMC,EAAU,IAAIC,OAAOJ,EAASE,GAAI,KAClCG,GAAsD,IAArCrB,EAAgBsB,OAAOH,GAE9C,IAAKE,GAAkBhC,GAAoBI,KAAkBD,EAU3D,OATIH,EACFD,EAAOY,EAAiB,CAAEiB,SAAU,CAAEE,QAAS,KAAQ,GAC9CE,EACTjC,EAAOY,EAAiBb,EAAS0B,GAAI,GAE9BpB,GACPL,EAAOY,EAAiBb,EAAS0B,GAAI,QAEvCZ,KAMNQ,QAAQC,IAAI,gDACQ,IAAnBpB,GAEH,MAAO,IAAMiC,aAAaT,KAE3B,CAACd,EAAiBX,EAAkBF,EAAUG,EAAkBW,EAAiBT,EAAeC,IAG9FU,EAIAC,EAKHoB,IAAAC,cAAAD,IAAAE,SAAA,KACGnC,GACGiC,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,SAAUC,UAAW,QAASC,UAAW,OAAQC,OAAQ,iBAAkBC,QAAS,SAClIT,IAAAC,cAAA,YAAM,aAAWnB,GACjBkB,IAAAC,cAAA,YAAM,cAAYvB,EAAY,KAAO,SARpCsB,IAAAC,cAAA,YAAM,yCAJND,IAAAC,cAAA,YAAM,uB,wBCjEjB,IAEIS,EAAW,GA4jBAC,MAzjBSC,IACtB,MAAM,IAAEC,EAAG,OAAEC,EAAS,IAAOF,GACvB,SACJjD,EAAQ,OACRoD,EAAM,MACNC,EAAK,kBACLjD,EAAiB,WACjBkD,EAAU,WACVC,EAAU,iBACVpD,EAAgB,WAChBqD,EAAU,QACVC,EAAO,YACPC,EAAW,WACXC,EAAU,UACVC,EAAS,YACTC,EAAW,cACXC,EAAa,eACbC,GACEZ,GACGa,EAAUC,GAAevD,mBAASyC,EAAOQ,aACzCO,EAAeC,GAAoBzD,mBAASyC,EAAOQ,aAEnDS,EAASC,GAAc3D,mBAAS,KAChC4D,EAASC,GAAc7D,mBAAS,KAChCR,EAAkBsE,GAAuB9D,oBAAS,IAElD+D,EAAcC,GAAmBhE,oBAAS,IAC1CiE,EAAcC,GAAmBlE,oBAAS,IAC1CmE,EAAYC,GAAiBpE,mBAAS,KACtCL,EAAe0E,GAAoBrE,oBAAS,IAC5CsE,EAAUC,GAAyBvE,oBAAS,IAE5CJ,EAAc4E,GAAmBxE,oBAAS,IAC1CH,EAAgB4E,GAAqBzE,oBAAS,IAE9C0E,EAAqBC,GAAmB3E,mBAASyC,EAAOY,gBACzDuB,EAAWC,iBAAO,IAMlBC,IALgBD,kBAAO,GACZA,mBAGCA,mBACDA,iBAAO,QAEjBE,GAAaC,IAAkBhF,oBAAS,IACxCiF,GAAoBC,IAAyBlF,oBAAS,IAEtDmF,GAAYC,IAAiBpF,mBAAS,kBACtCqF,GAAmBC,IAAwBtF,mBAAS,aAE3DW,oBAAU,KACJsC,GAEFsC,GAAetC,IAEhB,CAACA,IAEJ,MAAMsC,GAAiBC,UACrB,IACE,MAAMC,QAAiBC,IAAMC,IAAI,GAADC,OAAI1C,GAAS0C,OAAGC,GAAY,CAC1DC,aAAc,SAEVC,EAAYC,IAAIC,gBAAgBR,EAASS,MAC/C3C,EAAYwC,GACZtC,EAAiBoC,GACjB,MAAOM,OACPvF,QAAQuF,MAAM,6BAA8BA,SAYhDxF,oBAAU,KACRyF,IAAUC,iBAGV,MAAMC,EAAaC,YAAY,KACxBC,IAAkBC,uCAErB7F,QAAQC,IAAI,iCAAkCsF,OAC9CO,OAED,KAEH,MAAO,KACLC,cAAcL,KAEf,IAEH,MAqBMI,GAAqBA,KACzBF,IAAkBI,eAAe,CAC/BC,YAAY,EACZC,SAAU,UAEZ9B,IAAe,IAYjBrE,oBAAU,KACW6E,WAGjBuB,QAAQC,IAAI,CACVC,IAAaC,iBAAiBC,YAHdC,YAIhBH,IAAaI,kBAAkBF,YAJfC,YAKhBH,IAAaK,mBAAmBH,YALhBC,YAMhBH,IAAaM,kBAAkBJ,YANfC,YAOhBH,IAAaO,aAAaL,YAPVC,cAQfK,KAAK,IAAMzD,GAAgB,KAEhC0D,GACA,MAAMC,EAAWpB,YAAY,OAE1B,KACH,MAAO,IAAMI,cAAcgB,IAC1B,IAoHH,MAAMpI,GAASiG,MAAOoC,EAAKC,EAASC,KAClCnE,EAAW,KAADiC,OAAMiC,EAAkB,SAAW,QAAC,MAAAjC,OAAKgC,EAAG,MACtD,MAAMG,EAAO,IAAI1F,EAAU,CAAE2F,KAAMJ,IACnC/D,EAAW,IAAIkE,IACf,IACEnH,QAAQC,IAAI,wBAAyBgH,GACrCxD,GAAiB,GAvKnBmC,IAAkByB,gBAClBjD,IAAe,GACfpE,QAAQC,IAAI,mCAAoCkE,IAwK9C,MAAMmD,EAAO,CACXC,YAAaL,EACb/E,QAASA,EACTgF,KAAMA,EACN9E,WAAYO,EACZ4E,UAAWxD,EAASyD,QACpBrF,YAAaA,EACbG,YAAaA,EACbC,cAAcA,EACdvD,eAAeA,EACf6E,oBAAoBA,GAEtB9D,QAAQC,IAAI,OACZ,MAAM,KAAEqF,SAAeR,IAAM4C,KAAK9F,EAAK0F,GACvCtH,QAAQC,IAAI,YAAaqF,EAAMgC,GAC3BhC,EAAiB,YAAKA,EAAiB,aAAM1C,GAC/C+B,GAAeW,EAAiB,YAElCrC,EAAWqC,EAAW,MACtB7D,EAAW,IAAI6D,EAAW,MAEtBpB,GAASuD,SACXvD,GAASuD,QAAQE,QAInB,MAAMC,EAAkB,GAAA5C,OAAM1C,GAAS0C,OAAGM,EAAiB,YAC3DpB,GAASuD,QAAU,IAAII,MAAMD,GAC7B1D,GAASuD,QAAQK,OAGjBnE,GAAsB,GACtBe,GAAqB,kBACf,IAAIyB,QAAS/H,IACjB8F,GAASuD,QAAQM,QAAU,KACzB/H,QAAQC,IAAI,4BACZ7B,OAGJoG,GAAc,iBACdE,GAAqB,aACrBf,GAAsB,GACtBF,GAAiB,GAEjBzD,QAAQC,IAAI,kCAEZiD,EAAoBoC,EAAyB,oBAC7CtF,QAAQC,IAAI,qBAAsBqF,EAAyB,qBAE/B,IAAxBA,EAAkB,aAAuC,OAAxBA,EAAkB,cACrDtF,QAAQC,IAAI,sBAAuBqF,EAAkB,aAErD0C,OAAOC,SAASC,KAAO5C,EAAkB,aAGrB,GAAlB1G,GAA2BI,GAAiBqF,GAIvCrF,EACT4E,GAAgB,GAEPS,GACPC,IAAsB,IAGtBwB,KACApB,GAAqB,2BAXrBoB,KACApB,GAAqB,sCAavB1E,QAAQC,IAAI,cAAekE,IAE3B,MAAOoB,OACPvF,QAAQC,IAAI,6BAA8BsF,OAC1C9B,GAAiB,GACjBG,GAAgB,KAoBpB,OAhBA7D,oBAAU,KAER,MAAMoI,EAAeA,KACnBH,OAAOI,SAAS,EAAG,IAQrB,OAHAJ,OAAOK,iBAAiB,wBAAyBF,GAG1C,KACLH,OAAOM,oBAAoB,wBAAyBH,KAErD,IAGDpH,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKuH,UAAU,OACbxH,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQC,cAAe,MAAOW,MAAO,SAE1DhB,IAAAC,cAAA,OAAKE,MAAO,CAAEsH,KAAM,IACjB9F,GAAYA,EAAS+F,cAAcC,SAAS,QAC3C3H,IAAAC,cAAA,SACEc,OAAQA,GAAU,IAClBC,MAAOA,GAAS,IAChB4G,UAAQ,EACRC,UAAU,EACVC,MAAM,EACNC,OAAK,GAEL/H,IAAAC,cAAA,UAAQ+H,IAAKrG,EAAUwE,KAAK,cAAc,gDAI5CnG,IAAAC,cAAA,OAAK+H,IAAKrG,EAAUZ,OAAQA,GAAU,IAAKC,MAAOA,GAAS,MAG5DhD,GACCgC,IAAAC,cAAA,OACEE,MAAO,CACL8H,SAAU,WACVC,IAAK,OACLC,KAAM,IACNnH,MAAO,OACPD,OAAQ,OACRqH,gBAAiB,sDACjBC,UAAW,0BAGbrI,IAAAC,cAAA,OAAKE,MAAO,CAAE8H,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,sBAIrI7F,GACC3C,IAAAC,cAAA,OAAKE,MAAO,CAAE8H,SAAU,WAAYjH,MAAO,OAAQD,OAAQ,SAC1D4B,GACC3C,IAAAC,cAAA,OACEE,MAAO,CACL8H,SAAU,WACVC,IAAK,OACLC,KAAM,IACNnH,MAAO,OACPD,OAAQ,OACR0H,WAAY,uDACZJ,UAAW,4BACXK,aAAc,SAGhB1I,IAAAC,cAAA,OAAKE,MAAO,CAAE8H,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,cASvIpF,IACCpD,IAAAC,cAAA,OACEE,MAAO,CACL8H,SAAU,WACVC,IAAK,OACLC,KAAM,IACNnH,MAAO,OACPD,OAAQ,OACRqH,gBAAiB,wDACjBC,UAAW,0BAGbrI,IAAAC,cAAA,OAAKE,MAAO,CAAE8H,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAW9E,KAItIxF,GACC8B,IAAAC,cAAA,OACEE,MAAO,CACL8H,SAAU,WACVC,IAAK,QACLS,MAAO,KACPR,KAAM,IACNnH,MAAO,MACPD,OAAQ,OACRqH,gBAAiB,0DACjBC,UAAW,0BAGbrI,IAAAC,cAAA,OAAKE,MAAO,CAAE8H,SAAU,WAAYC,IAAK,QAASC,KAAM,MAAOG,UAAW,mBAAoBC,MAAO,QAASC,SAAU,SAAU,qBAO1IxI,IAAAC,cAAA,OAAKE,MAAO,CAAEsH,KAAM,EAAGlH,UAAW,OAAQD,UAAW,WAChC,IAAtBvC,GACCiC,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,WAAK,SAAO8B,GACXE,EAAQ2G,IAAI,CAACC,EAAQC,IACpB9I,IAAAC,cAAA,OAAK8I,IAAKD,EAAK3I,MAAO,CAAE6I,aAAc,QACpChJ,IAAAC,cAAA,OAAKE,MAAO,CAAE8I,gBAAiBJ,EAAOK,KAAO,UAAY,YAAazI,QAAS,MAAOiI,aAAc,QAAS,UACpG1I,IAAAC,cAAA,QAAMkJ,wBAAyB,CAAEC,OAAQC,IAAUC,SAAST,EAAOxC,UAE5ErG,IAAAC,cAAA,OAAKE,MAAO,CAAE8I,gBAAiBJ,EAAOK,KAAO,cAAgB,UAAWzI,QAAS,MAAOiI,aAAc,QAAS,UACtG1I,IAAAC,cAAA,QAAMkJ,wBAAyB,CAAEC,OAAQC,IAAUC,SAAST,EAAOK,MAAQ,wBAU1FlJ,IAAAC,cAAA,OAAKE,MAAO,CAAEC,QAAS,OAAQmJ,UAAW,SACxCvJ,IAAAC,cAAA,UACEE,MAAO,CACLsH,KAAM,EACN+B,YAAa,MACbP,gBAAiB,UACjBV,MAAO,QACP9H,QAAS,OACTD,OAAQ,oBACRiJ,OAAQ,WAEVC,QArPiBC,KACzB9G,GAAgB,GAChBkC,KACAtB,GAAc,gBACdxE,QAAQC,IAAI,iCACZD,QAAQC,IAAIjB,KAkPHuF,IAEHxD,IAAAC,cAAA,UACEE,MAAO,CACLsH,KAAM,EACNmC,WAAY,MACZX,gBAAiB,UACjBV,MAAO,QACP9H,QAAS,OACTD,OAAQ,oBACRiJ,OAAQ,WAEVC,QAAS3E,IACV,uBAGD/E,IAAAC,cAAA,UACEE,MAAO,CACLsH,KAAM,EACNmC,WAAY,MACZX,gBAAiB,UACjBV,MAAO,QACP9H,QAAS,OACTD,OAAQ,oBACRiJ,OAAQ,WAEVC,QAnZYG,KAEpB/G,GADI5E,KAmZG,oBAMH8B,IAAAC,cAAA,OAAKuH,UAAU,OACbxH,IAAAC,cAACxC,EAAU,CACTE,SAAUA,EACVC,OAAQA,GACRC,iBAAkBA,EAClBC,iBAAkBA,EAClBC,kBAAmBA,EACnBC,cAAeA,EACfC,aAAcA,EACdC,eAAgBA,KAKnBgD,GACClB,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAAA,OAAKuH,UAAU,cACbxH,IAAAC,cAAA,SACEuH,UAAU,eACVrB,KAAK,OACL2D,YAAY,eACZC,MAAOvH,EACPwH,SAnZWC,IAEvBxH,EAAcwH,EAAMC,OAAOH,OAG3BxG,IAAsB,IA+YV4G,UA5YWlN,IACT,UAAVA,EAAE8L,MACJ9J,QAAQC,IAAI,kBAAmBsD,GAC/B5E,GAAO4E,EAAY,CAAE/C,SAAU,CAAEE,QAAS,KAAQ,GAClD8C,EAAc,SA2YRzC,IAAAC,cAAA,MAAIE,MAAO,CAAEiK,OAAQ,YAAc,QC5iBhCC,kBAVDzJ,IACZ,MAAM,IAAEC,EAAG,OAAEC,GAAWF,EAAM0J,KAE9B,OADAtL,oBAAU,IAAMyF,IAAUC,kBAExB1E,IAAAC,cAAAD,IAAAE,SAAA,KACEF,IAAAC,cAACsK,EAAQ,CAAC1J,IAAKA,EAAKC,OAAQA,O,gCCLlC,MAAM0J,EAAS,IAAIC,IAGnBC,IAASC,OACP3K,IAAAC,cAACD,IAAM4K,WAAU,KACf5K,IAAAC,cAAC4K,IAAiB,CAACd,MAAOS,GACxBxK,IAAAC,cAAC6K,IAAa,CAACC,MAAOC,KACpBhL,IAAAC,cAACgL,EAAI,SAIXC,SAASC,eAAe,W","file":"static/js/main.d988ede3.chunk.js","sourcesContent":["function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = function() { return []; };\nwebpackEmptyContext.resolve = webpackEmptyContext;\nmodule.exports = webpackEmptyContext;\nwebpackEmptyContext.id = 21;","import React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\nconst Dictaphone = ({\n  commands,\n  myFunc,\n  listenAfterReply = false,\n  no_response_time = 3,\n  show_conversation = true,\n  apiInProgress = false, // Receive apiInProgress as a prop\n  listenButton = false,\n  session_listen=false,\n}) => {\n  const [transcribing, setTranscribing] = useState(true);\n  const [clearTranscriptOnListen, setClearTranscriptOnListen] = useState(true);\n  const { finalTranscript, resetTranscript, listening, browserSupportsSpeechRecognition, isMicrophoneAvailable } = useSpeechRecognition({ transcribing, clearTranscriptOnListen });\n  const [prevScript, setPrevScript] = useState(\"\");\n\n  useEffect(() => {\n    if (finalTranscript !== \"\") {\n      // Add logs to check the conditions\n      console.log(\"Got final result:\", finalTranscript);\n      console.log(\"listening?\", listening);\n      console.log(\"listenAfterReply:\", listenAfterReply);\n\n      // Clear the previous script if a keyword is found or if the transcript exceeds 89 words\n      if (session_listen && finalTranscript.split(\" \").length > 500000){\n        console.log(\"Transcript exceeds X words\");\n        myFunc(finalTranscript, commands[i], 6);\n        resetTranscript();\n        return;\n      }\n\n      if (session_listen==false && finalTranscript.split(\" \").length > 10000) {\n        console.log(\"Transcript exceeds 89 words. Clearing You really should call func-api to save .\");\n        resetTranscript();\n        return;\n      }\n\n      // Set the previous script\n      setPrevScript(finalTranscript);\n\n      // Start the timer to check for keywords after a pause\n      const timer = setTimeout(() => {\n        for (let i = 0; i < commands.length; i++) {\n          const { keywords, api_body } = commands[i];\n          for (let j = 0; j < keywords.length; j++) {\n            const keyword = new RegExp(keywords[j], \"i\");\n            const isKeywordFound = finalTranscript.search(keyword) !== -1;\n\n            if ((isKeywordFound || listenAfterReply || listenButton) && !apiInProgress) {\n              if (listenAfterReply) {\n                myFunc(finalTranscript, { api_body: { keyword: \"\" } }, 3);\n              } else if (isKeywordFound) {\n                myFunc(finalTranscript, commands[i], 1);\n              }\n              else if (listenButton) {\n                myFunc(finalTranscript, commands[i], 5);\n              }\n              resetTranscript();\n              return;\n            }\n          }\n        }\n        // Waiting for a keyword or API is in progress\n        console.log(\"Waiting for a keyword or API is in progress\");\n      }, no_response_time * 1000);\n\n      return () => clearTimeout(timer); // Clear the timer on component unmount or when useEffect runs again\n    }\n  }, [finalTranscript, listenAfterReply, commands, no_response_time, resetTranscript, apiInProgress, listenButton]);\n\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>No browser support</span>;\n  }\n\n  if (!isMicrophoneAvailable) {\n    return <span>Please allow access to the microphone</span>;\n  }\n\n  return (\n    <>\n      {show_conversation && (\n          <div style={{ display: \"flex\", flexDirection: \"column\", maxHeight: \"200px\", overflowY: \"auto\", border: \"1px solid #ccc\", padding: \"10px\" }}>\n          <span>You said: {prevScript}</span>\n          <span>Listening: {listening ? \"on\" : \"off\"}</span>\n          {/* Add other conversation messages here */}\n        </div>\n      )}\n    </>\n  );\n};\n\nexport default Dictaphone;\n","import React, { useState, useEffect, useRef } from \"react\";\nimport axios from \"axios\";\nimport { Streamlit } from \"streamlit-component-lib\";\nimport SpeechRecognition from \"react-speech-recognition\";\nimport Dictaphone from \"./Dictaphone\";\n// import Dictaphone_ss from \"./Dictaphone_ss\";\nimport * as faceapi from \"@vladmandic/face-api\";\nimport DOMPurify from 'dompurify';\n\nlet timer = null;\nlet faceTimer = null;\nlet g_anwers = [];\nlet firstFace = false;\n\nconst CustomVoiceGPT = (props) => {\n  const { api, kwargs = {} } = props;\n  const {\n    commands,\n    height,\n    width,\n    show_conversation,\n    show_video,\n    input_text,\n    no_response_time,\n    face_recon,\n    api_key,\n    refresh_ask,\n    self_image,\n    api_audio,\n    client_user,\n    force_db_root,\n    before_trigger,\n  } = kwargs;\n  const [imageSrc, setImageSrc] = useState(kwargs.self_image);\n  const [imageSrc_name, setImageSrc_name] = useState(kwargs.self_image);\n\n  const [message, setMessage] = useState(\"\");\n  const [answers, setAnswers] = useState([]);\n  const [listenAfterReply, setListenAfterReply] = useState(false);\n\n  const [modelsLoaded, setModelsLoaded] = useState(false);\n  const [captureVideo, setCaptureVideo] = useState(false);\n  const [textString, setTextString] = useState(\"\");\n  const [apiInProgress, setApiInProgress] = useState(false); // Added state for API in progress\n  const [speaking, setSpeakingInProgress] = useState(false); // Added state for API in progress\n\n  const [listenButton, setlistenButton] = useState(false); // Added state for API in progress\n  const [session_listen, setsession_listen] = useState(false);\n\n  const [before_trigger_vars, before_trigger_] = useState(kwargs.before_trigger); \n  const faceData = useRef([]);\n  const faceTriggered = useRef(false);\n  const videoRef = useRef();\n  const videoHeight = 480;\n  const videoWidth = 640;\n  const canvasRef = useRef();\n  const audioRef = useRef(null);\n\n  const [isListening, setIsListening] = useState(false);\n  const [UserUsedChatWindow, setUserUsedChatWindow] = useState(false);\n\n  const [buttonName, setButtonName] = useState(\"Click and Ask\");\n  const [buttonName_listen, setButtonName_listen] = useState(\"Listening\");\n\n  useEffect(() => {\n    if (self_image) {\n      // Fetch the image data from the API endpoint\n      fetchImageData(self_image);\n    }\n  }, [self_image]);\n\n  const fetchImageData = async (imageUrl) => {\n    try {\n      const response = await axios.get(`${api_audio}${imageUrl}`, {\n        responseType: 'blob', // Set responseType to 'blob' to handle file response\n      });\n      const objectUrl = URL.createObjectURL(response.data); // Use a different variable name here\n      setImageSrc(objectUrl);\n      setImageSrc_name(imageUrl)\n    } catch (error) {\n      console.error('Error fetching image data:', error);\n    }\n  };\n\n  const checkListeningStatus = () => {\n    // Check if continuous listening is active\n    if (!SpeechRecognition.browserSupportsContinuousListening()) {\n      // If not, restart continuous listening\n      startContinuousListening();\n    }\n  };\n\n  useEffect(() => {\n    Streamlit.setFrameHeight();\n\n    // Check listening status every minute\n    const intervalId = setInterval(() => {\n      if (!SpeechRecognition.browserSupportsContinuousListening()) {\n        // If continuous listening is not active, start it\n        console.log(\"LISTEN STOPPED TURNING BACK ON\", error);\n        listenContinuously();\n      }\n    }, 60000);\n\n    return () => {\n      clearInterval(intervalId);\n    };\n  }, []);\n\n  const startContinuousListening = () => {\n    // Start continuous listening\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    });\n    setIsListening(true)\n  };\n\n  const stopListening = () => {\n    SpeechRecognition.stopListening();\n    setIsListening(false);\n    console.log(\"Stopping Listening, isListening=\", isListening)\n\n    \n  }\n  \n  const startListening = () => {\n    SpeechRecognition.startListening();\n  };\n\n  const listenContinuously = () =>{\n    SpeechRecognition.startListening({\n      continuous: true,\n      language: \"en-GB\",\n    })\n    setIsListening(true)\n  }\n\n  const listenSession = () =>{\n    if (session_listen) {\n    setsession_listen(false)\n  }\n  else{\n    setsession_listen(true)\n  }\n    }\n\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = process.env.PUBLIC_URL + \"/models\";\n\n      Promise.all([\n        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),\n        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),\n        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),\n        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),\n      ]).then(() => setModelsLoaded(true));\n    };\n    loadModels();\n    const interval = setInterval(() => {\n      // console.log(\"faceData.current :>> \", faceData.current);\n    }, 3000);\n    return () => clearInterval(interval);\n  }, []);\n\n\n  const handleInputText = (event) => {\n    // Update the state with the input text\n    setTextString(event.target.value);\n  \n    // Set a variable to indicate that the user used the chat window\n    setUserUsedChatWindow(true);\n  };\n\n  const handleOnKeyDown = (e) => {\n    if (e.key === \"Enter\") {\n      console.log(\"textString :>> \", textString);\n      myFunc(textString, { api_body: { keyword: \"\" } }, 4);\n      setTextString(\"\");\n    }\n  };\n\n  const startVideo = () => {\n    setCaptureVideo(true);\n    navigator.mediaDevices\n      .getUserMedia({ video: { width: 300 } })\n      .then((stream) => {\n        let video = videoRef.current;\n        video.srcObject = stream;\n        video.play();\n      })\n      .catch((err) => {\n        console.error(\"error:\", err);\n      });\n  };\n\n  const handleVideoOnPlay = () => {\n    setInterval(async () => {\n      if (canvasRef && canvasRef.current) {\n        canvasRef.current.innerHTML = faceapi.createCanvasFromMedia(\n          videoRef.current\n        );\n        const displaySize = {\n          width: videoWidth,\n          height: videoHeight,\n        };\n\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n\n        const detections = await faceapi\n          .detectAllFaces(\n            videoRef.current,\n            new faceapi.TinyFaceDetectorOptions()\n          )\n          .withFaceLandmarks()\n          .withFaceExpressions();\n\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n\n        if (resizedDetections.length > 0) {\n          faceData.current = resizedDetections;\n          if (!faceTriggered.current && face_recon) {\n            myFunc(\"\", { api_body: { keyword: \"\" } }, 2);\n            faceTriggered.current = true;\n          }\n        } else {\n          faceTimer && clearTimeout(faceTimer);\n          setTimeout(() => {\n            faceData.current = [];\n          }, 1000);\n        }\n\n        if (resizedDetections.length > 0 && !firstFace) {\n          firstFace = true;\n          if (kwargs.hello_audio) {\n            const audio = new Audio(kwargs.hello_audio);\n            audio.play();\n          }\n        }\n\n        canvasRef &&\n          canvasRef.current &&\n          canvasRef.current\n            .getContext(\"2d\")\n            .clearRect(0, 0, videoWidth, videoHeight);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        canvasRef &&\n          canvasRef.current &&\n          faceapi.draw.drawFaceExpressions(\n            canvasRef.current,\n            resizedDetections\n          );\n      }\n    }, 300);\n  };\n\n  const closeWebcam = () => {\n    videoRef.current.pause();\n    videoRef.current.srcObject.getTracks()[0].stop();\n    setCaptureVideo(false);\n  };\n\n  const click_listenButton = () => {\n    setlistenButton(true)\n    listenContinuously()\n    setButtonName(\"Please Speak\")\n    console.log(\"listening button listen click\");\n    console.log(listenButton);\n  };\n\n  function isHTML(str) {\n    return /^</.test(str);\n  }\n\n  const myFunc = async (ret, command, type) => {\n    setMessage(` (${command[\"api_body\"][\"keyword\"]}) ${ret},`);\n    const text = [...g_anwers, { user: ret }];\n    setAnswers([...text]);\n    try {\n      console.log(\"api call on listen...\", command);\n      setApiInProgress(true); // Set API in progress to true\n      stopListening()\n\n      const body = {\n        tigger_type: type,\n        api_key: api_key,\n        text: text,\n        self_image: imageSrc_name,\n        face_data: faceData.current,\n        refresh_ask: refresh_ask,\n        client_user: client_user,\n        force_db_root:force_db_root,\n        session_listen:session_listen,\n        before_trigger_vars:before_trigger_vars,\n      };\n      console.log(\"api\");\n      const { data } = await axios.post(api, body);\n      console.log(\"data :>> \", data, body);\n      if (data[\"self_image\"] && data[\"self_image\"] !== imageSrc_name) {\n        fetchImageData(data[\"self_image\"]); // Fetch image data if it's different\n      }\n      setAnswers(data[\"text\"]);\n      g_anwers = [...data[\"text\"]];\n      \n      if (audioRef.current) {\n        audioRef.current.pause(); // Pause existing playback if any\n      }\n\n      // audioRef.current = new Audio(data[\"audio_path\"]);\n      const apiUrlWithFileName = `${api_audio}${data[\"audio_path\"]}`;\n      audioRef.current = new Audio(apiUrlWithFileName);\n      audioRef.current.play();\n      \n      // Wait for the onended callback to complete before continuing\n      setSpeakingInProgress(true)\n      setButtonName_listen(\"Speaking\")\n      await new Promise((resolve) => {\n        audioRef.current.onended = () => {\n          console.log(\"Audio playback finished.\");\n          resolve();\n        };\n      });\n      setButtonName(\"Click and Ask\")\n      setButtonName_listen(\"Listening\")\n      setSpeakingInProgress(false)\n      setApiInProgress(false)\n\n      console.log(\"Audio ENDED MOVE TO SET VARS .\");\n      \n      setListenAfterReply(data[\"listen_after_reply\"]);\n      console.log(\"listen after reply\", data[\"listen_after_reply\"]);\n\n      if (data[\"page_direct\"] !== false && data[\"page_direct\"] !== null) {\n        console.log(\"api has page direct\", data[\"page_direct\"]);\n        // window.location.reload();\n        window.location.href = data[\"page_direct\"];\n      }\n      \n      if (listenAfterReply==true && !listenButton && !UserUsedChatWindow) {\n        listenContinuously()\n        setButtonName_listen(\"Awaiting your Answer please speak\")\n      }\n      else if (listenButton) {\n      setlistenButton(false)\n      }\n      else if (UserUsedChatWindow){\n        setUserUsedChatWindow(false)\n      }\n      else {\n        listenContinuously()\n        setButtonName_listen(\"listeing for key word\")\n      }\n      \n      console.log(\"listing end\", isListening)\n\n    } catch (error) {\n      console.log(\"api call on listen failed!\", error);\n      setApiInProgress(false); // Set API in progress to false on error\n      setlistenButton(false)\n    }\n  };\n\n  useEffect(() => {\n    // Function to resize the window\n    const resizeWindow = () => {\n      window.resizeBy(0, 1); // Resize the window by 1 pixel vertically\n    };\n\n    // Resize the window after the response finishes\n    // Replace `RESPONSE_FINISH_EVENT` with the event that indicates the response finished\n    window.addEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n\n    // Cleanup the event listener\n    return () => {\n      window.removeEventListener('RESPONSE_FINISH_EVENT', resizeWindow);\n    };\n  }, []); // Run only once after component mounts\n\n  return (\n    <>\n      <div className=\"p-2\">\n        <div style={{ display: 'flex', flexDirection: 'row', width: '100%' }}>\n          {/* Image or video section */}\n          <div style={{ flex: 1 }}>\n            {imageSrc && imageSrc.toLowerCase().endsWith(\".mp4\") ? (\n              <video\n                height={height || 100}\n                width={width || 100}\n                controls\n                autoPlay={true}\n                loop={false}\n                muted\n              >\n                <source src={imageSrc} type=\"video/mp4\" />\n                Your browser does not support the video tag.\n              </video>\n            ) : (\n              <img src={imageSrc} height={height || 100} width={width || 100} />\n            )}\n            {/* Flashing green line indicator */}\n            {apiInProgress && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '10px',\n                  left: '0',\n                  width: '100%',\n                  height: '10px',\n                  backgroundImage: 'linear-gradient(90deg, blue, transparent 50%, blue)',\n                  animation: 'flashLine 1s infinite',\n                }}\n              >\n                <div style={{ position: 'relative', top: '-20px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>One Moment please</div>\n              </div>\n            )}\n            {/* Speaking indicator */}\n            {speaking && (\n              <div style={{ position: 'relative', width: '100%', height: '100%' }}>\n              {speaking && (\n                <div\n                  style={{\n                    position: 'absolute',\n                    top: '10px',\n                    left: '0',\n                    width: '100%',\n                    height: '20px',\n                    background: 'linear-gradient(to right, blue, transparent, purple)',\n                    animation: 'waveAnimation 1s infinite',\n                    borderRadius: '10px',\n                  }}\n                >\n                  <div style={{ position: 'absolute', top: '-30px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>\n                    Speaking\n                  </div>\n                </div>\n              )}\n              {/* Your image or other content here */}\n            </div>\n            )}\n            {/* Listening indicator */}\n            {isListening && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '10px',\n                  left: '0',\n                  width: '100%',\n                  height: '10px',\n                  backgroundImage: 'linear-gradient(90deg, green, transparent 50%, green)',\n                  animation: 'flashLine 1s infinite',\n                }}\n              >\n                <div style={{ position: 'absolute', top: '-30px', left: '50%', transform: 'translateX(-89%)', color: 'black', fontSize: '14px' }}>{buttonName_listen}</div>\n              </div>\n            )}\n            {/* Listening Session */}\n            {session_listen && (\n              <div\n                style={{\n                  position: 'relative',\n                  top: '-10px', /* Adjusted top position */\n                  right: '50', /* Added right position */\n                  left: '0',\n                  width: '50%', /* Adjusted width to show only to the right side */\n                  height: '10px',\n                  backgroundImage: 'linear-gradient(90deg, orange, transparent 50%, orange)',\n                  animation: 'flashLine 1s infinite',\n                }}\n              >\n                <div style={{ position: 'relative', top: '-20px', left: '50%', transform: 'translateX(-50%)', color: 'black', fontSize: '14px' }}>Session Started</div>\n              </div>\n            )}\n          </div>\n  \n          {/* Message section */}\n        {/* Conversation history */}\n        <div style={{ flex: 1, overflowY: 'auto', maxHeight: '400px' }}>\n      {show_conversation === true && (\n        <>\n          <div> You: {message}</div>\n          {answers.map((answer, idx) => (\n            <div key={idx} style={{ marginBottom: '5px' }}>\n              <div style={{ backgroundColor: answer.resp ? '#f2f2f2' : 'lightblue', padding: '5px', borderRadius: '5px' }}>\n                -user: <span dangerouslySetInnerHTML={{ __html: DOMPurify.sanitize(answer.user) }} />\n              </div>\n              <div style={{ backgroundColor: answer.resp ? 'lightyellow' : '#f2f2f2', padding: '5px', borderRadius: '5px' }}>\n                -resp: <span dangerouslySetInnerHTML={{ __html: DOMPurify.sanitize(answer.resp || \"thinking...\") }} />\n              </div>\n                </div>\n              ))}\n            </>\n          )}\n        </div>\n        </div>\n  \n        {/* Listen and Listening buttons */}\n        <div style={{ display: 'flex', marginTop: '10px' }}>\n          <button\n            style={{\n              flex: 1,\n              marginRight: '5px',\n              backgroundColor: '#3498db',\n              color: 'white',\n              padding: '10px',\n              border: '2px solid #2980b9',\n              cursor: 'pointer',\n            }}\n            onClick={click_listenButton}\n          >\n            {buttonName}\n          </button>\n          <button\n            style={{\n              flex: 1,\n              marginLeft: '5px',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              padding: '10px',\n              border: '2px solid #2980b9',\n              cursor: 'pointer',\n            }}\n            onClick={listenContinuously}\n          >\n            Conversational Mode\n          </button>\n          <button\n            style={{\n              flex: 1,\n              marginLeft: '5px',\n              backgroundColor: '#2980b9',\n              color: 'white',\n              padding: '10px',\n              border: '2px solid #2980b9',\n              cursor: 'pointer',\n            }}\n            onClick={listenSession}\n          >\n            Start A Session\n          </button>\n        </div>\n  \n        {/* Dictaphone component */}\n        <div className=\"p-2\">\n          <Dictaphone\n            commands={commands}\n            myFunc={myFunc}\n            listenAfterReply={listenAfterReply}\n            no_response_time={no_response_time}\n            show_conversation={show_conversation}\n            apiInProgress={apiInProgress}\n            listenButton={listenButton}\n            session_listen={session_listen}\n          />\n        </div>\n  \n        {/* Input text section */}\n        {input_text && (\n          <>\n            <div className=\"form-group\">\n              <input\n                className=\"form-control\"\n                type=\"text\"\n                placeholder=\"Chat with Me\"\n                value={textString}\n                onChange={handleInputText}\n                onKeyDown={handleOnKeyDown}\n              />\n            </div>\n            <hr style={{ margin: '20px 0' }} /> {/* Add a solid line */}\n          </>\n        )}\n  \n      </div>\n    </>\n  );\n};\n\nexport default CustomVoiceGPT;\n","import React, { useEffect, useState } from \"react\"\nimport {\n  ComponentProps,\n  Streamlit,\n  withStreamlitConnection,\n} from \"streamlit-component-lib\"\nimport VoiceGPT from \"./VoiceGPT.jsx\"\n\nconst Main = (props: ComponentProps) => {\n  const { api, kwargs } = props.args\n  useEffect(() => Streamlit.setFrameHeight())\n  return (\n    <>\n      <VoiceGPT api={api} kwargs={kwargs} />\n    </>\n  )\n}\n\nexport default withStreamlitConnection(Main)\n","import React from \"react\"\nimport ReactDOM from \"react-dom\"\nimport Main from \"./Main\"\n// Lots of import to define a Styletron engine and load the light theme of baseui\nimport { Client as Styletron } from \"styletron-engine-atomic\"\nimport { Provider as StyletronProvider } from \"styletron-react\"\nimport { ThemeProvider, LightTheme } from \"baseui\"\n\nconst engine = new Styletron()\n\n// Wrap your CustomSlider with the baseui them\nReactDOM.render(\n  <React.StrictMode>\n    <StyletronProvider value={engine}>\n      <ThemeProvider theme={LightTheme}>\n        <Main />\n      </ThemeProvider>\n    </StyletronProvider>\n  </React.StrictMode>,\n  document.getElementById(\"root\")\n)\n"],"sourceRoot":""}